{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0749b16a",
   "metadata": {},
   "source": [
    "Excelente ideia! Separar as alterações por trechos de código tornará a compreensão muito mais clara.\n",
    "\n",
    "Vou apresentar cada trecho do seu código original que será substituído ou modificado, seguido pelo novo código e uma explicação detalhada.\n",
    "\n",
    "1. Invocação do LLM e Pós-processamento (O Coração da Mudança)\n",
    "\n",
    "Esta é a parte mais crítica do pipeline, onde a inferência do LLM é realizada e as respostas são processadas.\n",
    "\n",
    "Código Original:\n",
    "\n",
    "# ... (dentro do bloco `if df_spk.count() > 0:`) ...\n",
    "\n",
    "llm_client = openai.OpenAI(api_key=DATABRICKS_TOKEN,\n",
    "                       base_url=\"https://dbc-d80f50a9-af23.cloud.databricks.com/serving-endpoints\"\n",
    "                       )\n",
    "descricao_agente = \"Atue como um médico oncologista especialista em laudos de mamografia.\"\n",
    "\n",
    "# Coleta os dados localmente\n",
    "df_local = df_spk.select(\"ficha\",\"id_item\",\"id_subitem\",\"id_cliente\",\"dth_pedido\",\"dth_resultado\", \"sigla_exame\", \"laudo_tratado\",\"linha_cuidado\",\"_datestamp\").toPandas()\n",
    "\n",
    "# Aplica o LLM localmente\n",
    "df_local[\"resposta_llm\"] = batch_generate(descricao_agente, df_local[\"laudo_tratado\"].tolist(), llm_client, batch_size=25)\n",
    "df_local = df_local.join(df_local[\"resposta_llm\"].apply(limpar_e_converter).apply(pd.Series))\n",
    "\n",
    "# ... (restante do código que usa df_local) ...\n",
    "\n",
    "# Funções auxiliares para o LLM\n",
    "def prompt_laudo(laudo_texto: str) -> str:\n",
    "# ... (código da função prompt_laudo) ...\n",
    "\n",
    "def generate(descricao_agente:str, laudo:str, llm_client) -> str:\n",
    "# ... (código da função generate) ...\n",
    "\n",
    "def batch_generate(descricao_agente, laudos, llm_client, batch_size=25):\n",
    "# ... (código da função batch_generate) ...\n",
    "\n",
    "def limpar_e_converter(item):\n",
    "# ... (código da função limpar_e_converter) ...\n",
    "\n",
    "\n",
    "Problema/Contexto:\n",
    "\n",
    "df_spk.toPandas(): Coleta todos os dados do Spark para o nó driver, o que é um gargalo de performance e escalabilidade para grandes volumes.\n",
    "batch_generate e generate: Apesar do nome, batch_generate chama o LLM sequencialmente para cada laudo dentro de um lote, e ainda inclui um time.sleep(0.5). Isso é extremamente lento e ineficiente.\n",
    "limpar_e_converter: É uma função Python que processa as respostas JSON localmente, após a coleta dos dados.\n",
    "Gerenciamento do Cliente LLM: O cliente openai.OpenAI é inicializado e gerenciado manualmente.\n",
    "\n",
    "Novo Código:\n",
    "\n",
    "import json # Necessário para json.dumps\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "\n",
    "# --- Nova definição do prompt como template de string ---\n",
    "# Esta função agora retorna um template de string que será preenchido pelo Spark\n",
    "def prompt_laudo_template() -> str:\n",
    "prompt = \"\"\"A seguir está um laudo médico de mamografia, conforme indicado abaixo. Se alguma informação não estiver presente no texto, retorne \"NÃO INFORMADO\". Sempre retorne apenas o dicionário Python.\n",
    "\n",
    "Laudo clínico:\n",
    "\\\"\\\"\\\"{laudo_texto}\\\"\\\"\\\"\n",
    "\n",
    "### Critérios de extração:\n",
    "\n",
    "- **Receptor de Estrogênio**: retorne se é \"POSITIVO\", \"NEGATIVO\" ou \"NÃO INFORMADO\".\n",
    "\n",
    "- **Receptor de Progesterona**: retorne se é \"POSITIVO\", \"NEGATIVO\" ou \"NÃO INFORMADO\".\n",
    "\n",
    "- **Status do HER-2**: retorne se o Status do HER-2 é \"NEGATIVO\", \"INCONCLUSIVO\", \"POSITIVO\" ou \"NÃO INFORMADO\". Com base no score seguindo as regras:\n",
    "- \"HER-2 - ESCORE 0\" ou \"1+\" → \"NEGATIVO\"\n",
    "- \"HER-2 - ESCORE 2+\" → \"INCONCLUSIVO\"\n",
    "- \"HER-2 - ESCORE 3+\" → \"POSITIVO\"\n",
    "\n",
    "- **Ki-67 (%)**: retorne o valor numérico da porcentagem de positividade do KI-67, caso seja um intervalo de valores retorne o intervalo com valor mínimo e valor máximo separado por um hífem.\n",
    "\n",
    "- **Status do CK5/6**: retorne \"POSITIVO\", \"NEGATIVO\" ou \"NÃO INFORMADO\" do Status do CK5/6.\n",
    "\n",
    "### Saída esperada (dicionário Python válido):\n",
    "```python\n",
    "{{\n",
    "\"receptor_estrogeno\": \"POSITIVO\" | \"NEGATIVO\" |  \"NÃO INFORMADO\",\n",
    "\"receptor_progesterona\": \"POSITIVO\" | \"NEGATIVO\" |  \"NÃO INFORMADO\",\n",
    "\"status_her2\": \"POSITIVO\" | \"POSITIVO\" | \"INCONCLUSIVO\" |  \"NÃO INFORMADO\",\n",
    "\"ki67_percentual\": float |  0,\n",
    "\"status_ck5_6\": \"POSITIVO\" | \"NEGATIVO\" |  \"NÃO INFORMADO\"\n",
    "}}\n",
    "\n",
    "\n",
    "\"\"\" return prompt.strip()\n",
    "\n",
    "--- Schema para o JSON de saída do LLM (usado por from_json) ---\n",
    "\n",
    "llm_output_schema = StructType([ StructField(\"receptor_estrogeno\", StringType(), True), StructField(\"receptor_progesterona\", StringType(), True), StructField(\"status_her2\", StringType(), True), StructField(\"ki67_percentual\", StringType(), True), # Manter como StringType para lidar com \"NÃO INFORMADO\" ou intervalos StructField(\"status_ck5_6\", StringType(), True), ])\n",
    "\n",
    "--- Bloco principal de execução (dentro do if df_spk.count() > 0:) ---\n",
    "Nome do modelo Foundation Model no Databricks\n",
    "\n",
    "llm_model_name = \"databricks-llama-4-maverick\" # Ou o modelo que você estiver usando\n",
    "\n",
    "O prompt_laudo_template() é uma string Python.\n",
    "Precisamos escapar as aspas para SQL e usar CONCAT para injetar o laudo_tratado.\n",
    "O json.dumps é usado para escapar o template do prompt para ser seguro em SQL.\n",
    "O .replace é para o placeholder do laudo.\n",
    "\n",
    "escaped_prompt_template = json.dumps(prompt_laudo_template()).replace('\"{{laudo_texto}}\"', \"laudo_tratado\")\n",
    "\n",
    "Usa ai_query para invocar o LLM de forma distribuída\n",
    "\n",
    "df_with_llm_raw_responses = df_spk.withColumn( \"llm_raw_response\", F.expr(f\"\"\" ai_query( '{llm_model_name}', CONCAT({escaped_prompt_template}), temperature => 0.0, max_tokens => 4000, top_p => 0.75, frequency_penalty => 0.0, presence_penalty => 0.0 ) \"\"\") )\n",
    "\n",
    "Converte as strings JSON das respostas do LLM em colunas estruturadas\n",
    "\n",
    "df_llm_parsed = df_with_llm_raw_responses.withColumn( \"llm_parsed_output\", F.from_json(F.col(\"llm_raw_response\"), llm_output_schema) ).select( \"*\", # Mantém todas as colunas originais F.col(\"llm_parsed_output.receptor_estrogeno\").alias(\"receptor_estrogeno\"), F.col(\"llm_parsed_output.receptor_progesterona\").alias(\"receptor_progesterona\"), F.col(\"llm_parsed_output.status_her2\").alias(\"status_her2\"), F.col(\"llm_parsed_output.ki67_percentual\").alias(\"ki67_percentual\"), F.col(\"llm_parsed_output.status_ck5_6\").alias(\"status_ck5_6\") ).drop(\"llm_raw_response\", \"llm_parsed_output\") # Remove as colunas intermediárias\n",
    "\n",
    "Garante que ki67_percentual seja float para a classificação\n",
    "\n",
    "df_llm_parsed = df_llm_parsed.withColumn( \"ki67_percentual_float\", F.when( F.col(\"ki67_percentual\").cast(DoubleType()).isNotNull(), F.col(\"ki67_percentual\").cast(DoubleType()) ).otherwise(0.0) # Se não for um número válido, assume 0.0 )\n",
    "\n",
    "... (restante do código de classificação, que usa df_llm_parsed) ...\n",
    "\n",
    "**Explicação da Mudança:**\n",
    "\n",
    "*   **Remoção de `df_spk.toPandas()`**: Os dados permanecem no `DataFrame` Spark, garantindo processamento distribuído.\n",
    "*   **Remoção de `generate`, `batch_generate`, `limpar_e_converter`**: Toda a lógica de invocação e parsing do LLM é substituída por uma única expressão Spark usando `ai_query` e `from_json`.\n",
    "*   **`ai_query`**: Esta função Spark SQL é a chave. Ela invoca o Foundation Model configurado no Databricks, passando o prompt (construído dinamicamente com `CONCAT` e o `laudo_tratado` de cada linha) e os parâmetros do modelo. O Databricks gerencia o batching, retries e a escalabilidade automaticamente.\n",
    "*   **`prompt_laudo_template()`**: A função `prompt_laudo` foi adaptada para retornar um template de string. Este template é então injetado na expressão `ai_query` de forma segura usando `json.dumps` e `replace` para o placeholder `laudo_texto`.\n",
    "*   **`from_json()`**: Substitui a função `limpar_e_converter`. Ele parseia a string JSON retornada pelo LLM diretamente no Spark, usando o `llm_output_schema` para tipagem e estruturação. Isso é muito mais eficiente e robusto.\n",
    "*   **`ki67_percentual_float`**: A conversão para float agora é feita diretamente no Spark, com tratamento para valores não numéricos.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Funções de Extração Heurística e Avaliação\n",
    "\n",
    "Estas funções são para gerar \"pseudo-ground truth\" e comparar com a saída do LLM. Elas não fazem parte do pipeline de inferência principal, mas são importantes para a validação.\n",
    "\n",
    "**Código Original:**\n",
    "\n",
    "```python\n",
    "# =================================================================\n",
    "# Funções de extração heurística (pseudo-gold) para o novo prompt\n",
    "# =================================================================\n",
    "\n",
    "def extrai_receptor_estrogeno(txt: str) -> str:\n",
    "# ... (código da função) ...\n",
    "\n",
    "def extrai_receptor_progesterona(txt: str) -> str:\n",
    "# ... (código da função) ...\n",
    "\n",
    "def extrai_status_her2(txt: str) -> str:\n",
    "# ... (código da função) ...\n",
    "\n",
    "def extrai_ki67_percentual(txt: str) -> float:\n",
    "# ... (código da função) ...\n",
    "\n",
    "def extrai_status_ck5_6(txt: str) -> str:\n",
    "# ... (código da função) ...\n",
    "\n",
    "# ==========================================================================\n",
    "# Função de avaliação sem ground truth completo (novo conjunto de campos)\n",
    "# ==========================================================================\n",
    "\n",
    "def avalia_extracao_sem_ground_truth_imuno(laudo_texto: str, json_modelo: dict):\n",
    "# ... (código da função) ...\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def agrega_resultados_dinamico(lista_comparacoes):\n",
    "# ... (código da função) ...\n",
    "\n",
    "\n",
    "Problema/Contexto:\n",
    "\n",
    "Nenhum problema intrínseco a estas funções. Elas são ferramentas de validação.\n",
    "\n",
    "Novo Código:\n",
    "\n",
    "Nenhum. Estas funções permanecem inalteradas e devem ser usadas para seu propósito original de avaliação.\n",
    "\n",
    "Explicação da Mudança:\n",
    "\n",
    "Estas funções não são usadas no novo pipeline de inferência com ai_query.\n",
    "Para usá-las para avaliar o desempenho do LLM, você precisaria coletar uma amostra do df_llm_parsed (ou df_final_classif) para o nó driver (usando .limit(N).toPandas()) e então aplicar essas funções localmente. Isso evita coletar todo o dataset, que é o problema que estamos resolvendo.\n",
    "3. Função parse_json_string\n",
    "\n",
    "Código Original:\n",
    "\n",
    "def parse_json_string(s):\n",
    "if isinstance(s, str):\n",
    "    try:\n",
    "        return ast.literal_eval(s)\n",
    "    except Exception:\n",
    "        return {}\n",
    "return s\n",
    "\n",
    "\n",
    "Problema/Contexto:\n",
    "\n",
    "Esta função era usada para parsear strings JSON.\n",
    "\n",
    "Novo Código:\n",
    "\n",
    "Removida.\n",
    "\n",
    "Explicação da Mudança:\n",
    "\n",
    "A funcionalidade de parsing de JSON é agora tratada de forma mais eficiente e distribuída pela função Spark F.from_json(), que opera diretamente nos DataFrames. Portanto, esta função Python não é mais necessária.\n",
    "\n",
    "Com estas alterações, seu pipeline se torna nativamente distribuído, escalável e otimizado para o uso de Foundation Models no Databricks, abordando diretamente as questões de custo e performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e712b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "casa\n"
     ]
    }
   ],
   "source": [
    "# --- Bloco de avaliação de métricas (após a geração de df_llm_parsed ou df_final_classif) ---\n",
    "\n",
    "# Para realizar a avaliação, você precisará coletar uma amostra dos dados para o driver.\n",
    "# Isso é aceitável para avaliação, mas não para o pipeline de inferência principal.\n",
    "# Ajuste o `limit(N)` conforme a quantidade de dados que você deseja avaliar.\n",
    "df_sample_for_eval = df_llm_parsed.limit(100).toPandas() # Coleta uma amostra para avaliação local\n",
    "\n",
    "lista_laudos_eval = df_sample_for_eval[\"laudo_tratado\"].tolist()\n",
    "\n",
    "# Prepara a saída do LLM para a função de avaliação\n",
    "# O `json_model_output` deve ser um dicionário Python para cada linha\n",
    "lista_json_modelo_eval = []\n",
    "for index, row in df_sample_for_eval.iterrows():\n",
    "    lista_json_modelo_eval.append({\n",
    "        \"receptor_estrogeno\": row[\"receptor_estrogeno\"],\n",
    "        \"receptor_progesterona\": row[\"receptor_progesterona\"],\n",
    "        \"status_her2\": row[\"status_her2\"],\n",
    "        \"ki67_percentual\": row[\"ki67_percentual\"], # Use a string original do LLM\n",
    "        \"status_ck5_6\": row[\"status_ck5_6\"]\n",
    "    })\n",
    "\n",
    "lista_pseudo_gold_eval = []\n",
    "lista_comparacoes_eval = []\n",
    "\n",
    "# As funções avalia_extracao_sem_ground_truth_imuno e agrega_resultados_dinamico\n",
    "# devem estar definidas em células anteriores.\n",
    "for laudo_txt, json_mod in zip(lista_laudos_eval, lista_json_modelo_eval):\n",
    "    json_heu, comp = avalia_extracao_sem_ground_truth_imuno(laudo_txt, json_mod)\n",
    "    lista_pseudo_gold_eval.append(json_heu)\n",
    "    lista_comparacoes_eval.append(comp)\n",
    "\n",
    "# Agrega os resultados das comparações\n",
    "json_metricas = agrega_resultados_dinamico(lista_comparacoes_eval)\n",
    "\n",
    "print(\"Métricas de Avaliação:\")\n",
    "print(json.dumps(json_metricas, indent=2))\n",
    "\n",
    "# Opcional: Para visualizar os resultados detalhados da avaliação\n",
    "# df_metrics_eval = pd.DataFrame()\n",
    "# df_metrics_eval[\"laudos\"] = lista_laudos_eval\n",
    "# df_metrics_eval[\"json_modelo\"] = lista_json_modelo_eval\n",
    "# df_metrics_eval[\"json_heuristico\"] = lista_pseudo_gold_eval\n",
    "# df_metrics_eval[\"comparacoes\"] = lista_comparacoes_eval\n",
    "# display(df_metrics_eval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5962270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Funções auxiliares para exportação de Excel (manter estas funções em uma célula) ---\n",
    "\n",
    "def salvar_excel(df, nome_arquivo):\n",
    "    \"\"\"\n",
    "    Salva um DataFrame em um arquivo Excel.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame a ser salvo.\n",
    "        nome_arquivo (str): Nome do arquivo Excel.\n",
    "    \"\"\"\n",
    "\n",
    "    # After installing, save the DataFrame to Excel again\n",
    "    df.to_excel(nome_arquivo, index=False)\n",
    "\n",
    "def conta_marcadores(txt: str, marcador: str) -> int:\n",
    "    \"\"\"\n",
    "    Conta quantas vezes uma marcador aparece no texto, ignorando maiúsculas/minúsculas.\n",
    "    \"\"\"\n",
    "    marcadores = {\n",
    "        'estrogenio': r\"\\b(receptor\\s+de\\s+estr[oó]g(?:[eê]nio|eno))\\b\",\n",
    "        'progesterona': r\"\\b(receptor\\s+de\\s+progesterona)\\b\",\n",
    "        'her2': r\"\\bher2\\b\",\n",
    "        'ck5_6': r\"\\bck5\\s*\\/\\s*6\\b\",\n",
    "        'ki67': r\"\\bki[-\\s]?67\\b\"\n",
    "    }\n",
    "    pattern = marcadores.get(marcador)\n",
    "    if not pattern:\n",
    "        raise ValueError(f\"marcador '{marcador}' não reconhecida. Use uma das seguintes: {list(marcadores.keys())}\")\n",
    "\n",
    "    matches = re.findall(pattern, txt, flags=re.IGNORECASE)\n",
    "    return len(matches)\n",
    "\n",
    "def pega_texto_marcador(txt: str, sigla: str) -> str: # Alterado para retornar str, não int\n",
    "    \"\"\"\n",
    "    Pega o texto que vem depois do marcador, limitado em 100 caracteres.\n",
    "    \"\"\"\n",
    "    siglas = {\n",
    "        'estrogenio': r\"\\b(receptor\\s+de\\s+estr[oó]g(?:[eê]nio|eno))\\b\",\n",
    "        'progesterona': r\"\\b(receptor\\s+de\\s+progesterona)\\b\",\n",
    "        'her2': r\"\\bher2\\b\",\n",
    "        'ck5_6': r\"\\bck5\\s*\\/\\s*6\\b\",\n",
    "        'ki67': r\"\\bki[-\\s]?67\\b\"\n",
    "    }\n",
    "    pattern = siglas.get(sigla)\n",
    "    if not pattern:\n",
    "        raise ValueError(f\"sigla '{sigla}' não reconhecida. Use uma das seguintes: {list(siglas.keys())}\")\n",
    "\n",
    "    match = re.search(pattern, txt, flags=re.IGNORECASE)\n",
    "    if match:\n",
    "        # Pega o texto após o marcador, limitado a 100 caracteres\n",
    "        start = match.end()\n",
    "        end = start + 100\n",
    "        return txt[start:end].strip()\n",
    "    return \"\"\n",
    "\n",
    "# --- Bloco para gerar a planilha de comparação (em uma nova célula) ---\n",
    "\n",
    "# df_sample_for_eval e lista_comparacoes_eval devem ter sido gerados na célula de avaliação anterior.\n",
    "# Se a célula de avaliação não for executada, este bloco falhará.\n",
    "\n",
    "if 'df_sample_for_eval' in locals() and not df_sample_for_eval.empty:\n",
    "    # Cria uma cópia do DataFrame de amostra para não modificar o original\n",
    "    df_laura = df_sample_for_eval.copy()\n",
    "\n",
    "# Normaliza a lista de comparações para adicionar as colunas de acerto\n",
    "# lista_comparacoes_eval deve vir da célula de avaliação\n",
    "if 'lista_comparacoes_eval' in locals() and lista_comparacoes_eval:\n",
    "    resultados_expandidos = pd.json_normalize(lista_comparacoes_eval)\n",
    "    # Adiciona um prefixo para evitar conflito de nomes de colunas\n",
    "    resultados_expandidos = resultados_expandidos.add_prefix('comparacao_')\n",
    "    df_laura = pd.concat(\n",
    "        [df_laura.reset_index(drop=True), resultados_expandidos.reset_index(drop=True)],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Renomeia as colunas de acerto para o formato esperado\n",
    "    df_laura = df_laura.rename(columns={\n",
    "        'comparacao_receptor_estrogeno.acertou': 'receptor_estrogeno.acertou',\n",
    "        'comparacao_receptor_progesterona.acertou': 'receptor_progesterona.acertou',\n",
    "        'comparacao_status_her2.acertou': 'status_her2.acertou',\n",
    "        'comparacao_ki67_percentual.acertou': 'ki67_percentual.acertou',\n",
    "        'comparacao_status_ck5_6.acertou': 'status_ck5_6.acertou'\n",
    "    })\n",
    "\n",
    "    # Contagem de quantas vezes cada sigla aparece no laudo\n",
    "    siglas = ['estrogenio', 'progesterona', 'her2', 'ck5_6', 'ki67']\n",
    "    for sigla in siglas:\n",
    "        df_laura['ctg_' + sigla] = df_laura['laudo_tratado'].apply(lambda x: conta_marcadores(x, sigla))\n",
    "        # Adiciona o texto do marcador para análise\n",
    "        df_laura['txt_' + sigla] = df_laura['laudo_tratado'].apply(lambda x: pega_texto_marcador(x, sigla))\n",
    "\n",
    "    # Insere coluna de erro genérico\n",
    "    df_laura['erro'] = df_laura.apply(lambda x:\n",
    "                                      (x.get('ki67_percentual.acertou', False) == False) or\n",
    "                                      (x.get('receptor_estrogeno.acertou', False) == False) or\n",
    "                                      (x.get('receptor_progesterona.acertou', False) == False) or\n",
    "                                      (x.get('status_her2.acertou', False) == False) or\n",
    "                                      (x.get('status_ck5_6.acertou', False) == False), axis=1)\n",
    "\n",
    "    # Salva o DataFrame em Excel\n",
    "    nome_arquivo_excel = \"/dbfs/FileStore/shared_uploads/seu_email/analise_laudos_comparacao.xlsx\" # Ajuste o caminho\n",
    "    salvar_excel(df_laura, nome_arquivo_excel)\n",
    "    print(f\"Planilha de comparação salva em: {nome_arquivo_excel}\")\n",
    "    display(df_laura) # Para visualizar no notebook\n",
    "else:\n",
    "    print(\"Lista de comparações vazia ou não encontrada. Não foi possível gerar a planilha de comparação.\")\n",
    "else:\n",
    "print(\"DataFrame de amostra para avaliação (df_sample_for_eval) vazio ou não encontrado. Não foi possível gerar a planilha de comparação.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5da5583",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "281438a5",
   "metadata": {},
   "source": [
    "## INCONSISTÊNCIAS IDENTIFICADAS NOS LAUDOS DE IMUNO-HISTOQUÍMICA\n",
    "### RE - RECEPTOR DE ESTRÓGENO\n",
    "- MAIS DE UM RESULTADOS NO MESMO LAUDO (13% erro confirmado - 84% para investigação granular)\n",
    "\n",
    "\n",
    "### RP - RECEPTOR DE PROGESTERONA\n",
    "- NEGATIVO E POSITIVO NA MESMA FRASE (3% de erro confirmado)\n",
    "    - NEGATIVO NO CARCINOMA MAMÁRIO INVASIVO CRIBRIFORME E POSITIVO COM FORTE INTENSIDADE EM 98% DAS CÉLULAS DO CARCINOMA LOBULAR INVASIVO\n",
    "    - NEGATIVO NAS CÉLULAS DA NEOPLASIA INVASIVA E POSITIVO COM INTENSIDADE MODERADA A FORTE EM 30% DAS CÉLULAS DO COMPONENTE DUCTAL 'IN SITU'\n",
    "    - NEGATIVO (CONTROLE INTERNO POSITIVO)\n",
    "    - NEGATIVO NAS CÉLULAS NEOPLÁSICAS DO FOCO DE INVASÃO MAIOR / POSITIVO COM INTENSIDADE MODERADA EM 40% DAS CÉLULAS DO CDIS\n",
    "    - NEGATIVO NA CÉLULAS NEOPLÁSICAS (CONTROLE INTERNO POSITIVO)\n",
    "    - NEGATIVO NAS CÉLULAS NEOPLÁSICAS (bloco A1; controle externo positivo)\n",
    "- MAIS DE UM RESULTADOS NO MESMO LAUDO\n",
    "\n",
    "### HER2\n",
    "- MAIS DE UM RESULTADOS NO MESMO LAUDO (55% erro confirmado)\n",
    "\n",
    "### CK5/6\n",
    "- MAIS DE UM RESULTADOS NO MESMO LAUDO\n",
    "- TEXTO DESPADRONIZADO (SEM EXPECIFICAR POSITIVO OU NEGATIVO) - (0,8% de erro confirmado)\n",
    "    - PERDA DE EXPRESSÃO NAS CELULAS DOS FOCOS DE AEP\n",
    "    - POSITIVO EM 20% DAS CÉLULAS NEOPLÁSICAS (DIFERENCIAÇÃO ESCAMOSA)\n",
    "    - PERDA DE EXPRESSÃO NOS FOCOS DE ATIPIA E NO CLIS\n",
    "    - PERDA DE EXPRESSÃO NO CDIS\n",
    "    - PERDA DE EXPRESSÃO NAS CÉLULAS NEOPLÁSICAS DO CDIS (PA) E NOS FOCOS DE HLA E ATIPIA PLANA\n",
    "    - PERDA DE EXPRESSÃO NOS FOCOS DE ATIPIA DA LESÃO PAPILÍFERA\n",
    "    - EXPRESSÃO REDUZIDA EM ALGUMAS CÉLULAS EPITELIAIS\n",
    "    - PERDA DE EXPRESSÃO NOS FOCOS DE CDIS E HLA DAS AMOSTRAS B2 e B3 (EXPRESSÃO NORMAL NA AMOSTRA A1)\n",
    "    - PERDA DE EXPRESSÃO NAS CÉLULAS ATÍPICAS (A1, A2 e A3)\n",
    "    - PERDA DE EXPRESSÃO NOS FOCOS DE CDIS E CLIS NAS AMOSTRAS\n",
    "\n",
    "### KI67\n",
    "- MAIS DE UM RESULTADOS NO MESMO LAUDO (13% erro confirmado - 84% para investigação granular)\n",
    "- TEXTO COM FAIXA DE PERCENTUAL - (2% de erro confirmado)\n",
    "    - proliferação celular estimada em 15-20%.\n",
    "    - POSITIVO EM 20 A 30% DAS CÉLULAS NEOPLÁSICAS\n",
    "    - POSITIVO EM 3-5% DAS CÉLULAS EPITELIAIS DE INTERESSE\n",
    "- MAIS DE UM RESULTADO NA MESMA LINHA DE TEXTO\n",
    "    - NÃO AVALIÁVEL NO FOCO DE MICROINVASÃO / POSITIVO EM 50% DAS CÉLULAS NEOPLÁSICAS DO CDIS Anti-KI-6\n",
    "    - POSITIVO EM 40% DAS CÉLULAS DO CARCINOMA MAMÁRIO INVASIVO CRIBRIFORME E POSITIVO EM 06% DAS CÉLULAS DO CARCINOMA LOBULAR INVASIVO."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff9dd67",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "baae68ba",
   "metadata": {},
   "source": [
    "```python\n",
    "def prompt_laudo_template() -> str:\n",
    "# REMOVER O 'f' ANTES DAS ASPAS TRIPLAS\n",
    "prompt = \"\"\"A seguir está um laudo médico de mamografia, conforme indicado abaixo. Se alguma informação não estiver presente no texto, retorne \"NÃO INFORMADO\". Sempre retorne apenas o dicionário Python.\n",
    "\n",
    "Laudo clínico:\n",
    "\\\"\\\"\\\"{laudo_texto}\\\"\\\"\\\"\n",
    "\n",
    "### Critérios de extração:\n",
    "\n",
    "- **Receptor de Estrogênio**: retorne se é \"POSITIVO\", \"NEGATIVO\" ou \"NÃO INFORMADO\".\n",
    "\n",
    "- **Receptor de Progesterona**: retorne se é \"POSITIVO\", \"NEGATIVO\" ou \"NÃO INFORMADO\".\n",
    "\n",
    "- **Status do HER-2**: retorne se o Status do HER-2 é \"NEGATIVO\", \"INCONCLUSIVO\", \"POSITIVO\" ou \"NÃO INFORMADO\". Com base no score seguindo as regras:\n",
    "- \"HER-2 - ESCORE 0\" ou \"1+\" → \"NEGATIVO\"\n",
    "- \"HER-2 - ESCORE 2+\" → \"INCONCLUSIVO\"\n",
    "- \"HER-2 - ESCORE 3+\" → \"POSITIVO\"\n",
    "\n",
    "- **Ki-67 (%)**: retorne o valor numérico da porcentagem de positividade do KI-67, caso seja um intervalo de valores retorne o intervalo com valor mínimo e valor máximo separado por um hífem.\n",
    "\n",
    "- **Status do CK5/6**: retorne \"POSITIVO\", \"NEGATIVO\" ou \"NÃO INFORMADO\" do Status do CK5/6.\n",
    "\n",
    "### Saída esperada (dicionário Python válido):\n",
    "```python\n",
    "{ # Remover as chaves duplas aqui também\n",
    "\"receptor_estrogeno\": \"POSITIVO\" | \"NEGATIVO\" |  \"NÃO INFORMADO\",\n",
    "\"receptor_progesterona\": \"POSITIVO\" | \"NEGATIVO\" |  \"NÃO INFORMADO\",\n",
    "\"status_her2\": \"POSITIVO\" | \"POSITIVO\" | \"INCONCLUSIVO\" |  \"NÃO INFORMADO\",\n",
    "\"ki67_percentual\": float |  0,\n",
    "\"status_ck5_6\": \"POSITIVO\" | \"NEGATIVO\" |  \"NÃO INFORMADO\"\n",
    "}\n",
    "\"\"\" \n",
    "return prompt.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3aafe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_laudo_template() -> str:\n",
    "    # REMOVER O 'f' ANTES DAS ASPAS TRIPLAS\n",
    "    prompt = \"\"\"A seguir está um laudo médico de mamografia, conforme indicado abaixo. Se alguma informação não estiver presente no texto, retorne \"NÃO INFORMADO\". Sempre retorne apenas o dicionário Python.\n",
    "\n",
    "    Laudo clínico:\n",
    "    \\\"\\\"\\\"{laudo_texto}\\\"\\\"\\\"\n",
    "\n",
    "    ### Critérios de extração:\n",
    "\n",
    "    - **Receptor de Estrogênio**: retorne se é \"POSITIVO\", \"NEGATIVO\" ou \"NÃO INFORMADO\".\n",
    "\n",
    "    - **Receptor de Progesterona**: retorne se é \"POSITIVO\", \"NEGATIVO\" ou \"NÃO INFORMADO\".\n",
    "\n",
    "    - **Status do HER-2**: retorne se o Status do HER-2 é \"NEGATIVO\", \"INCONCLUSIVO\", \"POSITIVO\" ou \"NÃO INFORMADO\". Com base no score seguindo as regras:\n",
    "    - \"HER-2 - ESCORE 0\" ou \"1+\" → \"NEGATIVO\"\n",
    "    - \"HER-2 - ESCORE 2+\" → \"INCONCLUSIVO\"\n",
    "    - \"HER-2 - ESCORE 3+\" → \"POSITIVO\"\n",
    "\n",
    "    - **Ki-67 (%)**: retorne o valor numérico da porcentagem de positividade do KI-67, caso seja um intervalo de valores retorne o intervalo com valor mínimo e valor máximo separado por um hífem.\n",
    "\n",
    "    - **Status do CK5/6**: retorne \"POSITIVO\", \"NEGATIVO\" ou \"NÃO INFORMADO\" do Status do CK5/6.\n",
    "\n",
    "    ### Saída esperada (dicionário Python válido):\n",
    "    ```python\n",
    "    { # Remover as chaves duplas aqui também\n",
    "    \"receptor_estrogeno\": \"POSITIVO\" | \"NEGATIVO\" |  \"NÃO INFORMADO\",\n",
    "    \"receptor_progesterona\": \"POSITIVO\" | \"NEGATIVO\" |  \"NÃO INFORMADO\",\n",
    "    \"status_her2\": \"POSITIVO\" | \"POSITIVO\" | \"INCONCLUSIVO\" |  \"NÃO INFORMADO\",\n",
    "    \"ki67_percentual\": float |  0,\n",
    "    \"status_ck5_6\": \"POSITIVO\" | \"NEGATIVO\" |  \"NÃO INFORMADO\"\n",
    "    }\n",
    "    \"\"\" \n",
    "    return prompt.strip()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fleury",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
