{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a59d99d",
   "metadata": {},
   "source": [
    "# Extração e Classificação de Dados Imunohistoquímicos de Câncer de Mama\n",
    "\n",
    "## Introdução Técnica\n",
    "\n",
    "Este notebook implementa um sistema de extração e classificação de dados a partir de laudos médicos de exames imunohistoquímicos de câncer de mama, utilizando modelos de linguagem de grande escala (LLMs) integrados com técnicas de processamento de linguagem natural.\n",
    "\n",
    "### Objetivo Principal\n",
    "\n",
    "O objetivo principal deste notebook é extrair informações estruturadas de laudos médicos não estruturados de exames imunohistoquímicos, para permitir a classificação molecular dos tumores de mama em subtipos clinicamente relevantes. Essa classificação é essencial para decisões terapêuticas e prognóstico das pacientes.\n",
    "\n",
    "### Tecnologias Utilizadas\n",
    "\n",
    "- **Processamento de Dados**: PySpark, pandas\n",
    "- **Aprendizado de Máquina**: Modelos de linguagem natural (LLMs) via API Databricks\n",
    "- **Processamento de Texto**: regex (expressões regulares)\n",
    "- **Monitoramento e Rastreamento**: MLflow\n",
    "- **Armazenamento de Dados**: Delta Lake\n",
    "- **Notificações e Alertas**: Octoops (Sentinel)\n",
    "- **Outras Bibliotecas**: numpy, json, tqdm, ast\n",
    "\n",
    "### Fluxo de Trabalho/Etapas Principais\n",
    "\n",
    "1. **Configuração do Ambiente**: Instalação de dependências e inicialização da sessão Spark\n",
    "2. **Carregamento de Dados**: Consulta SQL para extrair laudos específicos de imunohistoquímica\n",
    "3. **Preparação de Prompts**: Criação de templates para interação com o LLM\n",
    "4. **Processamento de Laudos**: Envio dos laudos ao LLM para extração de informações estruturadas\n",
    "5. **Extração de Biomarcadores**: Identificação de receptores hormonais (ER, PR), HER-2, Ki-67 e CK5/6\n",
    "6. **Classificação Molecular**: Determinação do subtipo molecular do tumor (Luminal A, Luminal B, HER-2, Triplo Negativo)\n",
    "7. **Avaliação da Qualidade**: Comparação das extrações do LLM com extrações por regex\n",
    "8. **Persistência de Dados**: Salvamento dos resultados em tabela Delta para uso posterior\n",
    "\n",
    "### Dados Envolvidos\n",
    "\n",
    "- **Fonte de Dados**: Tabela `refined.saude_preventiva.fleury_laudos`\n",
    "- **Tabela de Destino**: `refined.saude_preventiva.fleury_laudos_mama_imunohistoquimico`\n",
    "- **Tipos de Exame**: Exames com siglas \"IH-NEO\" e \"IHMAMA\" (imunohistoquímica)\n",
    "- **Filtros Aplicados**: \n",
    "  - `linha_cuidado = 'mama'`\n",
    "  - `sexo_cliente = 'F'`\n",
    "  - Presença dos termos \"mama\" e \"carcinoma\" no laudo\n",
    "- **Campos Extraídos**:\n",
    "  - `receptor_estrogeno`: Status do receptor de estrogênio (POSITIVO/NEGATIVO)\n",
    "  - `receptor_progesterona`: Status do receptor de progesterona (POSITIVO/NEGATIVO)\n",
    "  - `status_her2`: Status do receptor HER-2 (POSITIVO/INCONCLUSIVO/NEGATIVO)\n",
    "  - `ki67_percentual`: Valor percentual do marcador de proliferação Ki-67\n",
    "  - `status_ck5_6`: Status do marcador citoqueratina 5/6 (POSITIVO/NEGATIVO)\n",
    "\n",
    "### Resultados/Saídas Esperadas\n",
    "\n",
    "1. **DataFrame Enriquecido**: Laudos médicos com campos estruturados extraídos\n",
    "2. **Classificação Molecular**: Cada caso classificado em um subtipo molecular:\n",
    "   - Luminal A\n",
    "   - Luminal B\n",
    "   - Luminal com HER2 Positivo\n",
    "   - HER-2 Superexpresso\n",
    "   - Triplo Negativo\n",
    "3. **Métricas de Qualidade**: Avaliação da precisão das extrações automáticas\n",
    "4. **Persistência em Delta Lake**: Dados salvos para uso em pipelines downstream\n",
    "\n",
    "### Pré-requisitos\n",
    "\n",
    "- **Ambiente Databricks**: Com acesso ao endpoint do modelo de linguagem\n",
    "- **Dependências Python**: openai, pandas, pyspark, mlflow, octoops\n",
    "- **Permissões de Acesso**: Acesso à tabela de laudos médicos e permissão para escrita na tabela de destino\n",
    "- **Token de Autenticação**: Para acesso à API do modelo de linguagem\n",
    "\n",
    "### Considerações Importantes\n",
    "\n",
    "- **Privacidade de Dados**: Os dados são tratados conforme políticas de privacidade médica\n",
    "- **Validação Clínica**: As classificações moleculares automáticas devem ser validadas por especialistas\n",
    "- **Processamento Seletivo**: Apenas laudos contendo termos de carcinoma são processados pelo LLM\n",
    "- **Limitações**: A precisão da extração depende da qualidade e padronização dos laudos originais\n",
    "- **Avaliação de Qualidade**: Utiliza-se regex como pseudo-gold para avaliar a qualidade da extração do LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1509b562",
   "metadata": {},
   "source": [
    "# Extração de dado - Imunohistoquimico\n",
    "**Extrair os seguintes labels estruturados:**\n",
    "- Receptor de Estrógeno (categórica): POSITIVO ou NEGATIVO \n",
    "  - \"RECEPTOR DE ESTRÓGENO - POSITIVO \" \n",
    "  - \"RECEPTOR DE ESTRÓGENO – NEGATIVO\" \n",
    "\n",
    "- Receptor de Progesterona (categórica): POSITIVO ou NEGATIVO \n",
    "  - \"RECEPTOR DE PROGESTERONA - POSITIVO\" \n",
    "  - \"RECEPTOR DE PROGESTERONA - NEGATIVO\" \n",
    "\n",
    "- Status do HER-2 (categórica): Negativo, inconclusivo ou positivo \n",
    "  - \"HER-2 - ESCORE 0\" = Negativo \n",
    "  - \"HER-2 - ESCORE 1+\" = Negativo \n",
    "  - \"HER-2  -  ESCORE  2+\" = Inconclusivo \n",
    "  - \"HER-2  -  ESCORE  3+\" = Positivo \n",
    "\n",
    "- Porcentagem do Ki-67 (numérica):  \"KI-67 - POSITIVO EM 20% DAS CÉLULAS NEOPLÁSICAS\"\n",
    "  - Deve ser extraído esse número da porcentagem nessa frase \n",
    "\n",
    "- Status CK5/6 (categórica): POSITIVO ou NEGATIVO \n",
    "  - \"CK5/6 - POSITIVO \"ou \"CK5/6 - NEGATIVO\" \n",
    "  \n",
    "+ Para laudos que não possuem carcinoma, ou seja, casos negativos para câncer não devem se processados no LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c42bde6",
   "metadata": {},
   "source": [
    "## Instalação de Dependências\n",
    "\n",
    "Esta célula instala o pacote `octoops`, que é utilizado para monitoramento e alertas no ambiente Databricks. As outras dependências necessárias (como openai, tqdm, pandas e databricks-feature-store) estão comentadas pois provavelmente já estão instaladas no ambiente ou serão instaladas por outro processo.\n",
    "\n",
    "O pacote Octoops permite configurar alertas e notificações em caso de falhas no pipeline, sendo uma peça importante na infraestrutura de monitoramento do processo de extração de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf8d508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install openai -q\n",
    "# %pip install tqdm -q\n",
    "# %pip install pandarallel -q\n",
    "# %pip install databricks-feature-store -q\n",
    "# %pip install ace_tools -q\n",
    "%pip install octoops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffe1055",
   "metadata": {},
   "source": [
    "## Reinicialização do Python\n",
    "\n",
    "Após a instalação de novas dependências, é necessário reiniciar o interpretador Python para garantir que as bibliotecas recém-instaladas estejam disponíveis no ambiente de execução. O comando `dbutils.library.restartPython()` realiza essa reinicialização, garantindo que todas as dependências estejam carregadas corretamente antes de prosseguir com a execução do notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd464101",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40760035",
   "metadata": {},
   "source": [
    "## Importação de Bibliotecas e Configuração Inicial\n",
    "\n",
    "Esta célula realiza a importação de todas as bibliotecas necessárias para o processamento dos laudos e inicializa o ambiente Spark.\n",
    "\n",
    "**Objetivos principais:**\n",
    "1. Importar bibliotecas para manipulação de dados (PySpark, pandas, numpy)\n",
    "2. Importar bibliotecas para processamento de texto e regex\n",
    "3. Importar ferramentas para logging e monitoramento (mlflow)\n",
    "4. Importar bibliotecas para integração com APIs externas (openai)\n",
    "5. Inicializar a sessão Spark\n",
    "6. Obter o token de autenticação Databricks\n",
    "\n",
    "**Bibliotecas principais:**\n",
    "- **PySpark**: Framework para processamento distribuído de dados\n",
    "- **pandas/numpy**: Ferramentas para manipulação e análise de dados\n",
    "- **openai**: Cliente para comunicação com APIs de modelos de linguagem\n",
    "- **mlflow**: Plataforma para gerenciamento do ciclo de vida de modelos de ML\n",
    "- **tqdm**: Biblioteca para barras de progresso\n",
    "- **re**: Biblioteca para processamento de expressões regulares\n",
    "\n",
    "A sessão Spark é configurada com o nome \"LLM_Extractor\", e o token Databricks é obtido do contexto do notebook para autenticação com serviços externos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9518a2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import mlflow\n",
    "import time\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Any\n",
    "import openai\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "from databricks.feature_store import FeatureStoreClient\n",
    "from pyspark.sql import Row\n",
    "\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"LLM_Extractor\").getOrCreate()\n",
    "\n",
    "DATABRICKS_TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get() if dbutils.notebook.entry_point.getDbutils().notebook().getContext() is not None else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ff6f8e",
   "metadata": {},
   "source": [
    "## Desativação de Exibição MLflow no Notebook\n",
    "\n",
    "Esta célula desativa a exibição automática de informações do MLflow no notebook, configurando o comportamento do MLflow para evitar que ele adicione visualizações e saídas extras durante o rastreamento de experimentos. Isto é particularmente útil em notebooks de produção onde queremos controlar precisamente o que é exibido, sem poluição visual extra criada pelo rastreamento automático do MLflow.\n",
    "\n",
    "O comando `mlflow.tracing.disable_notebook_display()` evita que artefatos, métricas e parâmetros sejam automaticamente exibidos no notebook quando são registrados, mantendo a saída limpa e focada apenas no que está sendo explicitamente exibido pelo código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5c7275",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.tracing.disable_notebook_display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb24a4a0",
   "metadata": {},
   "source": [
    "## Configuração dos Parâmetros de Consulta\n",
    "\n",
    "Esta célula define os parâmetros de consulta para extrair laudos de imunohistoquímica específicos para câncer de mama. São configurados:\n",
    "\n",
    "1. **Tabela de Destino** (`table_imuno`): Define o nome da tabela Delta onde os resultados serão armazenados.\n",
    "\n",
    "2. **Cláusula WHERE para Incremento** (`where_clause`): Implementa uma estratégia de carga incremental, buscando apenas registros com timestamp mais recente que o último carregamento na tabela de destino.\n",
    "\n",
    "3. **Filtros de Extração** (`filtro_extracao`): Define critérios específicos para selecionar apenas laudos relevantes:\n",
    "   - Linha de cuidado específica para mama\n",
    "   - Pacientes do sexo feminino\n",
    "   - Siglas de exame específicas de imunohistoquímica (IH-NEO, IHMAMA)\n",
    "   - Presença dos termos \"mama\" e \"carcinoma\" nos laudos\n",
    "\n",
    "Esses filtros garantem que apenas os laudos de imunohistoquímica relevantes para câncer de mama feminino sejam processados, otimizando o uso de recursos computacionais e do modelo de linguagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aed17c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_imuno = \"refined.saude_preventiva.fleury_laudos_mama_imunohistoquimico\" \n",
    "\n",
    "where_clause = f\"\"\"\n",
    "WHERE\n",
    "    flr.`_datestamp` >= (\n",
    "        SELECT MAX(imuno._datestamp)\n",
    "        FROM {table_imuno} imuno\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    " \n",
    "filtro_extracao = \"\"\"\n",
    "    WHERE\n",
    "        linha_cuidado  = 'mama'\n",
    "        AND UPPER(sexo_cliente) = 'F'\n",
    "        AND sigla_exame IN (\"IH-NEO\", \"IHMAMA\")\n",
    "        AND laudo_tratado RLIKE '(?i)mama' AND laudo_tratado RLIKE '(?i)carcinoma'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8d1048",
   "metadata": {},
   "source": [
    "## Execução da Consulta SQL e Carregamento dos Dados\n",
    "\n",
    "Esta célula constrói e executa uma consulta SQL para extrair laudos de exames imunohistoquímicos relevantes para análise. \n",
    "\n",
    "**Processo detalhado:**\n",
    "\n",
    "1. **Construção da Consulta**: A consulta SQL é construída usando um Common Table Expression (CTE) chamado `base` que:\n",
    "   - Seleciona colunas relevantes da tabela principal de laudos (`refined.saude_preventiva.fleury_laudos`)\n",
    "   - Aplica o filtro incremental definido em `where_clause` para obter apenas registros novos\n",
    "   - Usa a cláusula `filtro_extracao` para filtrar apenas laudos de mama com carcinoma\n",
    "\n",
    "2. **Seleção de Campos**: A consulta extrai informações essenciais como:\n",
    "   - Identificadores (id_marca, id_unidade, id_cliente, id_ficha, etc.)\n",
    "   - Datas (dth_pedido, dth_resultado)\n",
    "   - Tipo de exame (sigla_exame)\n",
    "   - Conteúdo do laudo (laudo_tratado)\n",
    "   - Informações da linha de cuidado e sexo do cliente\n",
    "\n",
    "3. **Execução da Consulta**: A consulta é executada através do Spark SQL, criando um DataFrame `df_spk`\n",
    "\n",
    "4. **Visualização**: O DataFrame resultante é exibido na interface para verificação inicial dos dados carregados\n",
    "\n",
    "Esta etapa é fundamental para preparar o conjunto de dados que será processado pelo modelo de linguagem nas etapas subsequentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5930304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "WITH base AS (\n",
    "    SELECT\n",
    "        flr.id_marca,\n",
    "        flr.id_unidade,\n",
    "        flr.id_cliente, \n",
    "        flr.id_ficha,\n",
    "        flr.ficha,\n",
    "        flr.id_item, \n",
    "        flr.id_subitem, \n",
    "        flr.id_exame, \n",
    "        flr.dth_pedido,\n",
    "        flr.dth_resultado,\n",
    "        flr.sigla_exame,\n",
    "        flr.laudo_tratado,\n",
    "        flr.linha_cuidado,\n",
    "        flr.sexo_cliente,\n",
    "        flr.`_datestamp`\n",
    "    FROM refined.saude_preventiva.fleury_laudos flr    \n",
    "    {where_clause}\n",
    ")\n",
    "SELECT * FROM base\n",
    "{filtro_extracao}\n",
    "\"\"\"\n",
    "df_spk = spark.sql(query)\n",
    "display(df_spk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aaed21",
   "metadata": {},
   "source": [
    "## Verificação de Sexo e Tipos de Exame\n",
    "\n",
    "Esta célula executa uma verificação básica dos dados carregados, exibindo os valores distintos para duas colunas críticas: `sexo_cliente` e `sigla_exame`. \n",
    "\n",
    "O objetivo desta verificação é:\n",
    "1. Confirmar que apenas pacientes do sexo feminino (F) foram incluídos no dataset, conforme especificado no filtro\n",
    "2. Verificar quais siglas de exames de imunohistoquímica estão presentes nos dados carregados\n",
    "3. Validar que os filtros da consulta SQL foram aplicados corretamente\n",
    "\n",
    "Esta etapa de validação rápida ajuda a garantir a qualidade dos dados antes de prosseguir com análises mais detalhadas e o processamento pelo modelo de linguagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a881485",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_spk.select(\"sexo_cliente\", \"sigla_exame\").distinct())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef106dc",
   "metadata": {},
   "source": [
    "## Contagem de Registros\n",
    "\n",
    "Esta célula simples realiza a contagem do número total de registros no DataFrame `df_spk` carregado pela consulta SQL. O comentário \"# 3635\" indica que, em uma execução anterior, foram encontrados 3.635 registros.\n",
    "\n",
    "Conhecer o volume de dados é importante para:\n",
    "1. Estimar o tempo total de processamento pelo modelo de linguagem\n",
    "2. Verificar se o volume está de acordo com o esperado\n",
    "3. Avaliar a necessidade de processamento em lotes ou amostragem para testes\n",
    "\n",
    "Esta contagem serve como referência para monitoramento do pipeline em execuções futuras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d69fe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spk.count()\n",
    "# 3635"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b312858",
   "metadata": {},
   "source": [
    "## Funções para Processamento de Laudos com LLM\n",
    "\n",
    "Esta célula define funções essenciais para o processamento de laudos médicos utilizando um modelo de linguagem (LLM). São definidas quatro funções principais:\n",
    "\n",
    "### 1. `prompt_laudo`\n",
    "Define o template do prompt que será enviado ao LLM, instruindo-o a extrair informações específicas do laudo:\n",
    "- **Receptor de Estrogênio**: Status (POSITIVO/NEGATIVO)\n",
    "- **Receptor de Progesterona**: Status (POSITIVO/NEGATIVO)\n",
    "- **Status HER-2**: Classificado conforme escores (0/1+ como NEGATIVO, 2+ como INCONCLUSIVO, 3+ como POSITIVO)\n",
    "- **Ki-67 (%)**: Valor numérico da porcentagem de células positivas\n",
    "- **Status CK5/6**: Status (POSITIVO/NEGATIVO)\n",
    "\n",
    "### 2. `generate`\n",
    "Função principal que:\n",
    "- Recebe um laudo e uma descrição do agente\n",
    "- Formata o prompt com o conteúdo do laudo\n",
    "- Configura parâmetros do modelo (temperatura=0 para determinismo)\n",
    "- Trata erros de conexão com retentativas\n",
    "- Retorna a resposta do modelo\n",
    "\n",
    "### 3. `batch_generate`\n",
    "Função para processamento em lote que:\n",
    "- Divide os laudos em lotes menores\n",
    "- Processa cada laudo utilizando a função `generate`\n",
    "- Exibe uma barra de progresso usando `tqdm`\n",
    "- Retorna uma lista com as respostas do modelo\n",
    "\n",
    "### 4. `limpar_e_converter`\n",
    "Função para pós-processamento que:\n",
    "- Remove tags de código Markdown da resposta (```python, ```)\n",
    "- Converte o texto em JSON para um dicionário Python\n",
    "- Trata erros de conversão, fornecendo valores padrão\n",
    "\n",
    "Estas funções formam o núcleo do sistema de extração de informações, transformando o texto não estruturado dos laudos em dados estruturados que podem ser analisados programaticamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267c4b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_laudo(laudo_texto: str) -> str:\n",
    "    prompt = f\"\"\"A seguir está um laudo médico de mamografia, conforme indicado abaixo. Se alguma informação não estiver presente no texto, retorne \"NÃO INFORMADO\". Sempre retorne apenas o dicionário Python.\n",
    "\n",
    "    Laudo clínico:\n",
    "    \\\"\\\"\\\"{laudo_texto}\\\"\\\"\\\"\n",
    "\n",
    "    ### Critérios de extração:\n",
    "\n",
    "    - **Receptor de Estrogênio**: retorne se é \"POSITIVO\", \"NEGATIVO\" ou \"NÃO INFORMADO\".\n",
    "\n",
    "    - **Receptor de Progesterona**: retorne se é \"POSITIVO\", \"NEGATIVO\" ou \"NÃO INFORMADO\".\n",
    "\n",
    "    - **Status do HER-2**: retorne se o Status do HER-2 é \"NEGATIVO\", \"INCONCLUSIVO\", \"POSITIVO\" ou \"NÃO INFORMADO\". Com base no score seguindo as regras:\n",
    "    - \"HER-2 - ESCORE 0\" ou \"1+\" → \"NEGATIVO\"\n",
    "    - \"HER-2 - ESCORE 2+\" → \"INCONCLUSIVO\"\n",
    "    - \"HER-2 - ESCORE 3+\" → \"POSITIVO\"\n",
    "\n",
    "    - **Ki-67 (%)**: retorne o valor numérico da porcentagem de positividade do KI-67.\n",
    "\n",
    "    - **Status do CK5/6**: retorne \"POSITIVO\", \"NEGATIVO\" ou \"NÃO INFORMADO\" do Status do CK5/6.\n",
    "\n",
    "    ### Saída esperada (dicionário Python válido):\n",
    "    ```python\n",
    "    {{\n",
    "    \"receptor_estrogeno\": \"POSITIVO\" | \"NEGATIVO\" |  \"NÃO INFORMADO\",\n",
    "    \"receptor_progesterona\": \"POSITIVO\" | \"NEGATIVO\" |  \"NÃO INFORMADO\",\n",
    "    \"status_her2\": \"POSITIVO\" | \"POSITIVO\" | \"INCONCLUSIVO\" |  \"NÃO INFORMADO\",\n",
    "    \"ki67_percentual\": float |  0,\n",
    "    \"status_ck5_6\": \"POSITIVO\" | \"NEGATIVO\" |  \"NÃO INFORMADO\"\n",
    "    }}\n",
    "    ```\n",
    "    \"\"\"\n",
    "    return prompt.strip()\n",
    "\n",
    "def generate(descricao_agente:str, laudo:str, llm_client) -> str:\n",
    "    \"\"\"\n",
    "    Gera o resultado da análise de um laudo\n",
    "    Params:\n",
    "        descricao_agente: descricao do agente que a LLM representa (primeira mensagem enviada à LLM)\n",
    "        prompt: prompt base que será utilizado para gerar a análise\n",
    "        laudo: laudo a ser analisado (incluido dentro do prompt)\n",
    "        llm_client: cliente da API da LLM\n",
    "    Return:\n",
    "        response_message: resposta da LLM\n",
    "    \"\"\"\n",
    "    prompt = prompt_laudo(laudo)\n",
    "    messages = [\n",
    "        # Utilizamos o primeiro prompt para contextualizar o llm do que ele deve fazer. \n",
    "        # No exemplo utilizamos a abordagem Role, Task, Output, Prompting.\n",
    "        # Mas sintam-se a vontade para alterar de acordo com a necessidade\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": descricao_agente\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ]\n",
    "    model_params = {\n",
    "        \"model\": \"databricks-llama-4-maverick\",\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0,\n",
    "        \"max_tokens\": 4000,\n",
    "        \"top_p\": 0.75,\n",
    "        \"frequency_penalty\": 0,\n",
    "        \"presence_penalty\": 0\n",
    "    }\n",
    "    connection_retry = 0\n",
    "    while connection_retry < 3:\n",
    "        try:\n",
    "            response = llm_client.chat.completions.create(**model_params)\n",
    "            response_message = response.choices[0].message.content\n",
    "            break\n",
    "        # TODO: verificar se a excessao é de conexao\n",
    "        except (ConnectionError, TimeoutError) as e:\n",
    "            connection_retry += 1\n",
    "            print(\"Sem reposta do modelo\")\n",
    "            print(str(e))\n",
    "            print(\"Tentando novamente...\")\n",
    "            time.sleep(0.1)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    if connection_retry >= 3:\n",
    "        response_message = ''\n",
    "    \n",
    "    return response_message\n",
    "\n",
    "\n",
    "def batch_generate(descricao_agente, laudos, llm_client, batch_size=25):\n",
    "    responses = []\n",
    "    \n",
    "    llm_client = openai.OpenAI(\n",
    "        api_key=DATABRICKS_TOKEN,\n",
    "        base_url=\"https://dbc-d80f50a9-af23.cloud.databricks.com/serving-endpoints\"\n",
    "    )\n",
    "    \n",
    "    # Dividir em lotes\n",
    "    for i in range(0, len(laudos), batch_size):\n",
    "        laudos_batch = laudos[i:i+batch_size]\n",
    "        for laudo in tqdm(laudos_batch, desc=f\"Processando lote {i//batch_size + 1}\", total=len(laudos_batch)):\n",
    "            responses.append(generate(descricao_agente, laudo, llm_client))\n",
    "    \n",
    "    return responses\n",
    "\n",
    "def limpar_e_converter(item):\n",
    "    try:\n",
    "        item_limpo = re.sub(r\"```(?:python)?\", \"\", item).replace(\"```\", \"\").strip()\n",
    "        return json.loads(item_limpo)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao converter resposta: {e}\")\n",
    "        return {\n",
    "            \"receptor_estrogeno\": \"NÃO INFORMADO\",\n",
    "            \"receptor_progesterona\": \"NÃO INFORMADO\",\n",
    "            \"status_her2\": \"NÃO INFORMADO\",\n",
    "            \"ki67_percentual\": \"NÃO INFORMADO\",\n",
    "            \"status_ck5_6\": \"NÃO INFORMADO\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a83e21",
   "metadata": {},
   "source": [
    "## Funções de Extração Heurística (Pseudo-Gold)\n",
    "\n",
    "Esta célula define um conjunto de funções para extração heurística de informações dos laudos médicos, utilizando expressões regulares. Estas extrações servem como um \"pseudo-gold standard\" para avaliar o desempenho do LLM.\n",
    "\n",
    "### Funções de Extração Individual\n",
    "\n",
    "1. **`extrai_receptor_estrogeno`**: Identifica o status do receptor de estrogênio\n",
    "   - Reconhece padrões como \"receptor de estrogênio: positivo\"\n",
    "   - Identifica abreviações como \"ER+\" e \"ER-\"\n",
    "\n",
    "2. **`extrai_receptor_progesterona`**: Identifica o status do receptor de progesterona\n",
    "   - Reconhece padrões como \"receptor de progesterona: positivo\" \n",
    "   - Identifica abreviações como \"PR+\" e \"PR-\"\n",
    "\n",
    "3. **`extrai_status_her2`**: Determina o status do HER-2 baseado em escores\n",
    "   - Processa padrões como \"HER-2 ESCORE X+\"\n",
    "   - Mapeia escores 0/1+ como \"NEGATIVO\", 2+ como \"INCONCLUSIVO\", 3+ como \"POSITIVO\"\n",
    "\n",
    "4. **`extrai_ki67_percentual`**: Extrai o valor percentual do Ki-67\n",
    "   - Processa padrões como \"Ki-67: 20%\"\n",
    "   - Converte para valor numérico (float)\n",
    "\n",
    "5. **`extrai_status_ck5_6`**: Identifica o status do CK5/6\n",
    "   - Reconhece padrões como \"CK5/6 - POSITIVO\"\n",
    "   - Identifica abreviações como \"CK5/6+\" e \"CK5/6-\"\n",
    "\n",
    "### Função de Avaliação\n",
    "\n",
    "**`avalia_extracao_sem_ground_truth_imuno`**: Função chave que compara extrações do LLM com extrações heurísticas\n",
    "   - Gera extrações heurísticas para todos os campos\n",
    "   - Compara campo a campo os resultados do modelo vs. heurísticas\n",
    "   - Produz métricas de avaliação por campo (acertou/não acertou)\n",
    "\n",
    "Este sistema de avaliação permite medir a qualidade das extrações do LLM sem necessidade de anotação manual de dados, sendo uma ferramenta crucial para validação contínua do pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c3191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "#import ace_tools as tools\n",
    "\n",
    "# ==============================================\n",
    "# Funções de extração heurística (pseudo-gold) para o novo prompt\n",
    "# ==============================================\n",
    "\n",
    "def extrai_receptor_estrogeno(txt: str) -> str:\n",
    "    \"\"\"\n",
    "    Extrai o status de Receptor de Estrogênio: valores possíveis\n",
    "    \"POSITIVO\", \"NEGATIVO\" ou retorna \"NÃO INFORMADO\".\n",
    "    \"\"\"\n",
    "    txt_lower = txt.lower()\n",
    "    # Padrões comuns: \"receptor de estrogênio: positivo\" ou \"er+: positivo\" etc.\n",
    "    if re.search(r\"receptor\\s+de\\s+estrog[eê]genio\\s*[:\\-]?\\s*positivo\", txt_lower):\n",
    "        return \"POSITIVO\"\n",
    "    if re.search(r\"receptor\\s+de\\s+estrog[eê]genio\\s*[:\\-]?\\s*negativo\", txt_lower):\n",
    "        return \"NEGATIVO\"\n",
    "    # Abreviações: \"ER+\" / \"ER-\"\n",
    "    if re.search(r\"\\ber\\s*[\\+]\\b\", txt, flags=re.IGNORECASE):\n",
    "        return \"POSITIVO\"\n",
    "    if re.search(r\"\\ber\\s*[\\-]\\b\", txt, flags=re.IGNORECASE):\n",
    "        return \"NEGATIVO\"\n",
    "    return \"NÃO INFORMADO\"\n",
    "\n",
    "def extrai_receptor_progesterona(txt: str) -> str:\n",
    "    \"\"\"\n",
    "    Extrai o status de Receptor de Progesterona: valores possíveis\n",
    "    \"POSITIVO\", \"NEGATIVO\" ou retorna \"NÃO INFORMADO\".\n",
    "    \"\"\"\n",
    "    txt_lower = txt.lower()\n",
    "    if re.search(r\"receptor\\s+de\\s+progesterona\\s*[:\\-]?\\s*positivo\", txt_lower):\n",
    "        return \"POSITIVO\"\n",
    "    if re.search(r\"receptor\\s+de\\s+progesterona\\s*[:\\-]?\\s*negativo\", txt_lower):\n",
    "        return \"NEGATIVO\"\n",
    "    # Abreviações: \"PR+\" / \"PR-\"\n",
    "    if re.search(r\"\\bpr\\s*[\\+]\\b\", txt, flags=re.IGNORECASE):\n",
    "        return \"POSITIVO\"\n",
    "    if re.search(r\"\\bpr\\s*[\\-]\\b\", txt, flags=re.IGNORECASE):\n",
    "        return \"NEGATIVO\"\n",
    "    return \"NÃO INFORMADO\"\n",
    "\n",
    "def extrai_status_her2(txt: str) -> str:\n",
    "    \"\"\"\n",
    "    Extrai o Status do HER-2 baseado em termos de score:\n",
    "    - \"HER-2 - ESCORE 0\" ou \"1+\" → \"NEGATIVO\"\n",
    "    - \"HER-2 - ESCORE 2+\" → \"INCONCLUSIVO\"\n",
    "    - \"HER-2 - ESCORE 3+\" → \"POSITIVO\"\n",
    "    \"\"\"\n",
    "    txt_lower = txt.lower()\n",
    "    # Primeiro, busca padrão \"her-2 ... escore X+\"\n",
    "    m = re.search(r\"her[-\\s]?2.*?escore\\s*[:\\-]?\\s*([0-3]\\+?)\", txt_lower, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        score = m.group(1)\n",
    "        if score.startswith(\"0\") or score == \"1+\":\n",
    "            return \"NEGATIVO\"\n",
    "        if score == \"2+\":\n",
    "            return \"INCONCLUSIVO\"\n",
    "        if score == \"3+\":\n",
    "            return \"POSITIVO\"\n",
    "    # Outra forma: \"her2 3+\" isolado\n",
    "    m2 = re.search(r\"\\bher[-]?2\\s*[:\\-]?\\s*([0-3]\\+)\\b\", txt_lower, flags=re.IGNORECASE)\n",
    "    if m2:\n",
    "        score2 = m2.group(1)\n",
    "        if score2 == \"1+\":\n",
    "            return \"NEGATIVO\"\n",
    "        if score2 == \"2+\":\n",
    "            return \"INCONCLUSIVO\"\n",
    "        if score2 == \"3+\":\n",
    "            return \"POSITIVO\"\n",
    "    return \"NÃO INFORMADO\"\n",
    "\n",
    "def extrai_ki67_percentual(txt: str) -> float:\n",
    "    \"\"\"\n",
    "    Extrai o valor de Ki-67 em porcentagem. \n",
    "    Exemplo no texto: \"Ki-67: 20%\", \"Ki 67 15 %\", etc.\n",
    "    Se não encontrar, retorna 0.0.\n",
    "    \"\"\"\n",
    "    m = re.search(r\"ki[-\\s]?67.*?[:\\-]?\\s*(\\d{1,3}(?:\\.\\d+)?)\\s*%\", txt, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        try:\n",
    "            return float(m.group(1))\n",
    "        except ValueError:\n",
    "            return 0.0\n",
    "    return 0.0\n",
    "\n",
    "def extrai_status_ck5_6(txt: str) -> str:\n",
    "    \"\"\"\n",
    "    Extrai o status do CK5/6: \"POSITIVO\", \"NEGATIVO\" ou retorna \"NÃO INFORMADO\".\n",
    "    \"\"\"\n",
    "    txt_lower = txt.lower()\n",
    "    if re.search(r\"ck5\\s*\\/\\s*6.*?[:\\-]?\\s*positivo\", txt_lower):\n",
    "        return \"POSITIVO\"\n",
    "    if re.search(r\"ck5\\s*\\/\\s*6.*?[:\\-]?\\s*negativo\", txt_lower):\n",
    "        return \"NEGATIVO\"\n",
    "    # Abreviações: \"CK5/6+\" ou \"CK5/6-\"\n",
    "    if re.search(r\"\\bck5\\s*\\/\\s*6\\s*[\\+]\\b\", txt, flags=re.IGNORECASE):\n",
    "        return \"POSITIVO\"\n",
    "    if re.search(r\"\\bck5\\s*\\/\\s*6\\s*[\\-]\\b\", txt, flags=re.IGNORECASE):\n",
    "        return \"NEGATIVO\"\n",
    "    return \"NÃO INFORMADO\"\n",
    "\n",
    "# ==============================================\n",
    "# Função de avaliação sem ground truth completo (novo conjunto de campos)\n",
    "# ==============================================\n",
    "\n",
    "def avalia_extracao_sem_ground_truth_imuno(laudo_texto: str, json_modelo: dict):\n",
    "    \"\"\"\n",
    "    Gera pseudo-gold (json_heu) para os campos do novo prompt\n",
    "    e compara com json_modelo (saída da IA).\n",
    "    Retorna:\n",
    "      - json_heu: dicionário com valores heurísticos\n",
    "      - comparacoes: dicionário que, para cada campo, traz:\n",
    "          * valor_heu\n",
    "          * valor_mod\n",
    "          * acertou (boolean)\n",
    "    \"\"\"\n",
    "    # 1. Gera pseudo-gold (json_heu)\n",
    "    rei = extrai_receptor_estrogeno(laudo_texto)\n",
    "    rpr = extrai_receptor_progesterona(laudo_texto)\n",
    "    her = extrai_status_her2(laudo_texto)\n",
    "    ki6 = extrai_ki67_percentual(laudo_texto)\n",
    "    ck6 = extrai_status_ck5_6(laudo_texto)\n",
    "\n",
    "    json_heu = {\n",
    "        \"receptor_estrogeno\": rei,\n",
    "        \"receptor_progesterona\": rpr,\n",
    "        \"status_her2\": her,\n",
    "        \"ki67_percentual\": ki6,\n",
    "        \"status_ck5_6\": ck6\n",
    "    }\n",
    "\n",
    "    # 2. Prepara json_modelo: se não for dict, converte para dict vazio\n",
    "    if not isinstance(json_modelo, dict):\n",
    "        json_modelo = {}\n",
    "\n",
    "    # 3. Comparações campo a campo\n",
    "    comparacoes = {}\n",
    "\n",
    "    # Campos categóricos (strings)\n",
    "    for campo in [\"receptor_estrogeno\", \"receptor_progesterona\", \"status_her2\", \"status_ck5_6\"]:\n",
    "        val_heu = json_heu[campo]\n",
    "        val_mod = json_modelo.get(campo, \"NÃO INFORMADO\")\n",
    "        comparacoes[campo] = {\n",
    "            \"valor_heu\": val_heu,\n",
    "            \"valor_mod\": val_mod,\n",
    "            \"acertou\": (val_heu == val_mod)\n",
    "        }\n",
    "\n",
    "    # Campo Ki-67 (%)\n",
    "    val_heu_ki = json_heu[\"ki67_percentual\"]\n",
    "    try:\n",
    "        val_mod_ki = float(json_modelo.get(\"ki67_percentual\", 0))\n",
    "    except (ValueError, TypeError):\n",
    "        val_mod_ki = 0.0\n",
    "    comparacoes[\"ki67_percentual\"] = {\n",
    "        \"valor_heu\": val_heu_ki,\n",
    "        \"valor_mod\": val_mod_ki,\n",
    "        \"acertou\": (val_heu_ki == val_mod_ki)\n",
    "    }\n",
    "\n",
    "    return json_heu, comparacoes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c46b8b5",
   "metadata": {},
   "source": [
    "## Função Auxiliar para Parsing de JSON\n",
    "\n",
    "Esta célula define uma função de utilidade para lidar com o parsing de strings JSON. A função `parse_json_string` é responsável por converter strings que representam dicionários Python para objetos Python reais.\n",
    "\n",
    "**Objetivo da Célula:**\n",
    "- Fornecer uma função segura para converter strings que representam estruturas de dados Python em objetos Python efetivos\n",
    "- Tratar graciosamente casos onde a conversão falha\n",
    "\n",
    "**Detalhamento da Função:**\n",
    "- Verifica se o input já é uma string (caso não seja, retorna o próprio input)\n",
    "- Utiliza `ast.literal_eval` para converter a string em um objeto Python\n",
    "- Se a conversão falhar (por erro de formato, por exemplo), retorna um dicionário vazio\n",
    "\n",
    "Esta função é especialmente importante para garantir que as respostas do modelo de linguagem, que são retornadas como texto, possam ser tratadas como estruturas de dados Python para análise e validação posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2275832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_string(s):\n",
    "    if isinstance(s, str):\n",
    "        try:\n",
    "            return ast.literal_eval(s)\n",
    "        except Exception:\n",
    "            return {}\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f700dc35",
   "metadata": {},
   "source": [
    "## Função de Agregação de Resultados\n",
    "\n",
    "Esta célula define uma função especializada para agregar resultados de avaliação de múltiplos laudos, calculando métricas de desempenho para cada campo extraído.\n",
    "\n",
    "**Objetivo da Função:**\n",
    "`agrega_resultados_dinamico` processa uma lista de comparações (gerada pela função `avalia_extracao_sem_ground_truth_imuno`) e calcula estatísticas agregadas, incluindo:\n",
    "- Número total de acertos por campo\n",
    "- Total de laudos analisados\n",
    "- Taxa de acerto (acertos/total) para cada campo\n",
    "\n",
    "**Detalhamento da Implementação:**\n",
    "1. Utiliza `Counter` para contabilizar os acertos por campo de forma eficiente\n",
    "2. Itera por todas as comparações e todos os campos dentro de cada comparação\n",
    "3. Verifica o atributo \"acertou\" de cada campo para contabilizar os acertos\n",
    "4. Gera um dicionário estruturado com as estatísticas de cada campo\n",
    "5. Garante que todos os campos estão representados no resultado, mesmo os que não tiveram acertos\n",
    "\n",
    "**Características Importantes:**\n",
    "- É uma função genérica que não assume um conjunto fixo de campos, podendo processar qualquer estrutura de comparações\n",
    "- Trata adequadamente o caso de divisão por zero quando não há laudos\n",
    "- Mantém consistência na estrutura de saída para facilitar análises posteriores\n",
    "\n",
    "Esta função é crucial para avaliar quantitativamente o desempenho do modelo de extração em todo o conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd940ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def agrega_resultados_dinamico(lista_comparacoes):\n",
    "    \"\"\"\n",
    "    Agraga resultados de uma lista de dicionários de comparações, retornando para cada campo:\n",
    "      - acertos: número de vezes que 'acertou' == True\n",
    "      - total: número total de laudos (len(lista_comparacoes))\n",
    "      - taxa_acerto: acertos / total (ou 0.0 se total == 0)\n",
    "    \n",
    "    Suporta qualquer conjunto de chaves em cada dict, desde que cada valor seja outro dict contendo a chave 'acertou'.\n",
    "    \"\"\"\n",
    "    total_laudos = len(lista_comparacoes)\n",
    "    acertos_por_campo = Counter()\n",
    "\n",
    "    # Para cada comparação, percorremos todas as chaves e contamos os acertos\n",
    "    for comp in lista_comparacoes:\n",
    "        for campo, info in comp.items():\n",
    "            # Supondo que info seja um dict com a chave \"acertou\"\n",
    "            if info.get(\"acertou\", False):\n",
    "                acertos_por_campo[campo] += 1\n",
    "\n",
    "    # Monta o dicionário de saída\n",
    "    resultado = {}\n",
    "    for campo, acertos in acertos_por_campo.items():\n",
    "        resultado[campo] = {\n",
    "            \"acertos\": acertos,\n",
    "            \"total\": total_laudos,\n",
    "            \"taxa_acerto\": (acertos / total_laudos) if total_laudos > 0 else 0.0\n",
    "        }\n",
    "\n",
    "    # É possível que exista algum campo em alguma comparação que nunca teve 'acertou' == True.\n",
    "    # Se quisermos incluir também esses campos (com acertos = 0), podemos varrer as chaves da primeira entrada:\n",
    "    if lista_comparacoes:\n",
    "        primeira = lista_comparacoes[0]\n",
    "        for campo in primeira.keys():\n",
    "            if campo not in resultado:\n",
    "                resultado[campo] = {\n",
    "                    \"acertos\": 0,\n",
    "                    \"total\": total_laudos,\n",
    "                    \"taxa_acerto\": 0.0\n",
    "                }\n",
    "\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfee258",
   "metadata": {},
   "source": [
    "## Verificação de Contagem de Registros\n",
    "\n",
    "Esta célula executa uma verificação rápida de quantos registros estão disponíveis para processamento no DataFrame `df_spk`. \n",
    "\n",
    "Esta contagem é importante para:\n",
    "1. Verificar se temos dados para processar\n",
    "2. Dimensionar o tempo de execução esperado\n",
    "3. Avaliar se o processo de filtragem nos retornou um conjunto de dados compatível com o esperado\n",
    "\n",
    "O valor retornado será o número total de laudos de imunohistoquímica de mama com menção a carcinoma que estão disponíveis para processamento pelo modelo de linguagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7946b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spk.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d37ac1",
   "metadata": {},
   "source": [
    "## Extração de Marcadores com LLM e Classificação Molecular\n",
    "\n",
    "Esta célula implementa o core do pipeline de processamento dos laudos, envolvendo a extração de informações estruturadas dos laudos médicos utilizando um modelo de linguagem e a subsequente classificação molecular dos casos de câncer. Este é o ponto central do notebook, onde o processamento efetivo dos dados acontece.\n",
    "\n",
    "**Objetivo:**\n",
    "1. Configurar o cliente LLM para comunicação com o endpoint Databricks\n",
    "2. Processar os laudos médicos para extração de biomarcadores \n",
    "3. Classificar os tumores em subtipos moleculares com base nos biomarcadores extraídos\n",
    "\n",
    "**Fluxo de Processamento:**\n",
    "1. **Inicialização do Cliente LLM**: Configura o cliente OpenAI para se comunicar com o endpoint Databricks\n",
    "2. **Definição de Persona**: Define o papel do modelo como \"médico oncologista especialista\"\n",
    "3. **Amostragem de Dados**: Limita a análise a 15 registros para processamento local\n",
    "4. **Processamento em Lote**: Envia os laudos para o modelo em lotes\n",
    "5. **Pós-processamento**: Converte as respostas do modelo em formato estruturado\n",
    "6. **Classificação Molecular**: Aplica regras específicas para determinar o subtipo molecular:\n",
    "   - **Luminal A**: ER+ ou PR+, HER2-, Ki-67 < 14%\n",
    "   - **Luminal B**: ER+ ou PR+, HER2-, Ki-67 ≥ 14%\n",
    "   - **Luminal com HER2 Positivo**: ER+ ou PR+, HER2+\n",
    "   - **HER-2 Superexpresso**: ER-, PR-, HER2+\n",
    "   - **Triplo Negativo**: ER-, PR-, HER2-\n",
    "\n",
    "A célula contém também código comentado que representa versões anteriores ou alternativas do pipeline, incluindo opções para persistência dos dados e registro de métricas, que podem ser descomentadas conforme necessário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54575000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, LongType, IntegerType\n",
    "from pyspark.sql.functions import from_json, col\n",
    "from pyspark.sql.functions import col, pandas_udf\n",
    "from pyspark.sql.types import StringType\n",
    "import pandas as pd\n",
    "\n",
    "# realizar extração\n",
    "\n",
    "if df_spk.count() > 0:\n",
    "    llm_client = openai.OpenAI(api_key=DATABRICKS_TOKEN,\n",
    "                           base_url=\"https://dbc-d80f50a9-af23.cloud.databricks.com/serving-endpoints\"\n",
    "                           )\n",
    "    descricao_agente = \"Atue como um médico oncologista especialista em laudos de mamografia.\"\n",
    "\n",
    "    # Coleta os dados localmente\n",
    "    df_local = df_spk.select(\"ficha\",\"id_item\",\"id_subitem\",\"id_cliente\",\"dth_pedido\",\"dth_resultado\", \"sigla_exame\", \"laudo_tratado\",\"linha_cuidado\",\"_datestamp\").limited(15).toPandas()\n",
    "  \n",
    "\n",
    "    # Aplica o LLM localmente\n",
    "    df_local[\"resposta_llm\"] = batch_generate(descricao_agente, df_local[\"laudo_tratado\"].tolist(), llm_client, batch_size=100)\n",
    "    df_local= df_local.join(df_local[\"resposta_llm\"].apply(limpar_e_converter).apply(pd.Series)) \n",
    "\n",
    "    # Adiciona as respostas ao DataFrame local\n",
    "    #df_local[\"resposta_llm\"] = respostas_limpa\n",
    "\n",
    "    # Converte de volta para Spark   \n",
    "    df_respostas = spark.createDataFrame(df_local) \n",
    "    display(df_respostas)\n",
    "\n",
    "    # # Faz join com o DataFrame original para manter todas as colunas\n",
    "    # df_final = df_spk.join(df_respostas.select(\"ficha\",\"id_item\",\"id_subitem\", \"resposta_llm\"), on=[\"ficha\",\"id_item\",\"id_subitem\"], how=\"inner\")\n",
    "\n",
    "    # # Definir estrutura\n",
    "    # schema_resposta = StructType([\n",
    "    # StructField(\"receptor_estrogeno\", StringType(), True),\n",
    "    # StructField(\"receptor_progesterona\", StringType(), True),\n",
    "    # StructField(\"status_her2\", StringType(), True),\n",
    "    # StructField(\"ki67_percentual\", DoubleType(), True),\n",
    "    # StructField(\"status_ck5_6\", DoubleType(), True),\n",
    "    # ])\n",
    "\n",
    "    # df_final_expanded = df_final.withColumn(\"resposta_struct\", col(\"resposta_llm\"))\n",
    "\n",
    "    # # expandir resultado llma para colunas\n",
    "\n",
    "    # df_final_expanded = df_final_expanded.select(\n",
    "    # \"*\",\n",
    "    # col(\"resposta_struct.receptor_estrogeno\").alias(\"receptor_estrogeno\"),\n",
    "    # col(\"resposta_struct.receptor_progesterona\").alias(\"receptor_progesterona\"),\n",
    "    # col(\"resposta_struct.status_her2\").alias(\"status_her2\"),\n",
    "    # col(\"resposta_struct.ki67_percentual\").alias(\"ki67_percentual\"),\n",
    "    # col(\"resposta_struct.status_ck5_6\").alias(\"status_ck5_6\"),\n",
    "    # ).drop(\"resposta_struct\")\n",
    "\n",
    "    #display(df_final_expanded)\n",
    "\n",
    "    # a partir dos dados extraídos definir uma classificação final\n",
    "    df_final_classif = df_respostas.withColumn(\n",
    "            \"categoria_final\",\n",
    "            F.when(\n",
    "                (\n",
    "                    ((F.col(\"receptor_estrogeno\") == \"POSITIVO\") | (F.col(\"receptor_progesterona\") == \"POSITIVO\")) &\n",
    "                    (F.col(\"status_her2\") == \"NEGATIVO\") &\n",
    "                    (F.col(\"ki67_percentual\") < 14)\n",
    "                ),\n",
    "                \"Luminal A\"\n",
    "            ).when(\n",
    "                (\n",
    "                    ((F.col(\"receptor_estrogeno\") == \"POSITIVO\") | (F.col(\"receptor_progesterona\") == \"POSITIVO\")) &\n",
    "                    (F.col(\"status_her2\") == \"NEGATIVO\") &\n",
    "                    (F.col(\"ki67_percentual\") >= 14)\n",
    "                ),\n",
    "                \"Luminal B\"\n",
    "            ).when(\n",
    "                (\n",
    "                    ((F.col(\"receptor_estrogeno\") == \"POSITIVO\") | (F.col(\"receptor_progesterona\") == \"POSITIVO\")) &\n",
    "                    (F.col(\"status_her2\") == \"POSITIVO\")\n",
    "                ),\n",
    "                \"Luminal com HER2 Positivo\"\n",
    "            ).when(\n",
    "                (\n",
    "                    (F.col(\"receptor_estrogeno\") == \"NEGATIVO\") &\n",
    "                    (F.col(\"receptor_progesterona\") == \"NEGATIVO\") &\n",
    "                    (F.col(\"status_her2\") == \"POSITIVO\")\n",
    "                ),\n",
    "                \"HER-2 Superexpresso\"\n",
    "            ).when(\n",
    "                (\n",
    "                    (F.col(\"receptor_estrogeno\") == \"NEGATIVO\") &\n",
    "                    (F.col(\"receptor_progesterona\") == \"NEGATIVO\") &\n",
    "                    (F.col(\"status_her2\") == \"NEGATIVO\")\n",
    "                ),\n",
    "                \"Triplo Negativo\"\n",
    "            ).otherwise(\"Indefinido\")\n",
    "        )\n",
    "\n",
    "    display(df_final_classif)\n",
    "\n",
    "    # schema_resposta = StructType([\n",
    "    # StructField(\"receptor_estrogeno\", StringType(), True),\n",
    "    # StructField(\"receptor_progesterona\", StringType(), True),\n",
    "    # StructField(\"status_her2\", StringType(), True),\n",
    "    # StructField(\"ki67_percentual\", StringType(), True),\n",
    "    # StructField(\"status_ck5_6\", StringType(), True),\n",
    "    # ])\n",
    "\n",
    "    # df_final_expanded = df_final.withColumn(\"resposta_struct\", from_json(col(\"resposta_llm\"), schema_resposta))\n",
    "\n",
    "    # df_final_expanded = df_final_expanded.select(\n",
    "    # \"*\",\n",
    "    # col(\"resposta_struct.receptor_estrogeno\").alias(\"receptor_estrogeno\"),\n",
    "    # col(\"resposta_struct.receptor_progesterona\").alias(\"receptor_progesterona\"),\n",
    "    # col(\"resposta_struct.status_her2\").alias(\"status_her2\"),\n",
    "    # col(\"resposta_struct.ki67_percentual\").alias(\"ki67_percentual\"),\n",
    "    # col(\"resposta_struct.status_ck5_6\").alias(\"status_ck5_6\"),\n",
    "    # ).drop(\"resposta_llm\", \"resposta_struct\")\n",
    "\n",
    "    # display(df_final_expanded) \n",
    "\n",
    "\n",
    "    # ###################### Apenas para testes #################\n",
    "    # df_imunohistoquimico = df_imunohistoquimico.limit(100)\n",
    "    # ###########################################################\n",
    "\n",
    "    # rows = df_spk.select(\"laudo_tratado\").collect()\n",
    "    # laudos = [row.laudo_tratado for row in rows]\n",
    "\n",
    "    # respostas = batch_generate(descricao_agente, laudos, llm_client, batch_size=300)\n",
    "\n",
    "    # lista_dicts = [limpar_e_converter(item) for item in respostas]\n",
    "\n",
    "    # schema = StructType([\n",
    "    #     StructField(\"receptor_estrogeno\", StringType(), True),\n",
    "    #     StructField(\"receptor_progesterona\", StringType(), True),\n",
    "    #     StructField(\"status_her2\", StringType(), True),\n",
    "    #     StructField(\"ki67_percentual\", StringType(), True),\n",
    "    #     StructField(\"status_ck5_6\", StringType(), True),\n",
    "    # ])\n",
    "\n",
    "    # df_lista = spark.createDataFrame(lista_dicts, schema=schema)\n",
    "\n",
    "\n",
    "    # w = Window.orderBy(F.lit(1))\n",
    "\n",
    "    # df_imuno_indexed = (\n",
    "    #     df_imunohistoquimico\n",
    "    #     .withColumn(\"row_id\", F.row_number().over(w) - 1)  # subtrai 1 para ficar zero‐based\n",
    "    # )\n",
    "\n",
    "    # df_lista_indexed = (\n",
    "    #     df_lista\n",
    "    #     .withColumn(\"row_id\", F.row_number().over(w) - 1)\n",
    "    # )\n",
    "\n",
    "    # df_final = df_imuno_indexed.join(df_lista_indexed, on=\"row_id\").drop(\"row_id\")\n",
    "    # df_final = df_final.withColumn(\n",
    "\n",
    "    # df_final_classif = df_spk.withColumn(\n",
    "    #     \"categoria_final\",\n",
    "    #     F.when(\n",
    "    #         (\n",
    "    #             ((F.col(\"receptor_estrogeno\") == \"POSITIVO\") | (F.col(\"receptor_progesterona\") == \"POSITIVO\")) &\n",
    "    #             (F.col(\"status_her2\") == \"NEGATIVO\") &\n",
    "    #             (F.col(\"ki67_percentual\") < 14)\n",
    "    #         ),\n",
    "    #         \"Luminal A\"\n",
    "    #     ).when(\n",
    "    #         (\n",
    "    #             ((F.col(\"receptor_estrogeno\") == \"POSITIVO\") | (F.col(\"receptor_progesterona\") == \"POSITIVO\")) &\n",
    "    #             (F.col(\"status_her2\") == \"NEGATIVO\") &\n",
    "    #             (F.col(\"ki67_percentual\") >= 14)\n",
    "    #         ),\n",
    "    #         \"Luminal B\"\n",
    "    #     ).when(\n",
    "    #         (\n",
    "    #             ((F.col(\"receptor_estrogeno\") == \"POSITIVO\") | (F.col(\"receptor_progesterona\") == \"POSITIVO\")) &\n",
    "    #             (F.col(\"status_her2\") == \"POSITIVO\")\n",
    "    #         ),\n",
    "    #         \"Luminal com HER2 Positivo\"\n",
    "    #     ).when(\n",
    "    #         (\n",
    "    #             (F.col(\"receptor_estrogeno\") == \"NEGATIVO\") &\n",
    "    #             (F.col(\"receptor_progesterona\") == \"NEGATIVO\") &\n",
    "    #             (F.col(\"status_her2\") == \"POSITIVO\")\n",
    "    #         ),\n",
    "    #         \"HER-2 Superexpresso\"\n",
    "    #     ).when(\n",
    "    #         (\n",
    "    #             (F.col(\"receptor_estrogeno\") == \"NEGATIVO\") &\n",
    "    #             (F.col(\"receptor_progesterona\") == \"NEGATIVO\") &\n",
    "    #             (F.col(\"status_her2\") == \"NEGATIVO\")\n",
    "    #         ),\n",
    "    #         \"Triplo Negativo\"\n",
    "    #     ).otherwise(\"INDEFINIDO\")\n",
    "    # )\n",
    "\n",
    "    # df_final = (df_final.withColumn(\"id_unidade\", F.col(\"id_unidade\").cast(LongType()))\n",
    "    #                     .withColumn(\"id_cliente\", F.col(\"id_cliente\").cast(LongType()))\n",
    "    #                     .withColumn(\"id_item\", F.col(\"id_item\").cast(LongType()))\n",
    "    #                     .withColumn(\"id_subitem\", F.col(\"id_subitem\").cast(LongType()))\n",
    "    #                     .withColumn(\"id_exame\", F.col(\"id_exame\").cast(LongType()))\n",
    "    #                     .withColumn(\"index\",            F.col(\"index\").cast(LongType()))\n",
    "    #                 )\n",
    "\n",
    "    # Base histórica\n",
    "    #fs = FeatureStoreClient()\n",
    "    #fs.create_table(\n",
    "    #    name=\"refined.saude_preventiva.fleury_laudos_mamo_imunohistoquimico\",\n",
    "    #    primary_keys=[\"id_unidade\", \"id_cliente\", \"id_item\", \"id_subitem\", \"id_exame\"],\n",
    "    #    schema=df_final.schema,\n",
    "    #    description=\"Features extraídas de laudos de mamografia. Siglas: IH-NEO e IHMAMA\"\n",
    "    #)\n",
    "\n",
    "    # Append em prd\n",
    "    # num_linhas = df_final.count()\n",
    "    # fs = FeatureStoreClient()\n",
    "    # if num_linhas > 0:\n",
    "    #     print(f\"Há {num_linhas} registros para inserir — executando gravação…\")\n",
    "    #     primary_keys = [\"id_unidade\", \"id_cliente\", \"id_item\", \"id_subitem\", \"id_exame\"]\n",
    "    #     ###### Apenas para testes ##############\n",
    "    #     df_final = df_final.dropna()\n",
    "    #     df_final = df_final.dropDuplicates(primary_keys)\n",
    "    #     ########################################\n",
    "    #     df_final = df_final.dropDuplicates(primary_keys)\n",
    "    #     fs.write_table(\n",
    "    #         name=\"refined.saude_preventiva.fleury_laudos_mamo_imunohistoquimico\",\n",
    "    #         df=df_final,\n",
    "    #         mode=\"merge\",\n",
    "    #     )\n",
    "    # else:\n",
    "    #     print(\"Nenhum registro encontrado; nada a fazer.\")\n",
    "\n",
    "    # df_metrics = pd.DataFrame()\n",
    "    # df_metrics[\"laudos\"] = laudos\n",
    "    # df_metrics[\"resultados\"] = lista_dicts\n",
    "\n",
    "    # df_metrics[\"resultados\"] = df_metrics[\"resultados\"].apply(parse_json_string)\n",
    "\n",
    "    # lista_laudos2 = df_metrics[\"laudos\"].tolist()\n",
    "    # lista_modelo2 = df_metrics[\"resultados\"].tolist()\n",
    "\n",
    "    # lista_pseudo_gold2 = []\n",
    "    # lista_comparacoes2 = []\n",
    "\n",
    "    # for laudo_txt, json_mod in zip(lista_laudos2, lista_modelo2):\n",
    "    #     json_heu, comp = avalia_extracao_sem_ground_truth_novo(laudo_txt, json_mod)\n",
    "    #     lista_pseudo_gold2.append(json_heu)\n",
    "    #     lista_comparacoes2.append(comp)\n",
    "\n",
    "    # df_metrics = pd.DataFrame()\n",
    "    # df_metrics[\"laudos\"] = laudos\n",
    "    # df_metrics[\"resultados\"] = lista_comparacoes2\n",
    "    # resultados_expandidos = pd.json_normalize(df_metrics[\"resultados\"])\n",
    "    # df_metrics = pd.concat(\n",
    "    #         [df_metrics.drop(columns=[\"resultados\"]), resultados_expandidos],\n",
    "    #         axis=1\n",
    "    #     )\n",
    "    \n",
    "    # json_metricas = agrega_resultados_dinamico(lista_comparacoes2)\n",
    "\n",
    "    # from octoops import mlflowManager\n",
    "    # #  mlflow.set_experiment(\"/Users/aureliano.paiva@grupofleury.com.br/imunohistoquimico_fleury_metricas\")\n",
    "    # experiment_id = mlflowManager.get_or_create_experiment(\"/Shared/saude_preventiva_mama/experiments_imunohistoquimico\")\n",
    "    # mlflowManager.enable_autologging()   \n",
    "\n",
    "    # threshold = 0.8\n",
    "\n",
    "    # with mlflowManager.start_run(run_name=\"Extracao_Laudos_Run_Threshold\"):\n",
    "    #     for campo, stats in json_metricas.items():\n",
    "    #         taxa = stats[\"taxa_acerto\"]\n",
    "            \n",
    "    #         # Registrar a taxa de acerto\n",
    "    #         mlflowManager.log_metric(f\"{campo}_taxa_acerto\", taxa)\n",
    "            \n",
    "    #         # Registrar flag de aprovação no threshold\n",
    "    #         passou_flag = 1 if taxa >= threshold else 0\n",
    "    #         mlflowManager.log_metric(f\"{campo}_passou_threshold\", passou_flag)\n",
    "            \n",
    "    #         # Opcional: registrar acertos e total\n",
    "    #         mlflowManager.log_metric(f\"{campo}_acertos\", stats[\"acertos\"])\n",
    "    #         mlflowManager.log_metric(f\"{campo}_total\", stats[\"total\"])\n",
    "        \n",
    "    #     run_id = mlflowManager.active_run().info.run_id\n",
    "    #     print(f\"Run registrada: {run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e926042",
   "metadata": {},
   "source": [
    "## Processamento de Métricas de Avaliação (Código de Referência)\n",
    "\n",
    "Esta célula contém código de referência para processar métricas de avaliação do desempenho do modelo de extração. Embora não seja executado diretamente (pois depende de variáveis não definidas no fluxo principal), este código serve como template para avaliação de qualidade.\n",
    "\n",
    "O código demonstra como:\n",
    "1. Criar um DataFrame de métricas com laudos e resultados\n",
    "2. Converter estruturas de dados em formatos apropriados\n",
    "3. Executar a função de avaliação para cada laudo\n",
    "4. Transformar os resultados para facilitar análise\n",
    "\n",
    "Este tipo de avaliação é útil para monitorar a qualidade das extrações e identificar áreas para melhoria do prompt ou do processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9537e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "    df_metrics = pd.DataFrame()\n",
    "    df_metrics[\"laudos\"] = laudos\n",
    "    df_metrics[\"resultados\"] = lista_dicts\n",
    "\n",
    "    df_metrics[\"resultados\"] = df_metrics[\"resultados\"].apply(parse_json_string)\n",
    "\n",
    "    lista_laudos2 = df_metrics[\"laudos\"].tolist()\n",
    "    lista_modelo2 = df_metrics[\"resultados\"].tolist()\n",
    "\n",
    "    lista_pseudo_gold2 = []\n",
    "    lista_comparacoes2 = []\n",
    "\n",
    "    for laudo_txt, json_mod in zip(lista_laudos2, lista_modelo2):\n",
    "        json_heu, comp = avalia_extracao_sem_ground_truth_imuno(laudo_txt, json_mod)\n",
    "        lista_pseudo_gold2.append(json_heu)\n",
    "        lista_comparacoes2.append(comp)\n",
    "\n",
    "    df_metrics = pd.DataFrame()\n",
    "    df_metrics[\"laudos\"] = laudos\n",
    "    df_metrics[\"resultados\"] = lista_comparacoes2\n",
    "    resultados_expandidos = pd.json_normalize(df_metrics[\"resultados\"])\n",
    "    df_metrics = pd.concat(\n",
    "            [df_metrics.drop(columns=[\"resultados\"]), resultados_expandidos],\n",
    "            axis=1\n",
    "        )\n",
    "    \n",
    "    json_metricas = agrega_resultados_dinamico(lista_comparacoes2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1f992d",
   "metadata": {},
   "source": [
    "## Visualização dos Resultados do Modelo\n",
    "\n",
    "Esta célula realiza uma visualização direta do dicionário `json_mod`, que contém os resultados da extração do modelo de linguagem para um laudo específico. A função `display()` formata os dados para visualização interativa no ambiente Databricks.\n",
    "\n",
    "Esta visualização permite inspecionar rapidamente os valores extraídos para um laudo individual, servindo como uma verificação rápida da qualidade das extrações. Os campos exibidos incluem os valores para cada um dos biomarcadores: receptor de estrogênio, receptor de progesterona, status HER2, percentual do Ki-67 e status do CK5/6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd82156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(json_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51031e15",
   "metadata": {},
   "source": [
    "## Visualização das Métricas de Avaliação\n",
    "\n",
    "Esta célula exibe o DataFrame `df_metrics`, que contém os resultados detalhados da avaliação das extrações do modelo em comparação com as extrações heurísticas (pseudo-gold).\n",
    "\n",
    "O DataFrame exibe:\n",
    "1. Os laudos médicos originais\n",
    "2. Para cada campo extraído (receptores de estrogênio, progesterona, status HER2, etc.):\n",
    "   - O valor extraído pelo método heurístico\n",
    "   - O valor extraído pelo modelo de linguagem\n",
    "   - Um indicador booleano de acerto (True/False)\n",
    "\n",
    "Esta visualização é fundamental para análise detalhada do desempenho do modelo campo a campo e laudo a laudo, permitindo identificar padrões de erros específicos e oportunidades de melhoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b957ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_metrics)\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05f96ea",
   "metadata": {},
   "source": [
    "## Cálculo de Métricas de Avaliação\n",
    "\n",
    "Esta célula implementa o processo de avaliação da qualidade das extrações do LLM para o conjunto de laudos processados. O objetivo é comparar sistematicamente os resultados do modelo com as extrações heurísticas (pseudo-gold) para cada campo.\n",
    "\n",
    "**Fluxo de processamento:**\n",
    "1. Coleta todos os laudos processados do DataFrame final classificado\n",
    "2. Inicializa uma lista vazia para armazenar os resultados das comparações\n",
    "3. Para cada laudo:\n",
    "   - Obtém o texto original do laudo e a resposta do LLM\n",
    "   - Aplica a função de limpeza e conversão à resposta do LLM (se necessário)\n",
    "   - Executa a função `avalia_extracao_sem_ground_truth_imuno` para comparar com extrações heurísticas\n",
    "   - Armazena os resultados da comparação\n",
    "\n",
    "4. Cria um DataFrame para análise com:\n",
    "   - Os laudos originais\n",
    "   - Os resultados da avaliação normalizada (via `pd.json_normalize`)\n",
    "\n",
    "5. Agrega os resultados usando a função `agrega_resultados_dinamico` para obter métricas consolidadas\n",
    "\n",
    "Esta abordagem permite uma avaliação quantitativa da qualidade das extrações sem necessidade de anotação manual, utilizando regras heurísticas como referência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522c9368",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_laudos = df_final_classif.collect()\n",
    "resultados = []\n",
    "for row in lista_laudos:\n",
    "    laudo_txt = row[\"laudo_tratado\"]\n",
    "    resposta_llm = row[\"resposta_llm\"]\n",
    "    # Corrige: só chama limpar_e_converter se for string, senão usa o dict diretamente\n",
    "    if isinstance(resposta_llm, dict):\n",
    "        json_mod = resposta_llm\n",
    "    else:\n",
    "        json_mod = limpar_e_converter(resposta_llm)\n",
    "    pseudo_gold, compar = avalia_extracao_sem_ground_truth_imuno(laudo_txt, json_mod)\n",
    "    resultados.append(compar)\n",
    "\n",
    "df_metrics = pd.DataFrame()\n",
    "df_metrics[\"laudos\"] = df_respostas.select(\"laudo_tratado\").toPandas()[\"laudo_tratado\"]\n",
    "df_metrics[\"resultados\"] = resultados\n",
    "resultados_expandidos = pd.json_normalize(df_metrics[\"resultados\"])\n",
    "df_metrics = pd.concat(\n",
    "    [df_metrics.drop(columns=[\"resultados\"]), resultados_expandidos],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "json_metricas = agrega_resultados_dinamico(resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8079d0bd",
   "metadata": {},
   "source": [
    "## Visualização das Métricas Agregadas\n",
    "\n",
    "Esta célula exibe o dicionário `json_metricas`, que contém as métricas agregadas de desempenho do modelo para cada campo extraído. \n",
    "\n",
    "As métricas incluem:\n",
    "1. **Número de acertos**: Quantas vezes a extração do LLM concordou com a extração heurística\n",
    "2. **Total de laudos**: Número total de laudos avaliados\n",
    "3. **Taxa de acerto**: Proporção de acertos (acertos/total)\n",
    "\n",
    "Esta visualização oferece uma visão consolidada do desempenho do modelo por campo, permitindo identificar quais campos têm melhor ou pior desempenho. Tais informações são cruciais para direcionar esforços de melhoria, como ajustes no prompt, refinamento das heurísticas de avaliação ou treinamento adicional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe431f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(json_metricas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc32528a",
   "metadata": {},
   "source": [
    "## Contagem de Registros Classificados\n",
    "\n",
    "Esta célula realiza uma contagem simples do número de registros no DataFrame `df_final_classif`, que contém os laudos processados com suas respectivas classificações moleculares.\n",
    "\n",
    "Esta contagem serve para:\n",
    "1. Verificar quantos laudos foram processados com sucesso\n",
    "2. Confirmar que o processamento ocorreu como esperado\n",
    "3. Fornecer informação importante para monitoramento do pipeline\n",
    "\n",
    "O número retornado representa a quantidade total de laudos de imunohistoquímica de mama que foram classificados em subtipos moleculares pelo pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f74da31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_classif.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b627efd",
   "metadata": {},
   "source": [
    "## Persistência dos Dados Processados em Delta Lake\n",
    "\n",
    "Esta célula final implementa a persistência dos dados processados em uma tabela Delta Lake, para uso posterior em análises e modelos preditivos. Utiliza o padrão de operação \"merge\" (upsert) para garantir idempotência e evitar duplicações.\n",
    "\n",
    "**Componentes principais:**\n",
    "1. **Configurações de Monitoramento**: Definição do webhook para alertas via Sentinel\n",
    "2. **Inicialização da Sessão Spark**: Configuração da sessão para operações com Delta\n",
    "3. **Definição do Caminho de Saída**: Especificação da tabela de destino\n",
    "4. **Função `insert_data`**: Encapsula a lógica de inserção/atualização:\n",
    "   - Verifica se a tabela Delta já existe\n",
    "   - Cria a tabela se necessário\n",
    "   - Executa uma operação de merge quando a tabela já existe\n",
    "   \n",
    "5. **Tratamento de Erros**: Estrutura try/except com:\n",
    "   - Verificação da existência de dados para inserção\n",
    "   - Chamada à função de inserção quando há dados\n",
    "   - Envio de notificação via Sentinel quando não há dados para processamento\n",
    "   - Captura e relato de exceções\n",
    "\n",
    "Esta persistência é essencial para que os dados estruturados extraídos dos laudos e as classificações moleculares possam ser utilizados por sistemas downstream, como dashboards de BI, modelos preditivos ou ferramentas de apoio à decisão clínica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7929ed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "from octoops import Sentinel\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "WEBHOOK_DS_AI_BUSINESS_STG = 'stg'\n",
    "\n",
    "# Iniciar sessão Spark\n",
    "spark = SparkSession.builder.appName(\"DfPandasparaSpark\").getOrCreate()\n",
    "\n",
    "#OUTPUT_DATA_PATH = dbutils.widgets.get(\"OUTPUT_DATA_PATH\")\n",
    "OUTPUT_DATA_PATH = \"refined.saude_preventiva.fleury_laudos_mama_imunohistoquimico\"\n",
    "\n",
    "# função para salvar dados na tabela\n",
    "def insert_data(df_spk, output_data_path):\n",
    "\n",
    "    # Cria a tabela Delta se não existir\n",
    "    if not DeltaTable.isDeltaTable(spark, output_data_path):\n",
    "        df_spk.write.format(\"delta\").saveAsTable(output_data_path)\n",
    "    else:\n",
    "        # Carrega a tabela Delta existente\n",
    "        delta_table = DeltaTable.forPath(spark, output_data_path)\n",
    "\n",
    "        # Faz o merge (upsert)\n",
    "        (delta_table.alias(\"target\")\n",
    "        .merge(\n",
    "            df_spk.alias(\"source\"),\n",
    "            \"target.ficha = source.ficha AND target.id_item = source.id_item AND target.id_subitem = source.id_subitem\"\n",
    "        )\n",
    "        .whenMatchedUpdateAll() #atualiza todos os campos se o ID já existir\n",
    "        .whenNotMatchedInsertAll() #insere se o ID não existir\n",
    "        .execute())\n",
    "\n",
    " \n",
    "# salvar dados na tabela\n",
    "try:\n",
    "    # 1/0\n",
    "    if (df_final_classif.count() > 0):        \n",
    "\n",
    "\n",
    "        # Inserir tabela catalog\n",
    "        insert_data(df_final_classif, OUTPUT_DATA_PATH)\n",
    "        print('Total de registros salvos na tabela:', df_final_classif.count())\n",
    "       \n",
    "\n",
    "    else: \n",
    "        error_message = traceback.format_exc()\n",
    "        error_message = \"Fleury Imunuhistoquimico - Não há laudos para extração.\"\n",
    "        sentinela_ds_ai_business = Sentinel(\n",
    "            project_name='Monitor_Linhas_Cuidado_Mama',\n",
    "            env_type=WEBHOOK_DS_AI_BUSINESS_STG,\n",
    "            task_title='Fleury Mama Imunuhistoquimico'\n",
    "        )\n",
    "\n",
    "        sentinela_ds_ai_business.alerta_sentinela(\n",
    "            categoria='Alerta', \n",
    "            mensagem=error_message,\n",
    "            job_id_descritivo='4_fleury_mama_Imunuhistoquimico'\n",
    "        )\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "    raise e    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
