{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "880e39ee",
   "metadata": {},
   "source": [
    "# Extração Automatizada de Dados Imunohistoquímicos de Laudos de Mama\n",
    "\n",
    "## Introdução Técnica Detalhada\n",
    "\n",
    "Este notebook implementa um pipeline completo para extração automatizada de informações estruturadas de laudos imunohistoquímicos de mama, utilizando processamento de linguagem natural (NLP) através de Large Language Models (LLMs). O foco é identificar e extrair marcadores biológicos relevantes para o diagnóstico e classificação molecular do câncer de mama.\n",
    "\n",
    "### Objetivo Principal\n",
    "\n",
    "O objetivo principal deste notebook é extrair de forma automatizada e estruturada os seguintes biomarcadores dos laudos imunohistoquímicos:\n",
    "\n",
    "- **Receptor de Estrógeno**: Status (POSITIVO/NEGATIVO)\n",
    "- **Receptor de Progesterona**: Status (POSITIVO/NEGATIVO)\n",
    "- **HER-2**: Status (POSITIVO/INCONCLUSIVO/NEGATIVO) baseado no escore\n",
    "- **Ki-67**: Percentual de expressão (valor numérico)\n",
    "- **CK5/6**: Status (POSITIVO/NEGATIVO)\n",
    "\n",
    "Após a extração, o notebook classifica os casos em subtipos moleculares de câncer de mama (Luminal A, Luminal B, HER-2 Superexpresso, Triplo Negativo), que são fundamentais para definição do prognóstico e tratamento.\n",
    "\n",
    "### Tecnologias Utilizadas\n",
    "\n",
    "O notebook utiliza um ecossistema tecnológico diversificado:\n",
    "\n",
    "- **Frameworks de Processamento de Dados**:\n",
    "  - **Apache Spark** (PySpark): Para processamento distribuído de dados\n",
    "  - **Delta Lake**: Para armazenamento transacional em formato tabular\n",
    "  - **Pandas**: Para manipulações mais específicas de dados em memória\n",
    "\n",
    "- **Bibliotecas para Processamento de Linguagem Natural**:\n",
    "  - **OpenAI API**: Interface com modelos de linguagem avançados\n",
    "  - **LLaMA-4-Maverick**: Modelo de linguagem utilizado (via endpoint Databricks)\n",
    "  - **RegEx** (re): Para extração baseada em padrões (abordagem heurística)\n",
    "\n",
    "- **Bibliotecas de Monitoramento e Gestão**:\n",
    "  - **MLflow**: Para registro de métricas e experimentos\n",
    "  - **Octoops**: Framework interno para monitoramento e alertas\n",
    "  - **tqdm**: Para visualização do progresso de processamento em lotes\n",
    "\n",
    "- **Bibliotecas Auxiliares**:\n",
    "  - **json**: Para manipulação de dados em formato JSON\n",
    "  - **ast**: Para avaliação segura de strings Python\n",
    "\n",
    "### Fluxo de Trabalho/Etapas Principais\n",
    "\n",
    "O pipeline segue um fluxo sequencial bem definido:\n",
    "\n",
    "1. **Configuração do Ambiente**:\n",
    "   - Instalação de dependências (OpenAI, tqdm, etc.)\n",
    "   - Importação de bibliotecas necessárias\n",
    "   - Configuração de sessão Spark e tokens de acesso\n",
    "\n",
    "2. **Extração de Dados**:\n",
    "   - Definição de consultas SQL para selecionar laudos relevantes\n",
    "   - Aplicação de filtros (linha de cuidado 'mama', exame 'IHMAMA', presença de 'carcinoma')\n",
    "   - Carregamento de dados em um DataFrame Spark\n",
    "\n",
    "3. **Preparação do Processamento**:\n",
    "   - Definição das funções de prompt para o LLM\n",
    "   - Configuração das funções de geração em lote\n",
    "   - Implementação de funções de extração heurística (para validação)\n",
    "\n",
    "4. **Processamento dos Laudos**:\n",
    "   - Conversão para DataFrame Pandas para processamento em memória\n",
    "   - Envio dos laudos em lotes para o modelo LLM\n",
    "   - Limpeza e estruturação das respostas em formato JSON\n",
    "\n",
    "5. **Enriquecimento e Classificação**:\n",
    "   - Expansão das respostas JSON em colunas individuais\n",
    "   - Aplicação de regras de classificação molecular\n",
    "   - Análise e validação dos resultados\n",
    "\n",
    "6. **Persistência e Monitoramento**:\n",
    "   - Armazenamento dos resultados em tabela Delta\n",
    "   - Registro de métricas e desempenho (via MLflow)\n",
    "   - Geração de alertas em caso de falhas (via Sentinel)\n",
    "\n",
    "### Dados Envolvidos\n",
    "\n",
    "#### Fontes de Dados\n",
    "- **Tabela Principal**: `refined.saude_preventiva.pardini_laudos`\n",
    "  - Contém os laudos brutos de exames realizados\n",
    "  - Filtrados para `linha_cuidado = 'mama'` e `sigla_exame = 'IHMAMA'`\n",
    "\n",
    "#### Tabela de Destino\n",
    "- **Tabela de Saída**: `refined.saude_preventiva.pardini_laudos_mama_imunohistoquimico`\n",
    "  - Armazena os resultados processados com as informações extraídas\n",
    "  - Mantém chaves primárias para rastreabilidade (`ficha`, `id_exame`, `id_marca`, `sequencial`)\n",
    "\n",
    "#### Colunas Relevantes\n",
    "- **Entrada**:\n",
    "  - `laudo_tratado`: Texto completo do laudo imunohistoquímico\n",
    "  - Identificadores: `id_marca`, `id_unidade`, `id_cliente`, `ficha`, etc.\n",
    "  - Metadados: `dth_pedido`, `dth_resultado`, `linha_cuidado`, `sexo_cliente`\n",
    "\n",
    "- **Saída** (Extraída do LLM):\n",
    "  - `receptor_estrogeno`: Status do receptor de estrógeno\n",
    "  - `receptor_progesterona`: Status do receptor de progesterona\n",
    "  - `status_her2`: Classificação do HER-2 baseada no escore\n",
    "  - `ki67_percentual`: Valor percentual de expressão do Ki-67\n",
    "  - `status_ck5_6`: Status do marcador CK5/6\n",
    "  - `categoria_final`: Classificação molecular derivada dos marcadores\n",
    "\n",
    "### Resultados/Saídas Esperadas\n",
    "\n",
    "O notebook gera os seguintes resultados:\n",
    "\n",
    "1. **DataFrame Enriquecido** (`df_final_expanded`):\n",
    "   - Contém todos os dados originais mais as colunas extraídas pelo LLM\n",
    "\n",
    "2. **DataFrame Classificado** (`df_final_classif`):\n",
    "   - Adiciona a coluna `categoria_final` com a classificação molecular\n",
    "   - Categorias possíveis: \"Luminal A\", \"Luminal B\", \"Luminal com HER2 Positivo\", \"HER-2 Superexpresso\", \"Triplo Negativo\", \"Indefinido\"\n",
    "\n",
    "3. **Tabela Delta Persistente**:\n",
    "   - Armazena os resultados em formato Delta Lake para consultas futuras\n",
    "   - Utiliza operações de merge para atualizar registros existentes\n",
    "\n",
    "4. **Métricas de Validação** (opcional, quando ativado):\n",
    "   - Comparação entre extração por LLM e extração heurística\n",
    "   - Taxas de acerto por campo extraído\n",
    "\n",
    "### Pré-requisitos\n",
    "\n",
    "Para executar este notebook são necessários:\n",
    "\n",
    "- **Ambiente Databricks** com:\n",
    "  - Runtime que suporte PySpark e Delta Lake\n",
    "  - Acesso configurado ao endpoint do modelo LLaMA-4-Maverick\n",
    "  - Token de acesso válido (`DATABRICKS_TOKEN`)\n",
    "\n",
    "- **Bibliotecas Instaladas**:\n",
    "  - `openai`: Para interação com a API de LLM\n",
    "  - `tqdm`: Para visualização de progresso\n",
    "  - `pandarallel`: Para processamento paralelo de pandas\n",
    "  - `databricks-feature-store`: Para interação com feature store\n",
    "  - `octoops`: Para monitoramento e alertas\n",
    "\n",
    "- **Acesso a Dados**:\n",
    "  - Permissões de leitura na tabela `refined.saude_preventiva.pardini_laudos`\n",
    "  - Permissões de escrita na tabela `refined.saude_preventiva.pardini_laudos_mama_imunohistoquimico`\n",
    "\n",
    "### Considerações Importantes/Observações\n",
    "\n",
    "- **Filtragem de Laudos**: Apenas laudos que contenham os termos 'mama' e 'carcinoma' são processados, conforme especificado na documentação. Casos negativos para câncer são excluídos.\n",
    "\n",
    "- **Processamento em Lote**: O notebook implementa processamento em lotes (batch_size=100) para gerenciar a carga na API do modelo e evitar limites de taxa.\n",
    "\n",
    "- **Validação Heurística**: O código inclui funções para extração baseada em regras (expressões regulares) que podem ser usadas para validar os resultados do LLM.\n",
    "\n",
    "- **Robustez e Tratamento de Erros**:\n",
    "  - Tentativas múltiplas (até 3) para lidar com falhas de conexão\n",
    "  - Tratamento de erros ao converter respostas JSON\n",
    "  - Sistema de alerta via Sentinel para notificar problemas\n",
    "\n",
    "- **Limitações**:\n",
    "  - A precisão da extração depende da qualidade e estrutura dos laudos\n",
    "  - Laudos com formatação muito atípica podem ter resultados subótimos\n",
    "  - A conversão do valor percentual de Ki-67 pode exigir ajustes para casos especiais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac07b44",
   "metadata": {},
   "source": [
    "# Extração de dado - Imunohistoquimico\n",
    "**Extrair os seguintes labels estruturados:**\n",
    "- Receptor de Estrógeno (categórica): POSITIVO ou NEGATIVO \n",
    "  - \"RECEPTOR DE ESTRÓGENO - POSITIVO \" \n",
    "  - \"RECEPTOR DE ESTRÓGENO – NEGATIVO\" \n",
    "\n",
    "- Receptor de Progesterona (categórica): POSITIVO ou NEGATIVO \n",
    "  - \"RECEPTOR DE PROGESTERONA - POSITIVO\" \n",
    "  - \"RECEPTOR DE PROGESTERONA - NEGATIVO\" \n",
    "\n",
    "- Status do HER-2 (categórica): Negativo, inconclusivo ou positivo \n",
    "  - \"HER-2 - ESCORE 0\" = Negativo \n",
    "  - \"HER-2 - ESCORE 1+\" = Negativo \n",
    "  - \"HER-2  -  ESCORE  2+\" = Inconclusivo \n",
    "  - \"HER-2  -  ESCORE  3+\" = Positivo \n",
    "\n",
    "- Porcentagem do Ki-67 (numérica):  \"KI-67 - POSITIVO EM 20% DAS CÉLULAS NEOPLÁSICAS\"\n",
    "  - Deve ser extraído esse número da porcentagem nessa frase \n",
    "\n",
    "- Status CK5/6 (categórica): POSITIVO ou NEGATIVO \n",
    "  - \"CK5/6 - POSITIVO \"ou \"CK5/6 - NEGATIVO\" \n",
    "  \n",
    "+ Para laudos que não possuem carcinoma, ou seja, casos negativos para câncer não devem se processados no LLM.\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15467c85",
   "metadata": {},
   "source": [
    "## Instalação de Dependências\n",
    "\n",
    "Esta célula instala as bibliotecas Python necessárias para o funcionamento do notebook. Utiliza comandos mágicos do Jupyter (`%pip install`) para instalar pacotes diretamente no ambiente de execução:\n",
    "\n",
    "1. **openai (-q)**: Cliente Python para interação com a API do OpenAI, usada para fazer chamadas ao modelo de linguagem. A flag `-q` (quiet) reduz a verbosidade da saída.\n",
    "\n",
    "2. **tqdm (-q)**: Biblioteca para exibição de barras de progresso, útil para acompanhar o processamento em lotes dos laudos.\n",
    "\n",
    "3. **pandarallel (-q)**: Extensão do pandas para facilitar a paralelização de operações, melhorando a performance em processamentos de DataFrames.\n",
    "\n",
    "4. **databricks-feature-store (-q)**: Cliente para interagir com o Databricks Feature Store, um repositório centralizado para features de machine learning.\n",
    "\n",
    "5. **octoops**: Framework interno para gerenciamento de operações como monitoramento, alertas e integração com sistemas externos.\n",
    "\n",
    "Estas bibliotecas formam a base do ambiente necessário para a execução do pipeline de extração e processamento dos laudos imunohistoquímicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24908b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai -q\n",
    "%pip install tqdm -q\n",
    "%pip install pandarallel -q\n",
    "%pip install databricks-feature-store -q\n",
    "%pip install octoops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc92f35",
   "metadata": {},
   "source": [
    "## Reinicialização do Ambiente Python\n",
    "\n",
    "Esta célula executa um comando para reiniciar o kernel Python no ambiente Databricks. A função `dbutils.library.restartPython()` reinicia o interpretador Python, garantindo que todas as bibliotecas recém-instaladas na célula anterior estejam disponíveis e devidamente carregadas no ambiente de execução.\n",
    "\n",
    "Esta etapa é crucial após a instalação de novas bibliotecas, pois algumas delas só estarão completamente funcionais após a reinicialização do ambiente. Essa prática evita erros comuns como \"module not found\" ou comportamentos inesperados devido à carga parcial de dependências."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4114cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bdd845",
   "metadata": {},
   "source": [
    "## Importação de Bibliotecas e Configuração Inicial\n",
    "\n",
    "Esta célula realiza a importação de todas as bibliotecas necessárias para o funcionamento do pipeline de processamento de laudos imunohistoquímicos. O código é estruturado em blocos lógicos de importações:\n",
    "\n",
    "### Processamento de Dados e Spark\n",
    "- **PySpark**: `SparkSession` para gerenciar a sessão Spark\n",
    "- **Funções SQL**: Importações de `functions as F`, `Window`, `row_number` para manipulação de DataFrames\n",
    "- **Tipos de dados**: `pyspark.sql.types.*` para definição de schemas\n",
    "\n",
    "### Manipulação de Texto e Dados\n",
    "- **json**: Para manipulação de estruturas JSON\n",
    "- **re**: Para processamento com expressões regulares\n",
    "- **os, sys**: Para interação com o sistema operacional\n",
    "- **pandas, numpy**: Para manipulação de DataFrames em memória\n",
    "\n",
    "### Monitoramento e Logging\n",
    "- **mlflow**: Para registro de métricas e experimentos\n",
    "- **tqdm**: Para exibição de barras de progresso\n",
    "- **warnings**: Para gerenciamento de alertas\n",
    "\n",
    "### Integração com LLM\n",
    "- **openai**: Cliente para interação com a API OpenAI\n",
    "- **time**: Para controle de intervalos entre tentativas de conexão\n",
    "\n",
    "### Configuração Inicial\n",
    "- Criação da sessão Spark com nome \"LLM_Extractor\"\n",
    "- Configuração do token de acesso ao Databricks para autenticação da API\n",
    "\n",
    "Esta configuração abrangente estabelece todo o ambiente necessário para as operações de extração, processamento e persistência de dados que serão executadas nas células seguintes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930c1a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import mlflow\n",
    "import time\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Any\n",
    "import openai\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "from databricks.feature_store import FeatureStoreClient\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"LLM_Extractor\").getOrCreate()\n",
    "\n",
    "DATABRICKS_TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get() if dbutils.notebook.entry_point.getDbutils().notebook().getContext() is not None else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c137e9c",
   "metadata": {},
   "source": [
    "## Desativação da Exibição de Rastreamento do MLflow\n",
    "\n",
    "Esta célula desativa a exibição automática de elementos de rastreamento do MLflow no notebook. A função `mlflow.tracing.disable_notebook_display()` impede que componentes visuais de rastreamento do MLflow sejam automaticamente renderizados na saída das células.\n",
    "\n",
    "Esta configuração é útil para manter o notebook limpo e focado nos resultados principais da análise, especialmente quando múltiplos experimentos MLflow são registrados durante a execução. Os dados de rastreamento continuam sendo registrados normalmente, apenas não são exibidos automaticamente no notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9302cb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.tracing.disable_notebook_display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795e499f",
   "metadata": {},
   "source": [
    "## Configuração de Tabelas e Filtros para Extração de Dados\n",
    "\n",
    "Esta célula define os parâmetros essenciais para a extração de dados imunohistoquímicos de laudos de mama. Três componentes principais são configurados:\n",
    "\n",
    "### 1. Definição da Tabela de Destino\n",
    "```python\n",
    "table_anatom = \"refined.saude_preventiva.pardini_laudos_mama_imunohistoquimico\"\n",
    "```\n",
    "Esta variável especifica o caminho completo para a tabela Delta onde serão armazenados os resultados da extração.\n",
    "\n",
    "### 2. Cláusula WHERE para Processamento Incremental\n",
    "```python\n",
    "where_clause = f\"\"\"\n",
    "WHERE\n",
    "    _datestamp > (\n",
    "        SELECT MAX(anatom._datestamp)\n",
    "        FROM {table_anatom} anatom\n",
    "    )\n",
    "\"\"\"\n",
    "```\n",
    "Esta cláusula SQL implementa uma estratégia de processamento incremental, garantindo que apenas registros com timestamp mais recente que o último registro processado sejam extraídos. Isso otimiza o processamento ao evitar a reanálise de dados já processados.\n",
    "\n",
    "### 3. Filtros de Extração Específicos\n",
    "```python\n",
    "filtro_extracao = \"\"\"\n",
    "    WHERE\n",
    "        linha_cuidado  = 'mama'\n",
    "        AND UPPER(flr.sexo_cliente) = 'F'\n",
    "        AND sigla_exame IN (\"IHMAMA\")\n",
    "        AND laudo_tratado RLIKE '(?i)mama' AND laudo_tratado RLIKE '(?i)carcinoma'\n",
    "\"\"\"\n",
    "```\n",
    "Este filtro estabelece critérios específicos para seleção dos laudos:\n",
    "- **Linha de Cuidado**: Restringe aos exames da linha de cuidado 'mama'\n",
    "- **Sexo do Cliente**: Seleciona apenas pacientes do sexo feminino (`'F'`)\n",
    "- **Tipo de Exame**: Filtra apenas exames com sigla \"IHMAMA\" (Imunohistoquímica de mama)\n",
    "- **Conteúdo do Laudo**: Garante que apenas laudos que contenham os termos 'mama' e 'carcinoma' (usando expressão regular case-insensitive `(?i)`) sejam processados\n",
    "\n",
    "Essa configuração precisa garante que apenas os laudos relevantes para a análise imunohistoquímica de carcinoma mamário sejam processados, otimizando o uso de recursos computacionais e do modelo de linguagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7913bb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_anatom = \"refined.saude_preventiva.pardini_laudos_mama_imunohistoquimico\" \n",
    "\n",
    "where_clause = f\"\"\"\n",
    "WHERE\n",
    "    _datestamp > (\n",
    "        SELECT MAX(anatom._datestamp)\n",
    "        FROM {table_anatom} anatom\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    " \n",
    "filtro_extracao = \"\"\"\n",
    "    WHERE\n",
    "        linha_cuidado  = 'mama'\n",
    "        AND UPPER(flr.sexo_cliente) = 'F'\n",
    "        AND sigla_exame IN (\"IHMAMA\")\n",
    "        AND laudo_tratado RLIKE '(?i)mama' AND laudo_tratado RLIKE '(?i)carcinoma'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd4fc8c",
   "metadata": {},
   "source": [
    "## Consulta SQL para Verificação da Tabela de Destino\n",
    "\n",
    "Esta célula executa uma consulta SQL direta para examinar o conteúdo da tabela de destino onde os resultados serão salvos. O comando `%sql` é uma \"magic command\" do Jupyter que permite executar SQL nativo diretamente no ambiente Databricks.\n",
    "\n",
    "```sql\n",
    "select *\n",
    "from refined.saude_preventiva.pardini_laudos_mamo_imunohistoquimico\n",
    "```\n",
    "\n",
    "Esta consulta retorna todas as colunas e registros da tabela de destino, permitindo:\n",
    "\n",
    "- Verificar se a tabela já existe no ambiente\n",
    "- Examinar a estrutura atual dos dados (schema, colunas)\n",
    "- Confirmar os dados já existentes na tabela\n",
    "- Validar os resultados após o processamento\n",
    "\n",
    "Trata-se de uma etapa exploratória importante para entender o contexto dos dados já processados e confirmar que a estrutura está conforme esperado antes de prosseguir com novos processamentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0711da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "select *\n",
    "from refined.saude_preventiva.pardini_laudos_mamo_imunohistoquimico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd334d3",
   "metadata": {},
   "source": [
    "## Consulta SQL para Verificação das Siglas de Exame Disponíveis\n",
    "\n",
    "Esta célula executa uma consulta SQL para identificar todas as siglas de exame distintas disponíveis na tabela de laudos Pardini, filtradas para a linha de cuidado 'mama'. O comando utiliza novamente a \"magic command\" `%sql` para execução direta de SQL no ambiente Databricks.\n",
    "\n",
    "```sql\n",
    "select distinct (sigla_exame)\n",
    "from refined.saude_preventiva.pardini_laudos\n",
    "where linha_cuidado = 'mama'\n",
    "```\n",
    "\n",
    "Esta consulta tem objetivos exploratórios importantes:\n",
    "\n",
    "1. **Identificar a diversidade de exames**: Permite conhecer todos os tipos de exame disponíveis relacionados à linha de cuidado de mama\n",
    "2. **Validar os filtros**: Confirma que a sigla \"IHMAMA\" (usada no filtro de extração) realmente existe na base de dados\n",
    "3. **Identificar outras oportunidades**: Pode revelar outros tipos de exame que poderiam ser incluídos na análise no futuro\n",
    "\n",
    "Esta etapa exploratória é fundamental para confirmar que os filtros aplicados na célula anterior estão adequados à realidade dos dados disponíveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2892821a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "select distinct (sigla_exame)\n",
    "from refined.saude_preventiva.pardini_laudos\n",
    "where linha_cuidado = 'mama'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0efd1e",
   "metadata": {},
   "source": [
    "## Extração de Laudos para Processamento\n",
    "\n",
    "Esta célula realiza a extração principal dos laudos que serão processados pelo modelo de linguagem. Ela constrói e executa uma consulta SQL complexa que:\n",
    "\n",
    "### 1. Estrutura da Consulta\n",
    "\n",
    "A consulta utiliza uma Common Table Expression (CTE) chamada `base` para organizar a lógica:\n",
    "\n",
    "```python\n",
    "query = f\"\"\"\n",
    "WITH base AS (\n",
    "    SELECT\n",
    "        flr.id_marca, flr.id_unidade, flr.id_cliente, /* campos identificadores */\n",
    "        flr.ficha, flr.id_item, flr.id_subitem, flr.sequencial, flr.id_exame, /* identificadores do exame */\n",
    "        flr.dth_pedido, flr.dth_resultado, /* datas */\n",
    "        flr.sigla_exame, flr.laudo_tratado, flr.linha_cuidado, flr.sexo_cliente, flr._datestamp\n",
    "    FROM refined.saude_preventiva.pardini_laudos flr  \n",
    "    {where_clause}  \n",
    ")\n",
    "SELECT * FROM base {filtro_extracao}\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "### 2. Campos Selecionados\n",
    "\n",
    "A seleção inclui todos os campos necessários para:\n",
    "- Identificação do paciente e do exame (`id_marca`, `id_unidade`, `id_cliente`, `ficha`, etc.)\n",
    "- Informações temporais (`dth_pedido`, `dth_resultado`, `_datestamp`)\n",
    "- Conteúdo do laudo (`laudo_tratado`) - fonte principal para a extração de informações\n",
    "- Metadados do exame (`sigla_exame`, `linha_cuidado`)\n",
    "\n",
    "### 3. Filtragem\n",
    "\n",
    "A consulta combina duas cláusulas de filtro:\n",
    "- `where_clause`: Garante processamento incremental, extraindo apenas registros mais recentes que os já processados\n",
    "- `filtro_extracao`: Aplica os critérios de filtragem específicos (linha de cuidado 'mama', sigla 'IHMAMA', sexo 'F', presença dos termos 'mama' e 'carcinoma')\n",
    "\n",
    "### 4. Processamento e Visualização\n",
    "\n",
    "A consulta é executada pelo Spark SQL e os resultados são armazenados no DataFrame `df_spk`, que é exibido imediatamente com a função `display()` para inspeção visual.\n",
    "\n",
    "Esta etapa é crucial pois define o conjunto de dados que será enviado para processamento pelo modelo de linguagem, garantindo que apenas laudos relevantes sejam incluídos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5110a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "WITH base AS (\n",
    "    SELECT\n",
    "        flr.id_marca,\n",
    "        flr.id_unidade,\n",
    "        flr.id_cliente, \n",
    "        flr.id_ficha,\n",
    "        flr.ficha,\n",
    "        flr.id_item, \n",
    "        flr.id_subitem,\n",
    "        flr.sequencial, \n",
    "        flr.id_exame, \n",
    "        flr.dth_pedido,\n",
    "        flr.dth_resultado,\n",
    "        flr.sigla_exame,\n",
    "        flr.laudo_tratado,\n",
    "        flr.linha_cuidado,\n",
    "        flr.sexo_cliente,\n",
    "        flr.`_datestamp`\n",
    "    FROM refined.saude_preventiva.pardini_laudos flr  \n",
    "    {where_clause}  \n",
    "    \n",
    ")\n",
    "SELECT *\n",
    "FROM base\n",
    "{filtro_extracao}\n",
    "\"\"\"\n",
    "df_spk = spark.sql(query)\n",
    "display(df_spk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac1fdfd",
   "metadata": {},
   "source": [
    "## Consultas SQL Alternativas (Comentadas)\n",
    "\n",
    "Esta célula contém consultas SQL alternativas que estão comentadas, mas que oferecem abordagens diferentes para extração de dados. Embora não estejam sendo executadas, elas são mantidas como referência para estratégias alternativas de processamento:\n",
    "\n",
    "### 1. Consulta para Identificar Registros Não Processados\n",
    "\n",
    "A primeira consulta comentada (`query_append`) identifica registros que existem na tabela base, mas que ainda não foram processados e inseridos na tabela de destino:\n",
    "\n",
    "```sql\n",
    "WITH base AS (\n",
    "    -- Seleciona dados da tabela fonte\n",
    "),\n",
    "sem_extracao AS (\n",
    "    -- Faz um LEFT JOIN para identificar registros que não estão na tabela de destino\n",
    "    -- WHERE mb.id_unidade IS NULL filtra apenas os registros ausentes\n",
    ")\n",
    "```\n",
    "\n",
    "Esta abordagem é útil para processamentos incrementais quando já existe uma tabela de destino parcialmente populada.\n",
    "\n",
    "### 2. Consulta para Processamento Completo\n",
    "\n",
    "A segunda consulta comentada (`query_all_base`) implementa uma estratégia para processar todos os registros relevantes, sem considerar processamentos anteriores:\n",
    "\n",
    "```sql\n",
    "WITH base AS (\n",
    "    -- Seleciona e converte tipos de colunas (CAST)\n",
    "    -- Filtra por linha de cuidado e sigla de exame\n",
    ")\n",
    "```\n",
    "\n",
    "### 3. Pós-Processamento (Comentado)\n",
    "\n",
    "As linhas seguintes demonstram etapas adicionais para preparação dos dados:\n",
    "- Filtragem por texto usando regex: `df_imunohistoquimico.filter(F.col(\"laudo_tratado\").rlike(\"(?i)mama\"))`\n",
    "- Conversão para minúsculas: `withColumn(\"laudo_tratado\", F.lower(...))`\n",
    "- Criação de índice sequencial: `withColumn(\"index\", row_number().over(window) - 1)`\n",
    "\n",
    "Estas consultas alternativas representam diferentes estratégias que podem ser ativadas conforme a necessidade, substituindo ou complementando a abordagem principal implementada na célula anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1909519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_append = \"\"\"\n",
    "# WITH base AS (\n",
    "#     SELECT\n",
    "#         flr.id_unidade,\n",
    "#         flr.id_cliente, \n",
    "#         flr.id_item, \n",
    "#         flr.id_subitem, \n",
    "#         flr.id_exame, \n",
    "#         flr.dth_pedido,\n",
    "#         flr.laudo_tratado,\n",
    "#         flr.sigla_exame,\n",
    "#         flr.linha_cuidado\n",
    "#         FROM refined.saude_preventiva.pardini_laudos flr\n",
    "#     WHERE\n",
    "#         flr.linha_cuidado   = 'mama'\n",
    "#         flr.sigla_exame IN (\"IHMAMA\")\n",
    "# ),\n",
    "# sem_extracao AS (\n",
    "#     SELECT\n",
    "#         b.id_unidade,\n",
    "#         b.id_cliente,\n",
    "#         b.id_item,\n",
    "#         b.id_subitem,\n",
    "#         b.id_exame,\n",
    "#         b.dth_pedido,\n",
    "#         b.sigla_exame,\n",
    "#         b.laudo_tratado,\n",
    "#         b.RAW_CARCINOMA,\n",
    "#         b.HAS_CARCINOMA\n",
    "#     FROM base b\n",
    "#     LEFT JOIN refined.saude_preventiva.pardini_laudos_mamo_imunohistoquimico mb\n",
    "#       ON mb.id_unidade = b.id_unidade\n",
    "#      AND mb.id_cliente = b.id_cliente\n",
    "#      AND mb.id_item    = b.id_item\n",
    "#      AND mb.id_subitem = b.id_subitem\n",
    "#      AND mb.id_exame   = b.id_exame\n",
    "#     WHERE mb.id_unidade IS NULL\n",
    "# )\n",
    "# SELECT *\n",
    "# FROM sem_extracao\n",
    "# \"\"\"\n",
    "\n",
    "# query_all_base = \"\"\"WITH base AS (\n",
    "#         SELECT\n",
    "#             flr.id_unidade,\n",
    "#             flr.id_cliente, \n",
    "#             CAST(flr.id_item AS INT) AS id_item, \n",
    "#             CAST(flr.id_subitem AS INT) AS id_subitem, \n",
    "#             flr.id_exame, \n",
    "#             flr.dth_pedido,\n",
    "#             flr.laudo_tratado,\n",
    "#             flr.sigla_exame\n",
    "#         FROM refined.saude_preventiva.pardini_laudos flr\n",
    "#         WHERE\n",
    "#         flr.linha_cuidado = 'mama'\n",
    "#         AND\n",
    "#         flr.sigla_exame IN (\"IHMAMA\")\n",
    "#     )\n",
    "#     SELECT\n",
    "#         id_unidade,\n",
    "#         id_cliente, \n",
    "#         id_item, \n",
    "#         id_subitem, \n",
    "#         id_exame, \n",
    "#         dth_pedido,\n",
    "#         sigla_exame,\n",
    "#         laudo_tratado\n",
    "#     FROM base \"\"\"\n",
    "\n",
    "# df_imunohistoquimico = spark.sql(query_all_base)\n",
    "# df_imunohistoquimico = df_imunohistoquimico.filter(F.col(\"laudo_tratado\").rlike(\"(?i)mama\"))\n",
    "# df_imunohistoquimico = df_imunohistoquimico.withColumn(\"laudo_tratado\", F.lower(df_imunohistoquimico[\"laudo_tratado\"]))\n",
    "# window = Window.orderBy(F.monotonically_increasing_id())\n",
    "# df_imunohistoquimico = df_imunohistoquimico.withColumn(\"index\", row_number().over(window) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75168256",
   "metadata": {},
   "source": [
    "## Contagem de Registros Extraídos\n",
    "\n",
    "Esta célula executa uma operação simples porém importante: contar o número total de registros obtidos na consulta anterior.\n",
    "\n",
    "```python\n",
    "df_spk.count()\n",
    "```\n",
    "\n",
    "Esta operação aciona uma ação de processamento no DataFrame Spark (`df_spk`) e retorna um valor numérico representando o número total de linhas no conjunto de dados.\n",
    "\n",
    "O resultado dessa contagem é fundamental para:\n",
    "\n",
    "1. **Validação da Extração**: Confirmar se existem dados para processamento (se o resultado for zero, não há registros a serem processados)\n",
    "2. **Dimensionamento do Processamento**: Entender o volume de dados que serão enviados ao modelo de linguagem\n",
    "3. **Controle de Fluxo**: Decisões condicionais posteriores podem depender da existência de registros (conforme visto mais adiante no código)\n",
    "\n",
    "Esta verificação rápida permite avaliar imediatamente se os filtros aplicados na consulta SQL estão funcionando como esperado e se há dados disponíveis para a continuidade do processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff664947",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spk.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e568c47a",
   "metadata": {},
   "source": [
    "## Definição de Funções para Geração de Prompts e Interação com o LLM\n",
    "\n",
    "Esta célula implementa um conjunto de funções essenciais que orquestram a interação com o modelo de linguagem para extrair informações dos laudos imunohistoquímicos. Três funções principais são definidas:\n",
    "\n",
    "### 1. Função de Geração do Prompt (`prompt_laudo`)\n",
    "\n",
    "```python\n",
    "def prompt_laudo(laudo_texto: str) -> str:\n",
    "    # Gera o texto do prompt com instruções e o laudo\n",
    "```\n",
    "\n",
    "Esta função:\n",
    "- Recebe o texto do laudo como entrada\n",
    "- Cria um prompt estruturado com instruções específicas para o modelo\n",
    "- Inclui detalhes sobre os campos a serem extraídos e suas regras\n",
    "- Define o formato esperado da resposta (dicionário Python)\n",
    "\n",
    "O prompt possui:\n",
    "- **Contexto**: Informação que o texto é um laudo médico de mamografia\n",
    "- **Instruções de Fallback**: Orientação para retornar \"NÃO INFORMADO\" quando informações não estiverem presentes\n",
    "- **Critérios de Extração**: Regras específicas para cada campo:\n",
    "  - Receptor de Estrógeno: POSITIVO/NEGATIVO/NÃO INFORMADO\n",
    "  - Receptor de Progesterona: POSITIVO/NEGATIVO/NÃO INFORMADO\n",
    "  - Status do HER-2: NEGATIVO/INCONCLUSIVO/POSITIVO baseado no score\n",
    "  - Ki-67 (%): Valor numérico da porcentagem\n",
    "  - Status CK5/6: POSITIVO/NEGATIVO/NÃO INFORMADO\n",
    "- **Formato de Saída**: Template de dicionário Python a ser preenchido\n",
    "\n",
    "### 2. Função de Geração de Resposta (`generate`)\n",
    "\n",
    "```python\n",
    "def generate(descricao_agente:str, laudo:str, llm_client) -> str:\n",
    "    # Configura e envia a requisição para o modelo de linguagem\n",
    "```\n",
    "\n",
    "Esta função:\n",
    "- Recebe três parâmetros: descrição do agente (system prompt), texto do laudo e cliente da API\n",
    "- Configura o prompt usando a função `prompt_laudo`\n",
    "- Estrutura as mensagens no formato esperado pela API (system + user)\n",
    "- Define parâmetros do modelo: \"databricks-llama-4-maverick\", temperatura 0 (determinístico), tokens máximos, etc.\n",
    "- Implementa um mecanismo de tentativas (até 3) para lidar com falhas de conexão\n",
    "- Retorna o texto da resposta do modelo\n",
    "\n",
    "### 3. Função de Processamento em Lote (`batch_generate`)\n",
    "\n",
    "```python\n",
    "def batch_generate(descricao_agente, laudos, llm_client, batch_size=25):\n",
    "    # Processa múltiplos laudos em lotes\n",
    "```\n",
    "\n",
    "Esta função:\n",
    "- Recebe uma lista de laudos e processa em lotes de tamanho definido (default: 25)\n",
    "- Reinicializa o cliente OpenAI com o token Databricks e URL do endpoint\n",
    "- Usa `tqdm` para exibir barras de progresso durante o processamento\n",
    "- Para cada laudo no lote, chama a função `generate` e armazena as respostas\n",
    "- Retorna uma lista com todas as respostas do modelo\n",
    "\n",
    "### 4. Função de Limpeza e Conversão (`limpar_e_converter`)\n",
    "\n",
    "```python\n",
    "def limpar_e_converter(item):\n",
    "    # Limpa e converte a resposta do modelo para um dicionário Python\n",
    "```\n",
    "\n",
    "Esta função:\n",
    "- Recebe a resposta textual do modelo (geralmente contendo um bloco de código JSON/Python)\n",
    "- Remove marcadores de código (```python, ```) usando expressões regulares\n",
    "- Converte o texto limpo para um objeto Python (dicionário)\n",
    "- Implementa tratamento de erros, retornando um dicionário padrão com \"NÃO INFORMADO\" em caso de falha na conversão\n",
    "\n",
    "Estas funções formam o núcleo do sistema de extração de informações, encapsulando a lógica de interação com o modelo de linguagem, formatação de prompts, processamento em lote e tratamento de respostas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a2e8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_laudo(laudo_texto: str) -> str:\n",
    "    prompt = f\"\"\"A seguir está um laudo médico de mamografia, conforme indicado abaixo. Se alguma informação não estiver presente no texto, retorne \"NÃO INFORMADO\". Sempre retorne apenas o dicionário Python.\n",
    "\n",
    "    Laudo clínico:\n",
    "    \\\"\\\"\\\"{laudo_texto}\\\"\\\"\\\"\n",
    "\n",
    "    ### Critérios de extração:\n",
    "\n",
    "    - **Receptor de Estrogênio**: retorne se é \"POSITIVO\", \"NEGATIVO\" ou \"NÃO INFORMADO\".\n",
    "\n",
    "    - **Receptor de Progesterona**: retorne se é \"POSITIVO\", \"NEGATIVO\" ou \"NÃO INFORMADO\".\n",
    "\n",
    "    - **Status do HER-2**: retorne se o Status do HER-2 é \"NEGATIVO\", \"INCONCLUSIVO\", \"POSITIVO\" ou \"NÃO INFORMADO\". Com base no score seguindo as regras:\n",
    "    - \"HER-2 - ESCORE 0\" ou \"1+\" → \"NEGATIVO\"\n",
    "    - \"HER-2 - ESCORE 2+\" → \"INCONCLUSIVO\"\n",
    "    - \"HER-2 - ESCORE 3+\" → \"POSITIVO\"\n",
    "\n",
    "    - **Ki-67 (%)**: retorne o valor numérico da porcentagem de positividade do KI-67.\n",
    "\n",
    "    - **Status do CK5/6**: retorne \"POSITIVO\", \"NEGATIVO\" ou \"NÃO INFORMADO\" do Status do CK5/6.\n",
    "\n",
    "    ### Saída esperada (dicionário Python válido):\n",
    "    ```python\n",
    "    {{\n",
    "    \"receptor_estrogeno\": \"POSITIVO\" | \"NEGATIVO\" |  \"NÃO INFORMADO\",\n",
    "    \"receptor_progesterona\": \"POSITIVO\" | \"NEGATIVO\" |  \"NÃO INFORMADO\",\n",
    "    \"status_her2\": \"POSITIVO\" | \"POSITIVO\" | \"INCONCLUSIVO\" |  \"NÃO INFORMADO\",\n",
    "    \"ki67_percentual\": float |  0,\n",
    "    \"status_ck5_6\": \"POSITIVO\" | \"NEGATIVO\" |  \"NÃO INFORMADO\"\n",
    "    }}\n",
    "    ```\n",
    "    \"\"\"\n",
    "    return prompt.strip()\n",
    "\n",
    "def generate(descricao_agente:str, laudo:str, llm_client) -> str:\n",
    "    \"\"\"\n",
    "    Gera o resultado da análise de um laudo\n",
    "    Params:\n",
    "        descricao_agente: descricao do agente que a LLM representa (primeira mensagem enviada à LLM)\n",
    "        prompt: prompt base que será utilizado para gerar a análise\n",
    "        laudo: laudo a ser analisado (incluido dentro do prompt)\n",
    "        llm_client: cliente da API da LLM\n",
    "    Return:\n",
    "        response_message: resposta da LLM\n",
    "    \"\"\"\n",
    "    prompt = prompt_laudo(laudo)\n",
    "    messages = [\n",
    "        # Utilizamos o primeiro prompt para contextualizar o llm do que ele deve fazer. \n",
    "        # No exemplo utilizamos a abordagem Role, Task, Output, Prompting.\n",
    "        # Mas sintam-se a vontade para alterar de acordo com a necessidade\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": descricao_agente\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ]\n",
    "    model_params = {\n",
    "        \"model\": \"databricks-llama-4-maverick\",\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0,\n",
    "        \"max_tokens\": 4000,\n",
    "        \"top_p\": 0.75,\n",
    "        \"frequency_penalty\": 0,\n",
    "        \"presence_penalty\": 0\n",
    "    }\n",
    "    connection_retry = 0\n",
    "    while connection_retry < 3:\n",
    "        try:\n",
    "            response = llm_client.chat.completions.create(**model_params)\n",
    "            response_message = response.choices[0].message.content\n",
    "            break\n",
    "        # TODO: verificar se a excessao é de conexao\n",
    "        except (ConnectionError, TimeoutError) as e:\n",
    "            connection_retry += 1\n",
    "            print(\"Sem reposta do modelo\")\n",
    "            print(str(e))\n",
    "            print(\"Tentando novamente...\")\n",
    "            time.sleep(0.1)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    if connection_retry >= 3:\n",
    "        response_message = ''\n",
    "    \n",
    "    return response_message\n",
    "\n",
    "\n",
    "def batch_generate(descricao_agente, laudos, llm_client, batch_size=25):\n",
    "    responses = []\n",
    "    \n",
    "    llm_client = openai.OpenAI(\n",
    "        api_key=DATABRICKS_TOKEN,\n",
    "        base_url=\"https://dbc-d80f50a9-af23.cloud.databricks.com/serving-endpoints\"\n",
    "    )\n",
    "    \n",
    "    # Dividir em lotes\n",
    "    for i in range(0, len(laudos), batch_size):\n",
    "        laudos_batch = laudos[i:i+batch_size]\n",
    "        for laudo in tqdm(laudos_batch, desc=f\"Processando lote {i//batch_size + 1}\", total=len(laudos_batch)):\n",
    "            responses.append(generate(descricao_agente, laudo, llm_client))\n",
    "    \n",
    "    return responses\n",
    "\n",
    "def limpar_e_converter(item):\n",
    "    try:\n",
    "        item_limpo = re.sub(r\"```(?:python)?\", \"\", item).replace(\"```\", \"\").strip()\n",
    "        return json.loads(item_limpo)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao converter resposta: {e}\")\n",
    "        return {\n",
    "            \"receptor_estrogeno\": \"NÃO INFORMADO\",\n",
    "            \"receptor_progesterona\": \"NÃO INFORMADO\",\n",
    "            \"status_her2\": \"NÃO INFORMADO\",\n",
    "            \"ki67_percentual\": \"NÃO INFORMADO\",\n",
    "            \"status_ck5_6\": \"NÃO INFORMADO\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eb2be4",
   "metadata": {},
   "source": [
    "## Implementação de Funções de Extração Heurística\n",
    "\n",
    "Esta célula implementa um conjunto de funções baseadas em regras (expressões regulares) para extração de informações dos laudos, criando um mecanismo \"pseudo-gold standard\" que pode ser usado para avaliar e comparar os resultados do modelo de linguagem. O código está organizado em várias funções especializadas:\n",
    "\n",
    "### 1. Funções Específicas de Extração\n",
    "\n",
    "Cinco funções extraem informações específicas dos laudos usando expressões regulares:\n",
    "\n",
    "#### a) `extrai_receptor_estrogeno(txt)`\n",
    "- Busca termos como \"receptor de estrogenio: positivo\" \n",
    "- Busca abreviações como \"ER+\" ou \"ER-\"\n",
    "- Retorna \"POSITIVO\", \"NEGATIVO\" ou \"NÃO INFORMADO\"\n",
    "\n",
    "#### b) `extrai_receptor_progesterona(txt)`\n",
    "- Similar à função anterior, mas para receptor de progesterona\n",
    "- Busca padrões como \"receptor de progesterona: positivo\" \n",
    "- Busca abreviações como \"PR+\" ou \"PR-\"\n",
    "- Retorna \"POSITIVO\", \"NEGATIVO\" ou \"NÃO INFORMADO\"\n",
    "\n",
    "#### c) `extrai_status_her2(txt)`\n",
    "- Implementa lógica complexa para interpretar escores HER-2\n",
    "- Identifica padrões como \"her-2 escore X+\" ou \"her2 X+\"\n",
    "- Classifica baseado no escore: 0/1+ como \"NEGATIVO\", 2+ como \"INCONCLUSIVO\", 3+ como \"POSITIVO\"\n",
    "- Retorna \"NEGATIVO\", \"INCONCLUSIVO\", \"POSITIVO\" ou \"NÃO INFORMADO\"\n",
    "\n",
    "#### d) `extrai_ki67_percentual(txt)`\n",
    "- Extrai o valor numérico da porcentagem de Ki-67\n",
    "- Busca padrões como \"ki-67: 20%\" ou \"ki 67 15 %\"\n",
    "- Converte o valor encontrado para float\n",
    "- Retorna um valor float ou 0.0 se não encontrado\n",
    "\n",
    "#### e) `extrai_status_ck5_6(txt)`\n",
    "- Busca padrões como \"ck5/6: positivo\" ou \"ck5/6: negativo\"\n",
    "- Busca abreviações como \"CK5/6+\" ou \"CK5/6-\"\n",
    "- Retorna \"POSITIVO\", \"NEGATIVO\" ou \"NÃO INFORMADO\"\n",
    "\n",
    "### 2. Função de Avaliação Integrada\n",
    "\n",
    "A função `avalia_extracao_sem_ground_truth_novo(laudo_texto, json_modelo)` é o coração da avaliação:\n",
    "\n",
    "- **Geração de Gold Standard**: Aplica as funções de extração ao texto do laudo para criar um dicionário `json_heu` com os resultados da extração baseada em regras\n",
    "- **Preparação do Modelo**: Verifica se `json_modelo` é um dicionário válido, tratando casos onde não é\n",
    "- **Comparação Campo a Campo**: Para cada campo (receptores, HER-2, CK5/6), compara os valores extraídos heuristicamente com os valores do modelo\n",
    "- **Tratamento Especial para Ki-67**: Converte o valor do modelo para float para comparação adequada\n",
    "- **Resultado da Avaliação**: Retorna dois elementos:\n",
    "  1. `json_heu`: Dicionário com os valores extraídos heuristicamente\n",
    "  2. `comparacoes`: Dicionário detalhado de comparações para cada campo, incluindo valores extraídos por ambos os métodos e flag de acerto\n",
    "\n",
    "Esta abordagem de avaliação é valiosa porque permite validar o desempenho do modelo de linguagem mesmo sem um conjunto de dados rotulado manualmente, usando regras heurísticas como referência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adf9efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "#import ace_tools as tools\n",
    "\n",
    "# ==============================================\n",
    "# Funções de extração heurística (pseudo-gold) para o novo prompt\n",
    "# ==============================================\n",
    "\n",
    "def extrai_receptor_estrogeno(txt: str) -> str:\n",
    "    \"\"\"\n",
    "    Extrai o status de Receptor de Estrogênio: valores possíveis\n",
    "    \"POSITIVO\", \"NEGATIVO\" ou retorna \"NÃO INFORMADO\".\n",
    "    \"\"\"\n",
    "    txt_lower = txt.lower()\n",
    "    # Padrões comuns: \"receptor de estrogênio: positivo\" ou \"er+: positivo\" etc.\n",
    "    if re.search(r\"receptor\\s+de\\s+estrog[eê]genio\\s*[:\\-]?\\s*positivo\", txt_lower):\n",
    "        return \"POSITIVO\"\n",
    "    if re.search(r\"receptor\\s+de\\s+estrog[eê]genio\\s*[:\\-]?\\s*negativo\", txt_lower):\n",
    "        return \"NEGATIVO\"\n",
    "    # Abreviações: \"ER+\" / \"ER-\"\n",
    "    if re.search(r\"\\ber\\s*[\\+]\\b\", txt, flags=re.IGNORECASE):\n",
    "        return \"POSITIVO\"\n",
    "    if re.search(r\"\\ber\\s*[\\-]\\b\", txt, flags=re.IGNORECASE):\n",
    "        return \"NEGATIVO\"\n",
    "    return \"NÃO INFORMADO\"\n",
    "\n",
    "def extrai_receptor_progesterona(txt: str) -> str:\n",
    "    \"\"\"\n",
    "    Extrai o status de Receptor de Progesterona: valores possíveis\n",
    "    \"POSITIVO\", \"NEGATIVO\" ou retorna \"NÃO INFORMADO\".\n",
    "    \"\"\"\n",
    "    txt_lower = txt.lower()\n",
    "    if re.search(r\"receptor\\s+de\\s+progesterona\\s*[:\\-]?\\s*positivo\", txt_lower):\n",
    "        return \"POSITIVO\"\n",
    "    if re.search(r\"receptor\\s+de\\s+progesterona\\s*[:\\-]?\\s*negativo\", txt_lower):\n",
    "        return \"NEGATIVO\"\n",
    "    # Abreviações: \"PR+\" / \"PR-\"\n",
    "    if re.search(r\"\\bpr\\s*[\\+]\\b\", txt, flags=re.IGNORECASE):\n",
    "        return \"POSITIVO\"\n",
    "    if re.search(r\"\\bpr\\s*[\\-]\\b\", txt, flags=re.IGNORECASE):\n",
    "        return \"NEGATIVO\"\n",
    "    return \"NÃO INFORMADO\"\n",
    "\n",
    "def extrai_status_her2(txt: str) -> str:\n",
    "    \"\"\"\n",
    "    Extrai o Status do HER-2 baseado em termos de score:\n",
    "    - \"HER-2 - ESCORE 0\" ou \"1+\" → \"NEGATIVO\"\n",
    "    - \"HER-2 - ESCORE 2+\" → \"INCONCLUSIVO\"\n",
    "    - \"HER-2 - ESCORE 3+\" → \"POSITIVO\"\n",
    "    \"\"\"\n",
    "    txt_lower = txt.lower()\n",
    "    # Primeiro, busca padrão \"her-2 ... escore X+\"\n",
    "    m = re.search(r\"her[-\\s]?2.*?escore\\s*[:\\-]?\\s*([0-3]\\+?)\", txt_lower, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        score = m.group(1)\n",
    "        if score.startswith(\"0\") or score == \"1+\":\n",
    "            return \"NEGATIVO\"\n",
    "        if score == \"2+\":\n",
    "            return \"INCONCLUSIVO\"\n",
    "        if score == \"3+\":\n",
    "            return \"POSITIVO\"\n",
    "    # Outra forma: \"her2 3+\" isolado\n",
    "    m2 = re.search(r\"\\bher[-]?2\\s*[:\\-]?\\s*([0-3]\\+)\\b\", txt_lower, flags=re.IGNORECASE)\n",
    "    if m2:\n",
    "        score2 = m2.group(1)\n",
    "        if score2 == \"1+\":\n",
    "            return \"NEGATIVO\"\n",
    "        if score2 == \"2+\":\n",
    "            return \"INCONCLUSIVO\"\n",
    "        if score2 == \"3+\":\n",
    "            return \"POSITIVO\"\n",
    "    return \"NÃO INFORMADO\"\n",
    "\n",
    "def extrai_ki67_percentual(txt: str) -> float:\n",
    "    \"\"\"\n",
    "    Extrai o valor de Ki-67 em porcentagem. \n",
    "    Exemplo no texto: \"Ki-67: 20%\", \"Ki 67 15 %\", etc.\n",
    "    Se não encontrar, retorna 0.0.\n",
    "    \"\"\"\n",
    "    m = re.search(r\"ki[-\\s]?67.*?[:\\-]?\\s*(\\d{1,3}(?:\\.\\d+)?)\\s*%\", txt, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        try:\n",
    "            return float(m.group(1))\n",
    "        except ValueError:\n",
    "            return 0.0\n",
    "    return 0.0\n",
    "\n",
    "def extrai_status_ck5_6(txt: str) -> str:\n",
    "    \"\"\"\n",
    "    Extrai o status do CK5/6: \"POSITIVO\", \"NEGATIVO\" ou retorna \"NÃO INFORMADO\".\n",
    "    \"\"\"\n",
    "    txt_lower = txt.lower()\n",
    "    if re.search(r\"ck5\\s*\\/\\s*6.*?[:\\-]?\\s*positivo\", txt_lower):\n",
    "        return \"POSITIVO\"\n",
    "    if re.search(r\"ck5\\s*\\/\\s*6.*?[:\\-]?\\s*negativo\", txt_lower):\n",
    "        return \"NEGATIVO\"\n",
    "    # Abreviações: \"CK5/6+\" ou \"CK5/6-\"\n",
    "    if re.search(r\"\\bck5\\s*\\/\\s*6\\s*[\\+]\\b\", txt, flags=re.IGNORECASE):\n",
    "        return \"POSITIVO\"\n",
    "    if re.search(r\"\\bck5\\s*\\/\\s*6\\s*[\\-]\\b\", txt, flags=re.IGNORECASE):\n",
    "        return \"NEGATIVO\"\n",
    "    return \"NÃO INFORMADO\"\n",
    "\n",
    "# ==============================================\n",
    "# Função de avaliação sem ground truth completo (novo conjunto de campos)\n",
    "# ==============================================\n",
    "\n",
    "def avalia_extracao_sem_ground_truth_novo(laudo_texto: str, json_modelo: dict):\n",
    "    \"\"\"\n",
    "    Gera pseudo-gold (json_heu) para os campos do novo prompt\n",
    "    e compara com json_modelo (saída da IA).\n",
    "    Retorna:\n",
    "      - json_heu: dicionário com valores heurísticos\n",
    "      - comparacoes: dicionário que, para cada campo, traz:\n",
    "          * valor_heu\n",
    "          * valor_mod\n",
    "          * acertou (boolean)\n",
    "    \"\"\"\n",
    "    # 1. Gera pseudo-gold (json_heu)\n",
    "    rei = extrai_receptor_estrogeno(laudo_texto)\n",
    "    rpr = extrai_receptor_progesterona(laudo_texto)\n",
    "    her = extrai_status_her2(laudo_texto)\n",
    "    ki6 = extrai_ki67_percentual(laudo_texto)\n",
    "    ck6 = extrai_status_ck5_6(laudo_texto)\n",
    "\n",
    "    json_heu = {\n",
    "        \"receptor_estrogeno\": rei,\n",
    "        \"receptor_progesterona\": rpr,\n",
    "        \"status_her2\": her,\n",
    "        \"ki67_percentual\": ki6,\n",
    "        \"status_ck5_6\": ck6\n",
    "    }\n",
    "\n",
    "    # 2. Prepara json_modelo: se não for dict, converte para dict vazio\n",
    "    if not isinstance(json_modelo, dict):\n",
    "        json_modelo = {}\n",
    "\n",
    "    # 3. Comparações campo a campo\n",
    "    comparacoes = {}\n",
    "\n",
    "    # Campos categóricos (strings)\n",
    "    for campo in [\"receptor_estrogeno\", \"receptor_progesterona\", \"status_her2\", \"status_ck5_6\"]:\n",
    "        val_heu = json_heu[campo]\n",
    "        val_mod = json_modelo.get(campo, \"NÃO INFORMADO\")\n",
    "        comparacoes[campo] = {\n",
    "            \"valor_heu\": val_heu,\n",
    "            \"valor_mod\": val_mod,\n",
    "            \"acertou\": (val_heu == val_mod)\n",
    "        }\n",
    "\n",
    "    # Campo Ki-67 (%)\n",
    "    val_heu_ki = json_heu[\"ki67_percentual\"]\n",
    "    try:\n",
    "        val_mod_ki = float(json_modelo.get(\"ki67_percentual\", 0))\n",
    "    except (ValueError, TypeError):\n",
    "        val_mod_ki = 0.0\n",
    "    comparacoes[\"ki67_percentual\"] = {\n",
    "        \"valor_heu\": val_heu_ki,\n",
    "        \"valor_mod\": val_mod_ki,\n",
    "        \"acertou\": (val_heu_ki == val_mod_ki)\n",
    "    }\n",
    "\n",
    "    return json_heu, comparacoes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ba7f1a",
   "metadata": {},
   "source": [
    "## Função de Parse para Strings JSON\n",
    "\n",
    "Esta célula define uma função auxiliar `parse_json_string()` que proporciona uma maneira segura de converter strings contendo representações de dicionários Python para objetos dicionários reais.\n",
    "\n",
    "```python\n",
    "def parse_json_string(s):\n",
    "    if isinstance(s, str):\n",
    "        try:\n",
    "            return ast.literal_eval(s)\n",
    "        except Exception:\n",
    "            return {}\n",
    "    return s\n",
    "```\n",
    "\n",
    "A função opera da seguinte forma:\n",
    "\n",
    "1. **Verificação de Tipo**: Primeiro verifica se a entrada `s` é do tipo string, garantindo que a conversão só seja tentada em objetos apropriados\n",
    "  \n",
    "2. **Conversão Segura**: Usa `ast.literal_eval()` em vez de `eval()` para avaliar a string como uma expressão literal Python. Esta é uma abordagem muito mais segura que `eval()`, pois:\n",
    "   - Só avalia expressões literais de Python (não executa código arbitrário)\n",
    "   - Aceita apenas tipos básicos como dicionários, listas, strings, números, etc.\n",
    "   - Previne a execução de código malicioso ou não intencional\n",
    "\n",
    "3. **Tratamento de Erros**: Captura quaisquer exceções durante a avaliação e retorna um dicionário vazio `{}` em caso de falha, garantindo que um objeto válido sempre será retornado\n",
    "\n",
    "4. **Passagem Direta**: Se a entrada não for uma string, simplesmente retorna a própria entrada sem modificação\n",
    "\n",
    "Esta função é especialmente útil para processar as respostas do modelo de linguagem que foram armazenadas como strings mas representam estruturas de dados JSON. Ela garante que o processamento continue mesmo quando há problemas de formatação nas respostas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b2fe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_string(s):\n",
    "    if isinstance(s, str):\n",
    "        try:\n",
    "            return ast.literal_eval(s)\n",
    "        except Exception:\n",
    "            return {}\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d5f972",
   "metadata": {},
   "source": [
    "## Função para Agregação de Resultados de Avaliação\n",
    "\n",
    "Esta célula implementa uma função flexível para agregar resultados de avaliação entre múltiplos laudos, fornecendo métricas de desempenho para cada campo extraído.\n",
    "\n",
    "```python\n",
    "def agrega_resultados_dinamico(lista_comparacoes):\n",
    "    \"\"\"\n",
    "    Agraga resultados de uma lista de dicionários de comparações, retornando para cada campo:\n",
    "      - acertos: número de vezes que 'acertou' == True\n",
    "      - total: número total de laudos (len(lista_comparacoes))\n",
    "      - taxa_acerto: acertos / total (ou 0.0 se total == 0)\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "### Componentes Principais:\n",
    "\n",
    "1. **Estrutura de Entrada**:\n",
    "   - `lista_comparacoes`: Uma lista de dicionários, onde cada dicionário contém os resultados de comparação para um laudo\n",
    "   - Cada comparação tem campos como \"receptor_estrogeno\", \"status_her2\", etc., cada um com seu próprio dicionário contendo a chave \"acertou\"\n",
    "\n",
    "2. **Contagem de Acertos**:\n",
    "   ```python\n",
    "   total_laudos = len(lista_comparacoes)\n",
    "   acertos_por_campo = Counter()\n",
    "   \n",
    "   for comp in lista_comparacoes:\n",
    "       for campo, info in comp.items():\n",
    "           if info.get(\"acertou\", False):\n",
    "               acertos_por_campo[campo] += 1\n",
    "   ```\n",
    "   - Utiliza `Counter` da biblioteca `collections` para contabilizar eficientemente os acertos\n",
    "   - Percorre cada comparação e cada campo, incrementando o contador quando \"acertou\" é verdadeiro\n",
    "\n",
    "3. **Geração de Métricas**:\n",
    "   ```python\n",
    "   resultado = {}\n",
    "   for campo, acertos in acertos_por_campo.items():\n",
    "       resultado[campo] = {\n",
    "           \"acertos\": acertos,\n",
    "           \"total\": total_laudos,\n",
    "           \"taxa_acerto\": (acertos / total_laudos) if total_laudos > 0 else 0.0\n",
    "       }\n",
    "   ```\n",
    "   - Para cada campo, calcula três métricas:\n",
    "     - `acertos`: Total de acertos para o campo específico\n",
    "     - `total`: Número total de laudos avaliados\n",
    "     - `taxa_acerto`: Proporção de acertos (com proteção contra divisão por zero)\n",
    "\n",
    "4. **Tratamento de Campos Ausentes**:\n",
    "   ```python\n",
    "   if lista_comparacoes:\n",
    "       primeira = lista_comparacoes[0]\n",
    "       for campo in primeira.keys():\n",
    "           if campo not in resultado:\n",
    "               resultado[campo] = {\"acertos\": 0, \"total\": total_laudos, \"taxa_acerto\": 0.0}\n",
    "   ```\n",
    "   - Garante que todos os campos presentes nas comparações estejam representados nos resultados\n",
    "   - Inicializa campos não encontrados com zero acertos\n",
    "\n",
    "Esta função é essencial para a análise quantitativa do desempenho do sistema de extração, permitindo avaliar a precisão para cada tipo de informação extraída dos laudos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7564ad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def agrega_resultados_dinamico(lista_comparacoes):\n",
    "    \"\"\"\n",
    "    Agraga resultados de uma lista de dicionários de comparações, retornando para cada campo:\n",
    "      - acertos: número de vezes que 'acertou' == True\n",
    "      - total: número total de laudos (len(lista_comparacoes))\n",
    "      - taxa_acerto: acertos / total (ou 0.0 se total == 0)\n",
    "    \n",
    "    Suporta qualquer conjunto de chaves em cada dict, desde que cada valor seja outro dict contendo a chave 'acertou'.\n",
    "    \"\"\"\n",
    "    total_laudos = len(lista_comparacoes)\n",
    "    acertos_por_campo = Counter()\n",
    "\n",
    "    # Para cada comparação, percorremos todas as chaves e contamos os acertos\n",
    "    for comp in lista_comparacoes:\n",
    "        for campo, info in comp.items():\n",
    "            # Supondo que info seja um dict com a chave \"acertou\"\n",
    "            if info.get(\"acertou\", False):\n",
    "                acertos_por_campo[campo] += 1\n",
    "\n",
    "    # Monta o dicionário de saída\n",
    "    resultado = {}\n",
    "    for campo, acertos in acertos_por_campo.items():\n",
    "        resultado[campo] = {\n",
    "            \"acertos\": acertos,\n",
    "            \"total\": total_laudos,\n",
    "            \"taxa_acerto\": (acertos / total_laudos) if total_laudos > 0 else 0.0\n",
    "        }\n",
    "\n",
    "    # É possível que exista algum campo em alguma comparação que nunca teve 'acertou' == True.\n",
    "    # Se quisermos incluir também esses campos (com acertos = 0), podemos varrer as chaves da primeira entrada:\n",
    "    if lista_comparacoes:\n",
    "        primeira = lista_comparacoes[0]\n",
    "        for campo in primeira.keys():\n",
    "            if campo not in resultado:\n",
    "                resultado[campo] = {\n",
    "                    \"acertos\": 0,\n",
    "                    \"total\": total_laudos,\n",
    "                    \"taxa_acerto\": 0.0\n",
    "                }\n",
    "\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16e34b0",
   "metadata": {},
   "source": [
    "## Processamento Principal: Extração e Classificação de Biomarcadores\n",
    "\n",
    "Esta célula contém o bloco principal de execução do notebook, orquestrando o processo completo de extração de informações dos laudos imunohistoquímicos usando o modelo de linguagem. O código está estruturado como um condicional que só executa se existirem registros a serem processados.\n",
    "\n",
    "### Fluxo de Execução\n",
    "\n",
    "O processamento ocorre nas seguintes etapas:\n",
    "\n",
    "1. **Verificação da Disponibilidade de Dados**:\n",
    "   ```python\n",
    "   if df_spk.count() > 0:\n",
    "   ```\n",
    "   Só prossegue com o processamento se houver registros no DataFrame `df_spk`.\n",
    "\n",
    "2. **Inicialização do Cliente LLM**:\n",
    "   ```python\n",
    "   llm_client = openai.OpenAI(api_key=DATABRICKS_TOKEN,\n",
    "                           base_url=\"https://dbc-d80f50a9-af23.cloud.databricks.com/serving-endpoints\")\n",
    "   ```\n",
    "   Configura o cliente para acessar o endpoint do modelo no Databricks.\n",
    "\n",
    "3. **Definição do Sistema Prompt**:\n",
    "   ```python\n",
    "   descricao_agente = \"Atue como um médico oncologista especialista em laudos de mamografia.\"\n",
    "   ```\n",
    "   Estabelece o contexto para o modelo, instruindo-o a adotar a persona de um especialista médico.\n",
    "\n",
    "4. **Preparação dos Dados**:\n",
    "   ```python\n",
    "   df_local = df_spk.select(\"ficha\",\"id_exame\",\"id_marca\",\"sequencial\",\"laudo_tratado\").toPandas()\n",
    "   ```\n",
    "   Converte um subconjunto do DataFrame Spark para Pandas para facilitar o processamento.\n",
    "\n",
    "5. **Processamento com o Modelo LLM**:\n",
    "   ```python\n",
    "   respostas = batch_generate(descricao_agente, df_local[\"laudo_tratado\"].tolist(), llm_client, batch_size=100)\n",
    "   respostas_limpa = [limpar_e_converter(item) for item in respostas]\n",
    "   ```\n",
    "   Envia os laudos para o modelo em lotes de 100, processa as respostas e converte para dicionários Python.\n",
    "\n",
    "6. **Integração de Resultados**:\n",
    "   ```python\n",
    "   df_local[\"resposta_llm\"] = respostas_limpa\n",
    "   df_respostas = spark.createDataFrame(df_local)\n",
    "   ```\n",
    "   Adiciona as respostas ao DataFrame e converte de volta para Spark.\n",
    "\n",
    "7. **Junção com Dados Originais**:\n",
    "   ```python\n",
    "   df_final = df_spk.join(df_respostas.select(\"ficha\",\"id_exame\",\"id_marca\",\"sequencial\",\"resposta_llm\"), \n",
    "                          on=[\"ficha\",\"id_exame\",\"id_marca\",\"sequencial\"], how=\"inner\")\n",
    "   ```\n",
    "   Combina as respostas com todos os campos dos dados originais.\n",
    "\n",
    "8. **Expansão das Respostas em Colunas**:\n",
    "   ```python\n",
    "   df_final_expanded = df_final_expanded.select(\n",
    "       \"*\",\n",
    "       col(\"resposta_struct.receptor_estrogeno\").alias(\"receptor_estrogeno\"),\n",
    "       # ... outras colunas ...\n",
    "   ).drop(\"resposta_struct\")\n",
    "   ```\n",
    "   Extrai cada campo do JSON de resposta como uma coluna individual.\n",
    "\n",
    "9. **Classificação Molecular**:\n",
    "   ```python\n",
    "   df_final_classif = df_final_expanded.withColumn(\n",
    "       \"categoria_final\",\n",
    "       F.when(\n",
    "           (\n",
    "               ((F.col(\"receptor_estrogeno\") == \"POSITIVO\") | (F.col(\"receptor_progesterona\") == \"POSITIVO\")) &\n",
    "               (F.col(\"status_her2\") == \"NEGATIVO\") &\n",
    "               (F.col(\"ki67_percentual\") < 14)\n",
    "           ),\n",
    "           \"Luminal A\"\n",
    "       )\n",
    "       # ... outras categorias ...\n",
    "   )\n",
    "   ```\n",
    "   Aplica regras de classificação molecular baseadas nos biomarcadores, categorizando cada caso como:\n",
    "   - **Luminal A**: RE+ ou RP+, HER2-, Ki-67 < 14%\n",
    "   - **Luminal B**: RE+ ou RP+, HER2-, Ki-67 >= 14%\n",
    "   - **Luminal com HER2 Positivo**: RE+ ou RP+, HER2+\n",
    "   - **HER-2 Superexpresso**: RE-, RP-, HER2+\n",
    "   - **Triplo Negativo**: RE-, RP-, HER2-\n",
    "\n",
    "10. **Visualização dos Resultados**:\n",
    "    ```python\n",
    "    display(df_final_classif)\n",
    "    ```\n",
    "    Exibe o DataFrame final com todas as informações extraídas e classificações.\n",
    "\n",
    "### Métricas e Avaliação (Comentadas)\n",
    "\n",
    "O código também inclui seções comentadas para:\n",
    "- Cálculo de métricas de validação\n",
    "- Comparação com extração heurística\n",
    "- Registro de métricas via MLflow\n",
    "\n",
    "Esta célula representa o núcleo funcional do notebook, transformando os laudos textuais não estruturados em informações clinicamente relevantes e estruturadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d27639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, LongType, IntegerType\n",
    "from pyspark.sql.functions import from_json, col\n",
    "from pyspark.sql.functions import col, pandas_udf\n",
    "from pyspark.sql.types import StringType\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "if df_spk.count() > 0:\n",
    "    llm_client = openai.OpenAI(api_key=DATABRICKS_TOKEN,\n",
    "                           base_url=\"https://dbc-d80f50a9-af23.cloud.databricks.com/serving-endpoints\"\n",
    "                           )\n",
    "    descricao_agente = \"Atue como um médico oncologista especialista em laudos de mamografia.\"\n",
    "\n",
    "    # Coleta os dados \n",
    "    df_local = df_spk.select(\"ficha\",\"id_exame\",\"id_marca\",\"sequencial\",\"laudo_tratado\").toPandas()\n",
    "\n",
    "    # Aplica o LLM \n",
    "    respostas = batch_generate(descricao_agente, df_local[\"laudo_tratado\"].tolist(), llm_client, batch_size=100)\n",
    "    respostas_limpa = [limpar_e_converter(item) for item in respostas]\n",
    "\n",
    "    # Adiciona as respostas ao DataFrame\n",
    "    df_local[\"resposta_llm\"] = respostas_limpa\n",
    "\n",
    "    # Converte de volta para Spark\n",
    "    df_respostas = spark.createDataFrame(df_local)\n",
    "\n",
    "    # Faz join com o DataFrame original para manter todas as colunas\n",
    "    df_final = df_spk.join(df_respostas.select(\"ficha\",\"id_exame\",\"id_marca\",\"sequencial\",\"resposta_llm\"), on=[\"ficha\",\"id_exame\",\"id_marca\",\"sequencial\"], how=\"inner\")\n",
    "\n",
    "    # Definir estrutura\n",
    "    schema_resposta = StructType([\n",
    "    StructField(\"receptor_estrogeno\", StringType(), True),\n",
    "    StructField(\"receptor_progesterona\", StringType(), True),\n",
    "    StructField(\"status_her2\", StringType(), True),\n",
    "    StructField(\"ki67_percentual\", DoubleType(), True),\n",
    "    StructField(\"status_ck5_6\", DoubleType(), True),\n",
    "    ])\n",
    "\n",
    "    df_final_expanded = df_final.withColumn(\"resposta_struct\", col(\"resposta_llm\"))\n",
    "\n",
    "    # expandir resultado llma para colunas\n",
    "\n",
    "    df_final_expanded = df_final_expanded.select(\n",
    "    \"*\",\n",
    "    col(\"resposta_struct.receptor_estrogeno\").alias(\"receptor_estrogeno\"),\n",
    "    col(\"resposta_struct.receptor_progesterona\").alias(\"receptor_progesterona\"),\n",
    "    col(\"resposta_struct.status_her2\").alias(\"status_her2\"),\n",
    "    col(\"resposta_struct.ki67_percentual\").alias(\"ki67_percentual\"),\n",
    "    col(\"resposta_struct.status_ck5_6\").alias(\"status_ck5_6\"),\n",
    "    ).drop(\"resposta_struct\")\n",
    "\n",
    "    #display(df_final_expanded)\n",
    "\n",
    "    # a partir dos dados extraídos definir uma classificação final\n",
    "    df_final_classif = df_final_expanded.withColumn(\n",
    "            \"categoria_final\",\n",
    "            F.when(\n",
    "                (\n",
    "                    ((F.col(\"receptor_estrogeno\") == \"POSITIVO\") | (F.col(\"receptor_progesterona\") == \"POSITIVO\")) &\n",
    "                    (F.col(\"status_her2\") == \"NEGATIVO\") &\n",
    "                    (F.col(\"ki67_percentual\") < 14)\n",
    "                ),\n",
    "                \"Luminal A\"\n",
    "            ).when(\n",
    "                (\n",
    "                    ((F.col(\"receptor_estrogeno\") == \"POSITIVO\") | (F.col(\"receptor_progesterona\") == \"POSITIVO\")) &\n",
    "                    (F.col(\"status_her2\") == \"NEGATIVO\") &\n",
    "                    (F.col(\"ki67_percentual\") >= 14)\n",
    "                ),\n",
    "                \"Luminal B\"\n",
    "            ).when(\n",
    "                (\n",
    "                    ((F.col(\"receptor_estrogeno\") == \"POSITIVO\") | (F.col(\"receptor_progesterona\") == \"POSITIVO\")) &\n",
    "                    (F.col(\"status_her2\") == \"POSITIVO\")\n",
    "                ),\n",
    "                \"Luminal com HER2 Positivo\"\n",
    "            ).when(\n",
    "                (\n",
    "                    (F.col(\"receptor_estrogeno\") == \"NEGATIVO\") &\n",
    "                    (F.col(\"receptor_progesterona\") == \"NEGATIVO\") &\n",
    "                    (F.col(\"status_her2\") == \"POSITIVO\")\n",
    "                ),\n",
    "                \"HER-2 Superexpresso\"\n",
    "            ).when(\n",
    "                (\n",
    "                    (F.col(\"receptor_estrogeno\") == \"NEGATIVO\") &\n",
    "                    (F.col(\"receptor_progesterona\") == \"NEGATIVO\") &\n",
    "                    (F.col(\"status_her2\") == \"NEGATIVO\")\n",
    "                ),\n",
    "                \"Triplo Negativo\"\n",
    "            ).otherwise(\"Indefinido\")\n",
    "        )\n",
    "\n",
    "    display(df_final_classif)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # ###################### Apenas para testes #################\n",
    "    # df_imunohistoquimico = df_imunohistoquimico.limit(100)\n",
    "    # ###########################################################\n",
    "\n",
    "    # rows = df_imunohistoquimico.select(\"laudo_tratado\").collect()\n",
    "    # laudos = [row.laudo_tratado for row in rows]\n",
    "\n",
    "    # respostas = batch_generate(descricao_agente, laudos, llm_client, batch_size=10)\n",
    "\n",
    "    # lista_dicts = [limpar_e_converter(item) for item in respostas]\n",
    "\n",
    "    # schema = StructType([\n",
    "    #     StructField(\"receptor_estrogeno\", StringType(), True),\n",
    "    #     StructField(\"receptor_progesterona\", StringType(), True),\n",
    "    #     StructField(\"status_her2\", StringType(), True),\n",
    "    #     StructField(\"ki67_percentual\", StringType(), True),\n",
    "    #     StructField(\"status_ck5_6\", StringType(), True),\n",
    "    # ])\n",
    "\n",
    "    # df_lista = spark.createDataFrame(lista_dicts, schema=schema)\n",
    "\n",
    "    # w = Window.orderBy(F.lit(1))\n",
    "\n",
    "    # df_imuno_indexed = (\n",
    "    #     df_imunohistoquimico\n",
    "    #     .withColumn(\"row_id\", F.row_number().over(w) - 1)  # subtrai 1 para ficar zero‐based\n",
    "    # )\n",
    "\n",
    "    # df_lista_indexed = (\n",
    "    #     df_lista\n",
    "    #     .withColumn(\"row_id\", F.row_number().over(w) - 1)\n",
    "    # )\n",
    "\n",
    "    # df_final = df_imuno_indexed.join(df_lista_indexed, on=\"row_id\").drop(\"row_id\")\n",
    "\n",
    "    # df_final = df_final.withColumn(\n",
    "    #     \"categoria_final\",\n",
    "    #     F.when(\n",
    "    #         (\n",
    "    #             ((F.col(\"receptor_estrogeno\") == \"POSITIVO\") | (F.col(\"receptor_progesterona\") == \"POSITIVO\")) &\n",
    "    #             (F.col(\"status_her2\") == \"NEGATIVO\") &\n",
    "    #             (F.col(\"ki67_percentual\") < 14)\n",
    "    #         ),\n",
    "    #         \"Luminal A\"\n",
    "    #     ).when(\n",
    "    #         (\n",
    "    #             ((F.col(\"receptor_estrogeno\") == \"POSITIVO\") | (F.col(\"receptor_progesterona\") == \"POSITIVO\")) &\n",
    "    #             (F.col(\"status_her2\") == \"NEGATIVO\") &\n",
    "    #             (F.col(\"ki67_percentual\") >= 14)\n",
    "    #         ),\n",
    "    #         \"Luminal B\"\n",
    "    #     ).when(\n",
    "    #         (\n",
    "    #             ((F.col(\"receptor_estrogeno\") == \"POSITIVO\") | (F.col(\"receptor_progesterona\") == \"POSITIVO\")) &\n",
    "    #             (F.col(\"status_her2\") == \"POSITIVO\")\n",
    "    #         ),\n",
    "    #         \"Luminal com HER2 Positivo\"\n",
    "    #     ).when(\n",
    "    #         (\n",
    "    #             (F.col(\"receptor_estrogeno\") == \"NEGATIVO\") &\n",
    "    #             (F.col(\"receptor_progesterona\") == \"NEGATIVO\") &\n",
    "    #             (F.col(\"status_her2\") == \"POSITIVO\")\n",
    "    #         ),\n",
    "    #         \"HER-2 Superexpresso\"\n",
    "    #     ).when(\n",
    "    #         (\n",
    "    #             (F.col(\"receptor_estrogeno\") == \"NEGATIVO\") &\n",
    "    #             (F.col(\"receptor_progesterona\") == \"NEGATIVO\") &\n",
    "    #             (F.col(\"status_her2\") == \"NEGATIVO\")\n",
    "    #         ),\n",
    "    #         \"Triplo Negativo\"\n",
    "    #     ).otherwise(\"INDEFINIDO\")\n",
    "    # )\n",
    "\n",
    "    # Base histórica\n",
    "    #fs = FeatureStoreClient()\n",
    "    #fs.create_table(\n",
    "    #    name=\"refined.saude_preventiva.pardini_laudos_mamo_imunohistoquimico\",\n",
    "    #    primary_keys=[\"id_unidade\", \"id_cliente\", \"id_item\", \"id_subitem\", \"id_exame\"],\n",
    "    #    schema=df_final.schema,\n",
    "    #    description=\"Features extraídas de laudos de mamografia. Siglas: IH-NEO e IHMAMA\"\n",
    "    #)\n",
    "\n",
    "    # Append em prd\n",
    "    #num_linhas = df_final.count()\n",
    "    #fs = FeatureStoreClient()\n",
    "    #if num_linhas > 0:\n",
    "    #    print(f\"Há {num_linhas} registros para inserir — executando gravação…\")\n",
    "    #    primary_keys = [\"id_unidade\", \"id_cliente\", \"id_item\", \"id_subitem\", \"id_exame\"]\n",
    "    #    ###### Apenas para testes ##############\n",
    "    #    df_final = df_final.dropna()\n",
    "    #    df_final = df_final.dropDuplicates(primary_keys)\n",
    "    #    ########################################\n",
    "    #    fs.write_table(\n",
    "    #        name=\"refined.saude_preventiva.pardini_laudos_mamo_imunohistoquimico\",\n",
    "    #        df=df_final,\n",
    "    #        mode=\"merge\",\n",
    "    #    )\n",
    "    #else:\n",
    "    #    print(\"Nenhum registro encontrado; nada a fazer.\")\n",
    "\n",
    "    df_metrics = pd.DataFrame()\n",
    "    df_metrics[\"laudos\"] = laudos\n",
    "    df_metrics[\"resultados\"] = lista_dicts\n",
    "\n",
    "    df_metrics[\"resultados\"] = df_metrics[\"resultados\"].apply(parse_json_string)\n",
    "\n",
    "    lista_laudos2 = df_metrics[\"laudos\"].tolist()\n",
    "    lista_modelo2 = df_metrics[\"resultados\"].tolist()\n",
    "\n",
    "    lista_pseudo_gold2 = []\n",
    "    lista_comparacoes2 = []\n",
    "\n",
    "    for laudo_txt, json_mod in zip(lista_laudos2, lista_modelo2):\n",
    "        json_heu, comp = avalia_extracao_sem_ground_truth_novo(laudo_txt, json_mod)\n",
    "        lista_pseudo_gold2.append(json_heu)\n",
    "        lista_comparacoes2.append(comp)\n",
    "\n",
    "    df_metrics = pd.DataFrame()\n",
    "    df_metrics[\"laudos\"] = laudos\n",
    "    df_metrics[\"resultados\"] = lista_comparacoes2\n",
    "    resultados_expandidos = pd.json_normalize(df_metrics[\"resultados\"])\n",
    "    df_metrics = pd.concat(\n",
    "            [df_metrics.drop(columns=[\"resultados\"]), resultados_expandidos],\n",
    "            axis=1\n",
    "        )\n",
    "    \n",
    "    # json_metricas = agrega_resultados_dinamico(lista_comparacoes2)\n",
    "\n",
    "    # mlflow.set_experiment(\"/Users/aureliano.paiva@grupofleury.com.br/imunohistoquimico_pardini_metricas\")\n",
    "\n",
    "    # threshold = 0.8\n",
    "\n",
    "    # with mlflow.start_run(run_name=\"Extracao_Laudos_Run_Threshold\"):\n",
    "    #     for campo, stats in json_metricas.items():\n",
    "    #         taxa = stats[\"taxa_acerto\"]\n",
    "            \n",
    "    #         # Registrar a taxa de acerto\n",
    "    #         mlflow.log_metric(f\"{campo}_taxa_acerto\", taxa)\n",
    "            \n",
    "    #         # Registrar flag de aprovação no threshold\n",
    "    #         passou_flag = 1 if taxa >= threshold else 0\n",
    "    #         mlflow.log_metric(f\"{campo}_passou_threshold\", passou_flag)\n",
    "            \n",
    "    #         # Opcional: registrar acertos e total\n",
    "    #         mlflow.log_metric(f\"{campo}_acertos\", stats[\"acertos\"])\n",
    "    #         mlflow.log_metric(f\"{campo}_total\", stats[\"total\"])\n",
    "        \n",
    "    #     run_id = mlflow.active_run().info.run_id\n",
    "    #     print(f\"Run registrada: {run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f539596",
   "metadata": {},
   "source": [
    "## Contagem de Registros Processados\n",
    "\n",
    "Esta célula executa uma operação simples mas importante: verificar a quantidade de registros no DataFrame final após todo o processamento.\n",
    "\n",
    "```python\n",
    "df_final_classif.count()\n",
    "```\n",
    "\n",
    "Esta operação aciona uma ação no DataFrame Spark e retorna um número inteiro representando a quantidade total de registros que foram processados com sucesso pelo pipeline completo.\n",
    "\n",
    "Os resultados desta contagem são úteis para:\n",
    "\n",
    "1. **Validação de Processamento**: Confirmar que o processamento foi bem-sucedido e que foram gerados resultados\n",
    "2. **Controle de Qualidade**: Verificar se o número de registros de saída corresponde ao número de registros de entrada (df_spk.count())\n",
    "3. **Monitoramento**: Obter uma métrica básica de volume para registro e acompanhamento\n",
    "\n",
    "Esta verificação simples é parte importante do processo de validação dos resultados, garantindo que o pipeline de processamento está produzindo a quantidade esperada de registros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae22483d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_classif.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7838c984",
   "metadata": {},
   "source": [
    "## Persistência dos Resultados em Tabela Delta\n",
    "\n",
    "Esta célula final implementa o armazenamento persistente dos resultados processados em uma tabela Delta no catálogo Databricks. O código é estruturado para garantir robustez no processo de persistência, incluindo tratamento de erros e notificações.\n",
    "\n",
    "### Componentes Principais:\n",
    "\n",
    "1. **Importações e Configuração**:\n",
    "   ```python\n",
    "   import traceback\n",
    "   from octoops import Sentinel  # Framework de monitoramento interno\n",
    "   from delta.tables import DeltaTable  # API para manipulação de tabelas Delta\n",
    "   ```\n",
    "   - Importa bibliotecas para tratamento de exceções e manipulação de tabelas Delta\n",
    "   - Configura variáveis de ambiente como `WEBHOOK_DS_AI_BUSINESS_STG`\n",
    "\n",
    "2. **Definição do Caminho de Saída**:\n",
    "   ```python\n",
    "   OUTPUT_DATA_PATH = \"refined.saude_preventiva.pardini_laudos_mama_imunohistoquimico\"\n",
    "   ```\n",
    "   - Define o caminho completo para a tabela Delta de destino no formato `database.schema.table`\n",
    "\n",
    "3. **Função de Inserção de Dados**:\n",
    "   ```python\n",
    "   def insert_data(df_spk, output_data_path):\n",
    "       # Verifica se a tabela já existe\n",
    "       if not DeltaTable.isDeltaTable(spark, output_data_path):\n",
    "           # Cria a tabela se não existir\n",
    "           df_spk.write.format(\"delta\").saveAsTable(output_data_path)\n",
    "       else:\n",
    "           # Se existir, faz merge (upsert)\n",
    "           delta_table = DeltaTable.forPath(spark, output_data_path)\n",
    "           (delta_table.alias(\"target\")\n",
    "            .merge(...)\n",
    "            .whenMatchedUpdateAll()  # Atualiza todos os campos se o registro já existir\n",
    "            .whenNotMatchedInsertAll()  # Insere se o registro for novo\n",
    "            .execute())\n",
    "   ```\n",
    "   - Implementa lógica para criar a tabela ou fazer merge em tabela existente\n",
    "   - Usa chaves de identificação `ficha`, `id_exame`, `id_marca` e `sequencial` para identificar registros únicos\n",
    "\n",
    "4. **Bloco de Execução com Tratamento de Exceções**:\n",
    "   ```python\n",
    "   try:\n",
    "       if (df_final_classif.count() > 0):\n",
    "           # Executa persistência de dados\n",
    "           insert_data(df_final_classif, OUTPUT_DATA_PATH)\n",
    "           print('Total de registros salvos na tabela:', df_final_classif.count())\n",
    "       else:\n",
    "           # Gera alerta se não há dados para processar\n",
    "           error_message = \"Pardini Imunuhistoquimico - Não há laudos para extração.\"\n",
    "           sentinela_ds_ai_business = Sentinel(...)\n",
    "           sentinela_ds_ai_business.alerta_sentinela(...)\n",
    "   except Exception as e:\n",
    "       # Captura e imprime erros, então reenvie a exceção\n",
    "       traceback.print_exc()\n",
    "       raise e\n",
    "   ```\n",
    "   - Verifica se há registros para persistir antes de tentar salvar\n",
    "   - Envia notificações via Sentinel se não houver registros para processar\n",
    "   - Captura e registra exceções, garantindo visibilidade de qualquer problema\n",
    "\n",
    "Esta etapa final é crucial pois garante que os resultados do processamento sejam armazenados de forma persistente, permitindo acesso posterior para consultas, análises e integração com outros sistemas de saúde. O uso da tecnologia Delta Lake oferece transações ACID, garantindo integridade dos dados mesmo em casos de falhas durante a escrita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77ded36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "from octoops import Sentinel\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "WEBHOOK_DS_AI_BUSINESS_STG = 'stg'\n",
    "\n",
    "# Iniciar sessão Spark\n",
    "spark = SparkSession.builder.appName(\"DfPandasparaSpark\").getOrCreate()\n",
    "\n",
    "#OUTPUT_DATA_PATH = dbutils.widgets.get(\"OUTPUT_DATA_PATH\")\n",
    "OUTPUT_DATA_PATH = \"refined.saude_preventiva.pardini_laudos_mama_imunohistoquimico\"\n",
    "\n",
    "# função para salvar dados na tabela\n",
    "def insert_data(df_spk, output_data_path):\n",
    "\n",
    "    # Cria a tabela Delta se não existir\n",
    "    if not DeltaTable.isDeltaTable(spark, output_data_path):\n",
    "        df_spk.write.format(\"delta\").saveAsTable(output_data_path)\n",
    "    else:\n",
    "        # Carrega a tabela Delta existente\n",
    "        delta_table = DeltaTable.forPath(spark, output_data_path)\n",
    "\n",
    "        # Faz o merge (upsert)\n",
    "        (delta_table.alias(\"target\")\n",
    "        .merge(\n",
    "            df_spk.alias(\"source\"),\n",
    "            \"target.ficha = source.ficha AND target.id_exame = source.id_exame AND target.id_marca = source.id_marca AND target.sequencial = source.sequencial\"\n",
    "        )\n",
    "        .whenMatchedUpdateAll() #atualiza todos os campos se o ID já existir\n",
    "        .whenNotMatchedInsertAll() #insere se o ID não existir\n",
    "        .execute())\n",
    "\n",
    "# salvar dados na tabela\n",
    "try:\n",
    "    # 1/0\n",
    "    if (df_final_classif.count() > 0):        \n",
    "\n",
    "\n",
    "        # Inserir tabela catalog\n",
    "        insert_data(df_final_classif, OUTPUT_DATA_PATH)\n",
    "        print('Total de registros salvos na tabela:', df_final_classif.count())\n",
    "       \n",
    "\n",
    "    else: \n",
    "        error_message = traceback.format_exc()\n",
    "        error_message = \"Pardini Imunuhistoquimico - Não há laudos para extração.\"\n",
    "        sentinela_ds_ai_business = Sentinel(\n",
    "            project_name='Monitor_Linhas_Cuidado_Mama',\n",
    "            env_type=WEBHOOK_DS_AI_BUSINESS_STG,\n",
    "            task_title='Pardini Mama Imunuhistoquimico'\n",
    "        )\n",
    "\n",
    "        sentinela_ds_ai_business.alerta_sentinela(\n",
    "            categoria='Alerta', \n",
    "            mensagem=error_message,\n",
    "            job_id_descritivo='4_Pardini_mama_Imunuhistoquimico'\n",
    "        )\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "    raise e    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b318719",
   "metadata": {},
   "source": [
    "## Exportação para Excel (Comentada)\n",
    "\n",
    "Esta célula final contém código comentado que poderia ser usado para exportar os resultados processados para um arquivo Excel. Embora não esteja ativa, ela permanece como referência para casos em que seja necessária a exportação dos dados para análise externa.\n",
    "\n",
    "```python\n",
    "#%pip install openpyxl\n",
    "#df_pandas = df_final.toPandas()\n",
    "#df_pandas.to_excel(\"pardini_laudos_mamo_imunohistoquimico.xlsx\", index=False)\n",
    "```\n",
    "\n",
    "O código possui três componentes principais:\n",
    "\n",
    "1. **Instalação de Biblioteca**: `%pip install openpyxl` instalaria a biblioteca necessária para manipulação de arquivos Excel\n",
    "2. **Conversão para Pandas**: `df_final.toPandas()` converteria o DataFrame Spark em um DataFrame Pandas\n",
    "3. **Exportação para Excel**: `to_excel()` salvaria os dados em um arquivo Excel nomeado \"pardini_laudos_mamo_imunohistoquimico.xlsx\" sem incluir o índice\n",
    "\n",
    "Este recurso poderia ser útil para:\n",
    "- Análises locais dos dados processados\n",
    "- Compartilhamento de resultados com equipes que não têm acesso ao ambiente Databricks\n",
    "- Visualizações e formatações específicas usando Excel\n",
    "\n",
    "No entanto, em um ambiente de produção com grande volume de dados, a abordagem preferida é usar o armazenamento em tabelas Delta, como implementado na célula anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cc20bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install openpyxl\n",
    "#df_pandas = df_final.toPandas()\n",
    "#df_pandas.to_excel(\"pardini_laudos_mamo_imunohistoquimico.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
