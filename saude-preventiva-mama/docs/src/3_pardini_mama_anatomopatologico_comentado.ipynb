{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48714105",
   "metadata": {},
   "source": [
    "# Extração Automatizada de Informações de Laudos Anatomopatológicos de Mama\n",
    "\n",
    "## Introdução Técnica Detalhada\n",
    "\n",
    "Este notebook implementa um sistema completo para extrair, processar e validar informações clínicas relevantes de laudos anatomopatológicos de mama utilizando uma combinação de técnicas de processamento de linguagem natural (PLN) e modelos avançados de IA generativa. O processo foca na identificação de marcadores críticos para diagnóstico e classificação de lesões mamárias, particularmente relacionados à malignidade.\n",
    "\n",
    "### Objetivo Principal\n",
    "\n",
    "O objetivo principal deste notebook é automatizar a extração de informações estruturadas de laudos de anatomia patológica da mama, identificando:\n",
    "- **Descritores de malignidade** (carcinoma, invasivo, metastático, etc.)\n",
    "- **Grau histológico** (1, 2 ou 3)\n",
    "- **Grau nuclear** (1, 2 ou 3)\n",
    "- **Formação de túbulos** (1, 2 ou 3)\n",
    "- **Índice mitótico** (1, 2 ou 3)\n",
    "- **Tipo histológico** (carcinoma ductal invasivo, lobular, etc.)\n",
    "\n",
    "Estas informações são fundamentais para o estadiamento do câncer, definição de prognóstico e direcionamento do tratamento adequado.\n",
    "\n",
    "### Tecnologias Utilizadas\n",
    "\n",
    "O notebook utiliza diversas tecnologias avançadas:\n",
    "\n",
    "- **PySpark**: Framework para processamento distribuído de dados\n",
    "  - `pyspark.sql`: Manipulação de dados em formato tabular\n",
    "  - `pyspark.sql.functions`: Transformações e funções em colunas\n",
    "  - `pyspark.sql.window`: Operações de janela para ordenação e numeração de linhas\n",
    "\n",
    "- **OpenAI API**: Acesso ao modelo LLama-4-Maverick através de API Databricks\n",
    "  - Configuração de prompts específicos para extração médica\n",
    "  - Gerenciamento de temperatura e tokens para otimização de respostas\n",
    "\n",
    "- **Processamento de Texto**:\n",
    "  - `re`: Biblioteca de expressões regulares para extração baseada em padrões\n",
    "  - Técnicas de normalização de texto (lowercase, remoção de caracteres especiais)\n",
    "\n",
    "- **Manipulação de Dados**:\n",
    "  - `pandas`: Para análise dos resultados e métricas\n",
    "  - `numpy`: Operações numéricas\n",
    "  - `tqdm`: Barras de progresso para monitoramento de processamento em lotes\n",
    "\n",
    "- **Validação e Qualidade**:\n",
    "  - Funções personalizadas para avaliação de resultados\n",
    "  - Comparação entre extração baseada em regras e IA\n",
    "\n",
    "### Fluxo de Trabalho/Etapas Principais\n",
    "\n",
    "O notebook segue um fluxo de trabalho estruturado:\n",
    "\n",
    "1. **Configuração do Ambiente**: \n",
    "   - Importação de bibliotecas\n",
    "   - Inicialização da sessão Spark\n",
    "   - Obtenção do token de autenticação Databricks\n",
    "\n",
    "2. **Extração de Dados Fonte**:\n",
    "   - Consulta SQL para selecionar laudos relevantes da tabela `refined.saude_preventiva.pardini_laudos`\n",
    "   - Filtragem por linha de cuidado ('mama') e tipos específicos de exame (MICROH, FPAH)\n",
    "   - Normalização dos textos dos laudos\n",
    "\n",
    "3. **Definição de Funções de Processamento**:\n",
    "   - Criação de prompt especializado para o modelo de IA\n",
    "   - Implementação de funções para extrair informações via expressões regulares\n",
    "   - Configuração de funções para processamento em lote\n",
    "\n",
    "4. **Processamento com IA**:\n",
    "   - Envio dos laudos para o modelo LLama-4-Maverick\n",
    "   - Extração das informações estruturadas\n",
    "   - Transformação das respostas em formato JSON\n",
    "\n",
    "5. **Validação e Métricas**:\n",
    "   - Comparação dos resultados da IA com extração baseada em regras (pseudo-gold)\n",
    "   - Cálculo de taxas de acerto para cada campo extraído\n",
    "   - Geração de relatórios de desempenho\n",
    "\n",
    "6. **Persistência dos Resultados** (comentado no código atual):\n",
    "   - Salvamento na tabela `refined.saude_preventiva.pardini_laudos_mamo_anatomia_patologica`\n",
    "   - Registro de métricas de desempenho com MLflow\n",
    "\n",
    "### Dados Envolvidos\n",
    "\n",
    "#### Fontes de Dados:\n",
    "- **Tabela Principal**: `refined.saude_preventiva.pardini_laudos`\n",
    "  - Contém laudos médicos de diversos exames\n",
    "  - Filtrada para linha de cuidado 'mama' e exames específicos (MICROH, FPAH)\n",
    "\n",
    "#### Colunas Principais Utilizadas:\n",
    "- `id_unidade`: Identificador da unidade médica\n",
    "- `id_cliente`: Identificador do paciente\n",
    "- `id_item`, `id_subitem`, `id_exame`: Identificadores do exame realizado\n",
    "- `dth_pedido`: Data/hora do pedido do exame\n",
    "- `laudo_tratado`: Texto completo do laudo médico\n",
    "- `sigla_exame`: Código do tipo de exame\n",
    "\n",
    "#### Tabela de Destino:\n",
    "- `refined.saude_preventiva.pardini_laudos_mamo_anatomia_patologica`: Armazena os resultados da extração\n",
    "\n",
    "### Resultados/Saídas Esperadas\n",
    "\n",
    "O notebook produz os seguintes resultados:\n",
    "\n",
    "1. **DataFrame Estruturado (`df_final`)**: \n",
    "   - Contém todas as informações extraídas dos laudos\n",
    "   - Inclui tanto os dados originais quanto os campos extraídos\n",
    "\n",
    "2. **Métricas de Desempenho (`json_metricas`)**:\n",
    "   - Taxa de acerto para cada tipo de informação extraída\n",
    "   - Comparação entre extração baseada em regras e IA\n",
    "\n",
    "3. **Tabela Persistente** (quando descomentado):\n",
    "   - Dados salvos em formato Delta para uso em análises posteriores\n",
    "   - Acessível via SQL para integração com outros sistemas\n",
    "\n",
    "### Pré-requisitos\n",
    "\n",
    "Para executar este notebook são necessários:\n",
    "\n",
    "- **Ambiente Databricks** com:\n",
    "  - Cluster configurado com runtime ML\n",
    "  - Acesso às tabelas Delta no formato `refined.saude_preventiva.*`\n",
    "  - Token de acesso configurado para API de modelos (`DATABRICKS_TOKEN`)\n",
    "\n",
    "- **Bibliotecas Python**:\n",
    "  - OpenAI (para acesso à API)\n",
    "  - tqdm (para barras de progresso)\n",
    "  - Pandas, NumPy (para manipulação de dados)\n",
    "  - PySpark (para processamento distribuído)\n",
    "  - FeatureStore (para persistência, quando habilitado)\n",
    "\n",
    "### Considerações Importantes/Observações\n",
    "\n",
    "- **Limitação de Processamento**: O código atual inclui um limitador de registros (`limit(200)`) para fins de teste\n",
    "- **Chamadas de API**: O processamento em lote está configurado para evitar sobrecarga da API (batch_size=10)\n",
    "- **Validação**: A abordagem utiliza uma validação sem ground truth, comparando a extração da IA com uma extração baseada em regras\n",
    "- **Dados Sensíveis**: Os laudos contêm informações médicas sensíveis, sendo importante garantir a conformidade com requisitos de privacidade\n",
    "- **Código Comentado**: Algumas funcionalidades estão comentadas no código original (persistência, MLflow), necessitando descomentário para uso em produção"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7711d0",
   "metadata": {},
   "source": [
    "# Extração de dados - Anatomo Patologico\n",
    "**Descritores de MALIGNIDADE:**\n",
    "- carcinoma\n",
    "- invasivo\n",
    "- invasor\n",
    "- sarcoma\n",
    "- metástase\n",
    "- metastático\n",
    "- maligno\n",
    "- maligna\n",
    "- cdi, cli, cdis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01437a86",
   "metadata": {},
   "source": [
    "Outros labels a serem extraídos:\n",
    "\n",
    "- **Grau histológico:** será sempre um algarismo 1, 2 ou 3 (apenas três categorias). Para encontrar, basta procurar o primeiro algarismo numérico após o termo **\"grau histológico\"**.\n",
    "\n",
    "- **Grau nuclear:** será sempre um algarismo 1, 2 ou 3 (apenas três categorias). Para encontrar, basta procurar o primeiro algarismo numérico após o termo **\"grau nuclear\"**.\n",
    "\n",
    "- **Formação de túbulos:** será sempre um algarismo 1, 2 ou 3 (apenas três categorias). Para encontrar, basta procurar o primeiro algarismo numérico após o termo **\"formação de túbulos\"**.\n",
    "\n",
    "- **Índice mitótico:** será sempre um algarismo 1, 2 ou 3 (apenas três categorias). Para encontrar, basta procurar o primeiro algarismo numérico após o termo **\"mm2\"**. Nesse caso, é melhor procurar o termo **\"mm2\"** ao invés de **\"índice mitótico\"**.\n",
    "\n",
    "- **Labels de tipos histológicos:**\n",
    "  - Carcinoma de mama ductal invasivo (CDI)/SOE\n",
    "  - Carcinoma de mama ductal in situ\n",
    "  - Carcinoma de mama lobular invasivo\n",
    "  - Carcinoma de mama lobular\n",
    "  - Carcinoma de mama papilífero\n",
    "  - Carcinoma de mama metaplásico\n",
    "  - Carcinoma de mama mucinoso\n",
    "  - Carcinoma de mama tubular\n",
    "  - Carcinoma de mama cístico adenoide\n",
    "  - Carcinoma de mama medular\n",
    "  - Carcinoma de mama micropapilar\n",
    "  - Carcinoma de mama misto (ductal e lobular) invasivo\n",
    "\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a910612",
   "metadata": {},
   "source": [
    "## Instalação de Dependências\n",
    "\n",
    "Esta célula contém comandos comentados para instalação das bibliotecas necessárias para execução do notebook. Os comandos de instalação utilizam o prefixo `%pip`, que é uma magic command do Jupyter para instalar pacotes diretamente no ambiente de execução atual. Todas as instalações estão com a flag `-q` (quiet) para minimizar o output da instalação.\n",
    "\n",
    "As bibliotecas que seriam instaladas incluem:\n",
    "\n",
    "- **openai**: Cliente Python para interagir com a API da OpenAI (usada para comunicação com modelos de IA)\n",
    "- **tqdm**: Biblioteca para exibir barras de progresso durante operações longas\n",
    "- **pandarallel**: Extensão do pandas para paralelizar operações\n",
    "- **databricks-feature-store**: Cliente para interagir com o Feature Store do Databricks\n",
    "\n",
    "Há também um comando comentado `%restart_python` que reiniciaria o kernel Python após a instalação para garantir que as novas bibliotecas sejam carregadas corretamente.\n",
    "\n",
    "Para utilizar estas instalações, basta descomentar as linhas relevantes e executar a célula. No estado atual, a célula não realiza nenhuma operação por estar completamente comentada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffb2aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install openai -q\n",
    "# %pip install tqdm -q\n",
    "# %pip install pandarallel -q\n",
    "# %pip install databricks-feature-store -q\n",
    "# %restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5444b5c4",
   "metadata": {},
   "source": [
    "## Importação de Bibliotecas e Configuração de Ambiente\n",
    "\n",
    "Esta célula realiza a importação de todas as bibliotecas e módulos necessários para o funcionamento do notebook, além de configurar o ambiente de execução Spark.\n",
    "\n",
    "### Bibliotecas Importadas\n",
    "\n",
    "#### PySpark e SQL\n",
    "- `SparkSession`: Ponto de entrada para funcionalidades do Spark\n",
    "- `Window`: Funções para operações de janela (agregações, rankings)\n",
    "- `row_number()`: Função para adicionar numeração sequencial a registros\n",
    "- `functions` como `F`: Conjunto de funções para manipular dados em DataFrames\n",
    "\n",
    "#### Processamento de Dados\n",
    "- `pandas` e `numpy`: Para manipulação e análise de dados estruturados\n",
    "- `json`: Para manipulação de objetos JSON\n",
    "- `re`: Para operações com expressões regulares\n",
    "- `tqdm`: Para exibição de barras de progresso em processamentos longos\n",
    "\n",
    "#### APIs e Conectividade\n",
    "- `openai`: Cliente para comunicação com APIs de modelos de IA\n",
    "- `FeatureStoreClient`: Para interagir com o Feature Store do Databricks\n",
    "\n",
    "#### Utilitários\n",
    "- `os`, `sys`, `time`, `warnings`: Utilitários do sistema e controle de tempo\n",
    "- `relativedelta`: Para cálculos com datas\n",
    "- `List`, `Any` (typing): Para tipagem estática em funções Python\n",
    "\n",
    "### Configurações Realizadas\n",
    "\n",
    "A célula também:\n",
    "\n",
    "1. **Inicializa a Sessão Spark**: Cria uma nova sessão SparkSession configurada com o nome \"LLM_Extractor\"\n",
    "2. **Obtém Token Databricks**: Recupera o token de API do contexto atual do notebook para uso nas chamadas à API do LLM\n",
    "\n",
    "O token obtido (`DATABRICKS_TOKEN`) será utilizado posteriormente para autenticação com a API de modelos de linguagem na infraestrutura Databricks.\n",
    "\n",
    "### Impacto\n",
    "\n",
    "Esta célula prepara todo o ambiente necessário para as operações subsequentes de extração e processamento de dados. Após sua execução, todas as bibliotecas e configurações estarão disponíveis para uso nas demais células do notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346c4996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Any\n",
    "import openai\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "from databricks.feature_store import FeatureStoreClient\n",
    "\n",
    "spark = SparkSession.builder.appName(\"LLM_Extractor\").getOrCreate()\n",
    "\n",
    "DATABRICKS_TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get() if dbutils.notebook.entry_point.getDbutils().notebook().getContext() is not None else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3417dbb6",
   "metadata": {},
   "source": [
    "## Configuração de Opções de Exibição do Pandas (Comentado)\n",
    "\n",
    "Esta célula contém código comentado para configurar opções de exibição do pandas. Quando descomentado, o código ajustaria a forma como o pandas exibe DataFrames no notebook, expandindo os limites padrão de visualização.\n",
    "\n",
    "As opções comentadas são:\n",
    "\n",
    "- `pd.set_option('display.max_rows', None)`: Remove o limite de linhas exibidas, mostrando todas as linhas do DataFrame\n",
    "- `pd.set_option('display.max_columns', None)`: Remove o limite de colunas exibidas, mostrando todas as colunas do DataFrame\n",
    "- `pd.set_option('display.width', None)`: Remove a limitação de largura da exibição, permitindo que o conteúdo use todo o espaço horizontal disponível\n",
    "- `pd.set_option('display.max_colwidth', None)`: Remove o limite de largura de cada coluna, exibindo o conteúdo completo de cada célula sem truncamento\n",
    "\n",
    "Estas configurações são particularmente úteis ao trabalhar com dados textuais longos, como os laudos médicos que serão processados neste notebook, permitindo a visualização completa do conteúdo durante análises exploratórias.\n",
    "\n",
    "Para ativar estas configurações, basta descomentar as linhas relevantes antes de executar a célula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d932623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)       \n",
    "# pd.set_option('display.max_columns', None)   \n",
    "# pd.set_option('display.width', None) \n",
    "# pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd0b1b6",
   "metadata": {},
   "source": [
    "## Extração e Transformação de Dados de Laudos Anatomopatológicos\n",
    "\n",
    "Esta célula realiza a extração, filtragem e transformação dos dados de laudos anatomopatológicos da base do Pardini, preparando o dataset que será processado pelo modelo de IA.\n",
    "\n",
    "### Objetivo da Célula\n",
    "\n",
    "Esta célula:\n",
    "1. Define duas consultas SQL para extração de dados\n",
    "2. Executa a consulta principal para obter laudos anatomopatológicos\n",
    "3. Aplica transformações adicionais como filtragem por topografia e normalização de texto\n",
    "4. Adiciona um índice sequencial para rastreamento dos registros\n",
    "\n",
    "### Consultas SQL Definidas\n",
    "\n",
    "#### `query_append` (Não utilizada nesta execução)\n",
    "Esta consulta foi definida para extrair apenas registros incrementais, utilizando:\n",
    "- Join com a tabela de destino para identificar novos registros\n",
    "- Filtragem por linha de cuidado \"mama\" e códigos específicos de exame\n",
    "- Está comentada/não utilizada na execução atual\n",
    "\n",
    "#### `query_all_base` (Utilizada nesta execução)\n",
    "Esta consulta seleciona todos os registros relevantes da tabela `refined.saude_preventiva.pardini_laudos`:\n",
    "- Filtra por linha de cuidado = 'mama'\n",
    "- Seleciona apenas exames com siglas específicas: \"MICROH\" e \"FPAH\"\n",
    "- Extrai colunas de identificação e o texto do laudo\n",
    "\n",
    "### Transformações Aplicadas\n",
    "\n",
    "Após a execução da consulta, o DataFrame resultante passa por três transformações principais:\n",
    "\n",
    "1. **Filtragem por Topografia**:\n",
    "   ```python\n",
    "   df_anatomopatologico = df_anatomopatologico.filter(F.col(\"laudo_tratado\").rlike(\"(?i)Topografia: mama\"))\n",
    "   ```\n",
    "   Este filtro utiliza uma expressão regular case-insensitive para garantir que apenas laudos relacionados à mama sejam processados.\n",
    "\n",
    "2. **Normalização do Texto**:\n",
    "   ```python\n",
    "   df_anatomopatologico = df_anatomopatologico.withColumn(\"laudo_tratado\", F.lower(df_anatomopatologico[\"laudo_tratado\"]))\n",
    "   ```\n",
    "   Converte todo o texto do laudo para minúsculas, facilitando a posterior extração por expressões regulares.\n",
    "\n",
    "3. **Adição de Índice Sequencial**:\n",
    "   ```python\n",
    "   window = Window.orderBy(F.monotonically_increasing_id())\n",
    "   df_anatomopatologico = df_anatomopatologico.withColumn(\"index\", row_number().over(window) - 1)\n",
    "   ```\n",
    "   Adiciona uma coluna \"index\" com numeração sequencial iniciando em 0, que será utilizada para junção com os resultados da extração por IA.\n",
    "\n",
    "### Resultado\n",
    "\n",
    "O resultado desta célula é o DataFrame `df_anatomopatologico` contendo os laudos filtrados e normalizados, com uma coluna adicional de índice. Este DataFrame será a base para o processamento de extração de informações através do modelo de IA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc4be47",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_append = \"\"\"\n",
    "WITH base AS (\n",
    "    SELECT\n",
    "        flr.id_unidade,\n",
    "        flr.id_cliente, \n",
    "        flr.id_item, \n",
    "        flr.id_subitem, \n",
    "        flr.id_exame, \n",
    "        flr.dth_pedido,\n",
    "        flr.laudo_tratado,\n",
    "        flr.sigla_exame,\n",
    "        flr.linha_cuidado\n",
    "        FROM refined.saude_preventiva.pardini_laudos flr\n",
    "    WHERE\n",
    "        flr.linha_cuidado   = 'mama'\n",
    "        flr.sigla_exame IN (\"MICROH\",\"MICROH\",\"FPAH\")\n",
    "),\n",
    "sem_extracao AS (\n",
    "    SELECT\n",
    "        b.id_unidade,\n",
    "        b.id_cliente,\n",
    "        b.id_item,\n",
    "        b.id_subitem,\n",
    "        b.id_exame,\n",
    "        b.dth_pedido,\n",
    "        b.sigla_exame,\n",
    "        b.laudo_tratado,\n",
    "        b.RAW_CARCINOMA,\n",
    "        b.HAS_CARCINOMA\n",
    "    FROM base b\n",
    "    LEFT JOIN refined.saude_preventiva.pardini_laudos_mamo_anatomia_patologica mb\n",
    "      ON mb.id_unidade = b.id_unidade\n",
    "     AND mb.id_cliente = b.id_cliente\n",
    "     AND mb.id_item    = b.id_item\n",
    "     AND mb.id_subitem = b.id_subitem\n",
    "     AND mb.id_exame   = b.id_exame\n",
    "    WHERE mb.id_unidade IS NULL\n",
    ")\n",
    "SELECT *\n",
    "FROM sem_extracao\n",
    "\"\"\"\n",
    "\n",
    "query_all_base = \"\"\"SELECT\n",
    "        flr.id_unidade,\n",
    "        -- flr.id_pedido,\n",
    "        flr.id_cliente, \n",
    "        id_item, \n",
    "        id_subitem, \n",
    "        flr.id_exame, \n",
    "        flr.dth_pedido,\n",
    "        flr.laudo_tratado,\n",
    "        flr.sigla_exame\n",
    "    FROM refined.saude_preventiva.pardini_laudos flr\n",
    "    WHERE\n",
    "      flr.linha_cuidado = 'mama'\n",
    "      AND\n",
    "      flr.sigla_exame IN (\"MICROH\",\"MICROH\",\"FPAH\")\n",
    "      \"\"\"\n",
    "df_anatomopatologico = spark.sql(query_all_base)\n",
    "df_anatomopatologico = df_anatomopatologico.filter(F.col(\"laudo_tratado\").rlike(\"(?i)Topografia: mama\"))\n",
    "df_anatomopatologico = df_anatomopatologico.withColumn(\"laudo_tratado\", F.lower(df_anatomopatologico[\"laudo_tratado\"]))\n",
    "window = Window.orderBy(F.monotonically_increasing_id())\n",
    "df_anatomopatologico = df_anatomopatologico.withColumn(\"index\", row_number().over(window) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07bbd50",
   "metadata": {},
   "source": [
    "## Contagem de Registros para Processamento\n",
    "\n",
    "Esta célula realiza uma operação simples mas importante: conta o número de registros no DataFrame `df_anatomopatologico` após a filtragem e transformação realizadas anteriormente. Esta contagem é armazenada na variável `num_linhas`.\n",
    "\n",
    "### Objetivo da Célula\n",
    "\n",
    "O principal objetivo é quantificar o volume de dados que será processado pelo modelo de IA, permitindo:\n",
    "1. Verificar se há dados disponíveis para processamento\n",
    "2. Estimar o tempo e recursos necessários para o processamento completo\n",
    "3. Servir como base para decisões condicionais em células posteriores\n",
    "\n",
    "### Funcionamento\n",
    "\n",
    "O comando `df_anatomopatologico.count()` executa uma ação em Spark que percorre todo o DataFrame e conta o número de linhas. Esta é uma operação que materializa o DataFrame, já que as transformações anteriores são lazy (só executadas quando necessário).\n",
    "\n",
    "### Impacto\n",
    "\n",
    "O valor armazenado em `num_linhas` será utilizado posteriormente em uma condição `if num_linhas > 0:` para determinar se o processamento com o modelo de IA deve prosseguir. Isso evita tentativas de processamento quando não há dados disponíveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abd5250",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_linhas = df_anatomopatologico.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489b14f",
   "metadata": {},
   "source": [
    "## Definição de Funções para Processamento de Laudos com IA\n",
    "\n",
    "Esta célula implementa um conjunto completo de funções para processar laudos médicos utilizando modelos de IA. É uma das células mais complexas do notebook, incluindo definições de prompt, lógica de comunicação com API e tratamento de erros.\n",
    "\n",
    "### Funções Implementadas\n",
    "\n",
    "#### 1. `prompt_laudo(laudo_texto: str) -> str`\n",
    "\n",
    "**Objetivo**: Criar um prompt estruturado para extração de informações específicas de um laudo médico.\n",
    "\n",
    "**Parâmetros**:\n",
    "- `laudo_texto`: O texto do laudo a ser analisado\n",
    "\n",
    "**Funcionamento**:\n",
    "- Constrói um prompt detalhado com instruções específicas para o modelo de IA\n",
    "- Inclui o texto do laudo dentro de aspas triplas\n",
    "- Define critérios claros para extração de cada tipo de informação (descritores de malignidade, grau histológico, etc.)\n",
    "- Especifica o formato esperado para a resposta (dicionário Python)\n",
    "\n",
    "**Saída**: String contendo o prompt completo a ser enviado para o modelo de IA\n",
    "\n",
    "#### 2. `generate(descricao_agente:str, laudo:str, llm_client) -> str`\n",
    "\n",
    "**Objetivo**: Processar um único laudo através do modelo de IA.\n",
    "\n",
    "**Parâmetros**:\n",
    "- `descricao_agente`: Descrição do papel que o modelo deve assumir (médico oncologista)\n",
    "- `laudo`: Texto do laudo a ser analisado\n",
    "- `llm_client`: Cliente da API do modelo de IA\n",
    "\n",
    "**Funcionamento**:\n",
    "- Gera o prompt chamando a função `prompt_laudo()`\n",
    "- Configura os parâmetros da chamada de API:\n",
    "  - Modelo: \"databricks-llama-4-maverick\"\n",
    "  - Temperature: 0 (para maximizar a determinação das respostas)\n",
    "  - Tokens máximos: 4000\n",
    "  - Configurações adicionais como top_p, frequency/presence penalty\n",
    "- Implementa lógica de retry (até 3 tentativas) em caso de falha de conexão\n",
    "- Captura e trata exceções, com reporte de erros\n",
    "\n",
    "**Saída**: Resposta textual do modelo de IA contendo o resultado da extração\n",
    "\n",
    "#### 3. `batch_generate(descricao_agente, laudos, llm_client, batch_size=25)`\n",
    "\n",
    "**Objetivo**: Processar múltiplos laudos em lotes, controlando a carga sobre a API.\n",
    "\n",
    "**Parâmetros**:\n",
    "- `descricao_agente`: Descrição do papel do modelo\n",
    "- `laudos`: Lista de textos de laudos a serem analisados\n",
    "- `llm_client`: Cliente da API\n",
    "- `batch_size`: Tamanho do lote para processamento (padrão: 25)\n",
    "\n",
    "**Funcionamento**:\n",
    "- Reconfigura o cliente OpenAI com o token e URL do endpoint Databricks\n",
    "- Divide o processamento em lotes do tamanho especificado\n",
    "- Utiliza a biblioteca tqdm para exibir barras de progresso do processamento\n",
    "- Chama a função `generate()` para cada laudo individualmente\n",
    "\n",
    "**Saída**: Lista de respostas do modelo, uma para cada laudo processado\n",
    "\n",
    "#### 4. `limpar_e_converter(item)`\n",
    "\n",
    "**Objetivo**: Converter a resposta textual do modelo em um dicionário Python estruturado.\n",
    "\n",
    "**Parâmetros**:\n",
    "- `item`: Texto de resposta do modelo de IA\n",
    "\n",
    "**Funcionamento**:\n",
    "- Remove marcadores Markdown para blocos de código (```python, ```)\n",
    "- Converte a string JSON para um objeto Python utilizando json.loads()\n",
    "- Implementa tratamento de erros, retornando um dicionário padrão em caso de falha\n",
    "- O dicionário padrão contém todos os campos com valores vazios ou \"NÃO INFORMADO\"\n",
    "\n",
    "**Saída**: Dicionário Python contendo as informações extraídas estruturadas\n",
    "\n",
    "### Impacto\n",
    "\n",
    "Este conjunto de funções forma o núcleo do processamento de laudos com IA, permitindo:\n",
    "1. Extrair informações estruturadas de texto livre\n",
    "2. Processar grandes volumes de laudos de forma eficiente\n",
    "3. Padronizar as respostas em formato consistente\n",
    "4. Tratar erros e falhas de forma robusta\n",
    "\n",
    "O design modular facilita a manutenção e eventuais modificações nos critérios de extração ou parâmetros do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3d2037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_laudo(laudo_texto: str) -> str:\n",
    "    prompt = f\"\"\"A seguir está um laudo médico de mamografia. Se alguma informação não estiver presente no texto, retorne \"NÃO INFORMADO\". Sempre retorne apenas o dicionário Python.\n",
    "\n",
    "    Laudo clínico:\n",
    "    \\\"\\\"\\\"{laudo_texto}\\\"\\\"\\\"\n",
    "\n",
    "    ### Critérios de extração:\n",
    "\n",
    "    - **Descritores de malignidade**: retorne uma **lista** com os termos de malignidade encontrados no texto (case-insensitive). Se nenhum for encontrado, retorne lista vazia `[]`. Lista de termos: ['carcinoma', \"invasivo\", \"invasor\", \"sarcoma\", \"metástase\", \"metastático\", \"maligno\", \"maligna\", \"cdi\", \"cli\", \"cdis\"]\n",
    "\n",
    "    - **Grau histológico**: retorne o valor numérico do grau histológico.\n",
    "\n",
    "    - **Grau nuclear**: retorne o valor numérico do grau nuclear.\n",
    "\n",
    "    - **Formação de túbulos**: retorne o valor numérico caso exista formação de túbulos.\n",
    "\n",
    "    - **Índice mitótico**: retorne o valor numérico do score do índice mitótico que aparece após o mm2.\n",
    "\n",
    "    - **Tipo histológico**: identifique e retorne a frase correspondente se algum dos seguintes for mencionado (case-insensitive, variações aceitas):\n",
    "      - Carcinoma de mama ductal invasivo\n",
    "      - Carcinoma de mama ductal in situ\n",
    "      - Carcinoma de mama lobular invasivo\n",
    "      - Carcinoma de mama lobular\n",
    "      - Carcinoma de mama papilífero\n",
    "      - Carcinoma de mama metaplásico\n",
    "      - Carcinoma de mama mucinoso\n",
    "      - Carcinoma de mama tubular\n",
    "      - Carcinoma de mama cístico adenoide\n",
    "      - Carcinoma de mama medular\n",
    "      - Carcinoma de mama micropapilar\n",
    "      - Carcinoma de mama misto (ductal e lobular) invasivo\n",
    "\n",
    "    ### Saída esperada (dicionário Python válido):\n",
    "    ```python\n",
    "    {{\n",
    "      \"descritores_malignidade\": [\"termo1\", \"termo2\", ...],\n",
    "      \"grau_histologico\": número | \"NÃO INFORMADO\",\n",
    "      \"grau_nuclear\": número | \"NÃO INFORMADO\",\n",
    "      \"formacao_tubulos\": número | \"NÃO INFORMADO\",\n",
    "      \"indice_mitotico\": número | \"NÃO INFORMADO\",\n",
    "      \"tipo_histologico\": \"texto correspondente ou 'NÃO INFORMADO'\n",
    "    }}\n",
    "    ```\n",
    "    \"\"\"\n",
    "    return prompt.strip()\n",
    "\n",
    "def generate(descricao_agente:str, laudo:str, llm_client) -> str:\n",
    "    \"\"\"\n",
    "    Gera o resultado da análise de um laudo\n",
    "    Params:\n",
    "        descricao_agente: descricao do agente que a LLM representa (primeira mensagem enviada à LLM)\n",
    "        prompt: prompt base que será utilizado para gerar a análise\n",
    "        laudo: laudo a ser analisado (incluido dentro do prompt)\n",
    "        llm_client: cliente da API da LLM\n",
    "    Return:\n",
    "        response_message: resposta da LLM\n",
    "    \"\"\"\n",
    "    prompt = prompt_laudo(laudo)\n",
    "    messages = [\n",
    "        # Utilizamos o primeiro prompt para contextualizar o llm do que ele deve fazer. \n",
    "        # No exemplo utilizamos a abordagem Role, Task, Output, Prompting.\n",
    "        # Mas sintam-se a vontade para alterar de acordo com a necessidade\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": descricao_agente\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ]\n",
    "    model_params = {\n",
    "        \"model\": \"databricks-llama-4-maverick\",\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0,\n",
    "        \"max_tokens\": 4000,\n",
    "        \"top_p\": 0.75,\n",
    "        \"frequency_penalty\": 0,\n",
    "        \"presence_penalty\": 0\n",
    "    }\n",
    "    connection_retry = 0\n",
    "    while connection_retry < 3:\n",
    "        try:\n",
    "            response = llm_client.chat.completions.create(**model_params)\n",
    "            response_message = response.choices[0].message.content\n",
    "            break\n",
    "        # TODO: verificar se a excessao é de conexao\n",
    "        except (ConnectionError, TimeoutError) as e:\n",
    "            connection_retry += 1\n",
    "            print(\"Sem reposta do modelo\")\n",
    "            print(str(e))\n",
    "            print(\"Tentando novamente...\")\n",
    "            time.sleep(0.1)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    if connection_retry >= 3:\n",
    "        response_message = ''\n",
    "    \n",
    "    return response_message\n",
    "\n",
    "\n",
    "def batch_generate(descricao_agente, laudos, llm_client, batch_size=25):\n",
    "    responses = []\n",
    "    \n",
    "    llm_client = openai.OpenAI(\n",
    "        api_key=DATABRICKS_TOKEN,\n",
    "        base_url=\"https://dbc-d80f50a9-af23.cloud.databricks.com/serving-endpoints\"\n",
    "    )\n",
    "    \n",
    "    # Dividir em lotes\n",
    "    for i in range(0, len(laudos), batch_size):\n",
    "        laudos_batch = laudos[i:i+batch_size]\n",
    "        for laudo in tqdm(laudos_batch, desc=f\"Processando lote {i//batch_size + 1}\", total=len(laudos_batch)):\n",
    "            responses.append(generate(descricao_agente, laudo, llm_client))\n",
    "    \n",
    "    return responses\n",
    "\n",
    "def limpar_e_converter(item):\n",
    "    try:\n",
    "        item_limpo = re.sub(r\"```(?:python)?\", \"\", item).replace(\"```\", \"\").strip()\n",
    "        return json.loads(item_limpo)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao converter resposta: {e}\")\n",
    "        return {\n",
    "            'descritores_malignidade': [],\n",
    "            'grau_histologico': \"NÃO INFORMADO\",\n",
    "            'grau_nuclear': \"NÃO INFORMADO\",\n",
    "            'formacao_tubulos': \"NÃO INFORMADO\",\n",
    "            'indice_mitotico': \"NÃO INFORMADO\",\n",
    "            'tipo_histologico': \"NÃO INFORMADO\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba33528d",
   "metadata": {},
   "source": [
    "## Funções para Extração Baseada em Regras e Validação de Resultados\n",
    "\n",
    "Esta célula implementa um conjunto abrangente de funções para extrair informações dos laudos utilizando expressões regulares (abordagem baseada em regras) e para validar as respostas do modelo de IA contra essa extração.\n",
    "\n",
    "### Funções de Extração por Expressões Regulares\n",
    "\n",
    "#### 1. Lista de Termos e Tipos\n",
    "Duas listas são definidas:\n",
    "- `TERMS`: Lista de descritores de malignidade a serem identificados nos laudos\n",
    "- `TIPOS`: Lista de tipos histológicos a serem identificados nos laudos\n",
    "\n",
    "#### 2. Funções Específicas para Cada Campo\n",
    "\n",
    "##### `extrai_descritores(txt)`\n",
    "- **Objetivo**: Identificar todos os descritores de malignidade presentes no texto\n",
    "- **Método**: Para cada termo na lista `TERMS`, verifica sua presença no texto usando expressão regular com fronteira de palavra (`\\\\b`)\n",
    "- **Saída**: Lista ordenada de termos encontrados\n",
    "\n",
    "##### `extrai_grau_histologico(txt)`\n",
    "- **Objetivo**: Extrair o grau histológico (1, 2 ou 3) do texto\n",
    "- **Método**: Usa expressão regular para identificar padrões como \"grau histológico: 2\" ou variações\n",
    "- **Saída**: Valor numérico ou `None` se não encontrado\n",
    "\n",
    "##### `extrai_grau_nuclear(txt)`\n",
    "- **Objetivo**: Extrair o grau nuclear (1, 2 ou 3) do texto\n",
    "- **Método**: Similar ao grau histológico, procura por padrões específicos\n",
    "- **Saída**: Valor numérico ou `None` se não encontrado\n",
    "\n",
    "##### `extrai_formacao_tubulos(txt)`\n",
    "- **Objetivo**: Extrair a classificação de formação de túbulos (1, 2 ou 3)\n",
    "- **Método**: Busca padrões como \"formação de túbulos: 2\" com tratamento para variações de escrita\n",
    "- **Saída**: Valor numérico ou `None` se não encontrado\n",
    "\n",
    "##### `extrai_indice_mitotico(txt)`\n",
    "- **Objetivo**: Extrair o índice mitótico do texto\n",
    "- **Método**: Busca por padrões como \"mitótico: 2 mm2\" ou \"índice mitótico 3/10 mm2\"\n",
    "- **Saída**: Valor numérico ou `None` se não encontrado\n",
    "\n",
    "##### `extrai_tipo_histologico(txt)`\n",
    "- **Objetivo**: Identificar o tipo histológico mencionado no texto\n",
    "- **Método**: Converte o texto para minúsculas e verifica a presença de cada tipo da lista `TIPOS`\n",
    "- **Saída**: String com o tipo histológico ou `None` se não encontrado\n",
    "\n",
    "### Função de Validação\n",
    "\n",
    "#### `avalia_extracao_sem_ground_truth(laudo_texto, json_modelo)`\n",
    "- **Objetivo**: Comparar os resultados da extração por IA com uma extração baseada em regras\n",
    "- **Método**: \n",
    "  1. Gera um \"pseudo-gold standard\" usando as funções de extração por regras\n",
    "  2. Compara cada campo extraído pela IA com o correspondente do pseudo-gold\n",
    "  3. Para descritores de malignidade, compara os conjuntos de termos\n",
    "  4. Para campos numéricos/texto, compara os valores exatos\n",
    "- **Saída**: \n",
    "  1. O dicionário completo do pseudo-gold\n",
    "  2. Um dicionário de comparações contendo, para cada campo:\n",
    "     - O valor do pseudo-gold\n",
    "     - O valor extraído pela IA\n",
    "     - Um booleano indicando se houve acerto\n",
    "\n",
    "### Impacto e Uso\n",
    "\n",
    "Este conjunto de funções é fundamental para:\n",
    "\n",
    "1. **Validação Automática**: Permite avaliar o desempenho do modelo de IA sem necessidade de anotação manual\n",
    "2. **Métricas de Qualidade**: Fornece base para calcular taxas de acerto por campo\n",
    "3. **Diagnóstico de Erros**: Possibilita identificar padrões específicos onde a IA apresenta dificuldades\n",
    "\n",
    "Esta abordagem de \"validação sem ground truth\" é especialmente valiosa em cenários onde a criação de um conjunto de dados de referência manualmente anotado seria custosa e demorada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fbd3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TERMS = ['carcinoma', 'invasivo', 'invasor', 'sarcoma', \n",
    "         'metástase', 'metastático', 'maligno', 'maligna', \n",
    "         'cdi', 'cli', 'cdis']\n",
    "\n",
    "def extrai_descritores(txt):\n",
    "    achados = set()\n",
    "    for termo in TERMS:\n",
    "        # insensível a maiúsculas e minúsculas, plenos caracteres\n",
    "        if re.search(rf\"\\b{re.escape(termo)}\\b\", txt, flags=re.IGNORECASE):\n",
    "            achados.add(termo.lower())\n",
    "    return sorted(achados)  # lista em ordem alfabética\n",
    "\n",
    "def extrai_grau_histologico(txt):\n",
    "    # Captura algo como \"Grau histológico: 2\" ou \"grau histológico 2\"\n",
    "    m = re.search(r\"grau\\s+histol[oó]gico\\s*[:\\-]?\\s*(\\d)\", txt, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        return int(m.group(1))\n",
    "    return None\n",
    "\n",
    "def extrai_grau_nuclear(txt):\n",
    "    m = re.search(r\"grau\\s+nuclear\\s*[:\\-]?\\s*(\\d)\", txt, flags=re.IGNORECASE)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def extrai_formacao_tubulos(txt):\n",
    "    m = re.search(r\"forma[cç][aã]o\\s+de\\s+t[uú]bulos\\s*[:\\-]?\\s*(\\d)\", txt, flags=re.IGNORECASE)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def extrai_indice_mitotico(txt):\n",
    "    # Ex.: \"índice mitótico 3/10 mm2\" ou \"mitótico: 2 mm2\"\n",
    "    m = re.search(r\"mit[oó]tico\\s*[:\\-]?\\s*(\\d+)\\s*/?\\s*\\d*\\s*mm2\", txt, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        return int(m.group(1))\n",
    "    return None\n",
    "\n",
    "TIPOS = [\n",
    "  \"carcinoma de mama ductal invasivo\",\n",
    "  \"carcinoma de mama ductal in situ\",\n",
    "  \"carcinoma de mama lobular invasivo\",\n",
    "  \"carcinoma de mama lobular\",\n",
    "  \"carcinoma de mama papilífero\",\n",
    "  \"carcinoma de mama metapl[aá]sico\",\n",
    "  \"carcinoma de mama mucinoso\",\n",
    "  \"carcinoma de mama tubular\",\n",
    "  \"carcinoma de mama c[ií]stico adenoide\",\n",
    "  \"carcinoma de mama medular\",\n",
    "  \"carcinoma de mama micropapilar\",\n",
    "  \"carcinoma de mama misto (ductal e lobular) invasivo\"\n",
    "]\n",
    "\n",
    "def extrai_tipo_histologico(txt):\n",
    "    txt_lower = txt.lower()\n",
    "    for tipo in TIPOS:\n",
    "        # usar comparação simplificada, removendo acentos se quiser\n",
    "        padrao = tipo.lower()\n",
    "        if padrao in txt_lower:\n",
    "            return tipo  # retorna exatamente a frase padronizada\n",
    "    return None\n",
    "\n",
    "def avalia_extracao_sem_ground_truth(laudo_texto, json_modelo):\n",
    "    # 1. Gera pseudo-gold\n",
    "    descrs_hei = extrai_descritores(laudo_texto)\n",
    "    gr_hist_hei = extrai_grau_histologico(laudo_texto)\n",
    "    gr_nuc_hei  = extrai_grau_nuclear(laudo_texto)\n",
    "    form_tub_hei= extrai_formacao_tubulos(laudo_texto)\n",
    "    ind_mit_hei = extrai_indice_mitotico(laudo_texto)\n",
    "    tipo_histo_hei = extrai_tipo_histologico(laudo_texto)\n",
    "\n",
    "    json_heu = {\n",
    "        \"descritores_malignidade\": descrs_hei,\n",
    "        \"grau_histologico\": gr_hist_hei if gr_hist_hei is not None else \"NÃO INFORMADO\",\n",
    "        \"grau_nuclear\": gr_nuc_hei if gr_nuc_hei is not None else \"NÃO INFORMADO\",\n",
    "        \"formacao_tubulos\": form_tub_hei if form_tub_hei is not None else \"NÃO INFORMADO\",\n",
    "        \"indice_mitotico\": ind_mit_hei if ind_mit_hei is not None else \"NÃO INFORMADO\",\n",
    "        \"tipo_histologico\": tipo_histo_hei if tipo_histo_hei is not None else \"NÃO INFORMADO\"\n",
    "    }\n",
    "\n",
    "    # 2. Prepara json_modelo – já é recebido do ChatGPT como dicionário Python\n",
    "\n",
    "    # 3. Comparações campo a campo:\n",
    "    comparacoes = {}\n",
    "\n",
    "    # 3.1. Descritores de malignidade: compara igualdade exata (acertos ou não)\n",
    "    val_heu_desc = set(json_heu[\"descritores_malignidade\"])\n",
    "    val_mod_desc = set(json_modelo.get(\"descritores_malignidade\", []))\n",
    "    acertou_desc = (val_heu_desc == val_mod_desc)\n",
    "    comparacoes[\"descritores_malignidade\"] = {\n",
    "        \"pseudo_gold\": json_heu[\"descritores_malignidade\"],\n",
    "        \"IA\": json_modelo.get(\"descritores_malignidade\", []),\n",
    "        \"acertou\": acertou_desc\n",
    "    }\n",
    "\n",
    "    # 3.2. Para cada campo numérico ou de texto, basta verificar igualdade exata\n",
    "    def compara_campo(nome):\n",
    "        val_heu = json_heu[nome]\n",
    "        val_mod = json_modelo.get(nome, \"NÃO INFORMADO\")\n",
    "        acertou = (val_heu == val_mod)\n",
    "        return {\n",
    "            \"pseudo_gold\": val_heu,\n",
    "            \"IA\": val_mod,\n",
    "            \"acertou\": acertou\n",
    "        }\n",
    "\n",
    "    for campo in [\"grau_histologico\", \"grau_nuclear\", \"formacao_tubulos\", \"indice_mitotico\", \"tipo_histologico\"]:\n",
    "        comparacoes[campo] = compara_campo(campo)\n",
    "\n",
    "    return json_heu, comparacoes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f368be7d",
   "metadata": {},
   "source": [
    "## Função para Agregação e Análise de Resultados de Validação\n",
    "\n",
    "Esta célula implementa a função `agrega_resultados()` que processa os resultados das comparações individuais entre as extrações do modelo de IA e o pseudo-gold standard, gerando métricas consolidadas de desempenho.\n",
    "\n",
    "### Objetivo da Função\n",
    "\n",
    "A função `agrega_resultados()` tem como objetivo calcular estatísticas agregadas sobre o desempenho do modelo de IA na extração de informações dos laudos, incluindo:\n",
    "- Contagem total de acertos por campo\n",
    "- Taxa de acerto (percentual de sucesso) para cada campo\n",
    "- Métricas gerais sobre o volume de dados processados\n",
    "\n",
    "### Parâmetros e Estrutura\n",
    "\n",
    "**Parâmetro de Entrada**:\n",
    "- `lista_comparacoes`: Lista de dicionários, cada um contendo os resultados da comparação para um laudo individual\n",
    "\n",
    "**Fluxo de Processamento**:\n",
    "1. Calcula o total de laudos processados (`total_laudos = len(lista_comparacoes)`)\n",
    "2. Inicializa contadores para rastrear acertos:\n",
    "   - `acertos_descritores` para descritores de malignidade\n",
    "   - `acertos_campos` usando `Counter()` para demais campos\n",
    "3. Itera pela lista de comparações:\n",
    "   - Verifica e incrementa contador se houve acerto em descritores de malignidade\n",
    "   - Para cada campo (grau histológico, nuclear, etc.), verifica e conta acertos\n",
    "4. Constrói um dicionário de resultados com estatísticas para cada campo\n",
    "\n",
    "**Estrutura do Resultado**:\n",
    "Para cada campo (descritores_malignidade, grau_histológico, etc.), a função gera:\n",
    "```python\n",
    "{\n",
    "    \"acertos\": número_de_acertos,\n",
    "    \"total\": total_de_laudos,\n",
    "    \"taxa_acerto\": número_de_acertos / total_de_laudos\n",
    "}\n",
    "```\n",
    "\n",
    "### Campos Analisados\n",
    "\n",
    "A função calcula métricas para todos os campos relevantes:\n",
    "- Descritores de malignidade\n",
    "- Grau histológico\n",
    "- Grau nuclear\n",
    "- Formação de túbulos\n",
    "- Índice mitótico\n",
    "- Tipo histológico\n",
    "\n",
    "### Importância e Uso\n",
    "\n",
    "Este tipo de função de agregação é essencial para:\n",
    "1. Avaliar o desempenho global do modelo de IA na tarefa de extração\n",
    "2. Identificar campos específicos onde o modelo pode estar enfrentando dificuldades\n",
    "3. Acompanhar a evolução do desempenho ao longo do tempo ou com diferentes configurações de prompt\n",
    "\n",
    "As métricas geradas podem ser usadas para:\n",
    "- Reportar o desempenho do modelo para stakeholders\n",
    "- Definir thresholds de confiança para uso em produção\n",
    "- Identificar oportunidades de melhoria no prompt ou no processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c792937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def agrega_resultados(lista_comparacoes):\n",
    "    total_laudos = len(lista_comparacoes)\n",
    "    \n",
    "    # Conta quantos acertos em descritores_malignidade\n",
    "    acertos_descritores = 0\n",
    "    \n",
    "    # Conta acertos por campo numérico/textual\n",
    "    acertos_campos = Counter()\n",
    "    \n",
    "    for comp in lista_comparacoes:\n",
    "        # Para descritores_malignidade, só existe \"acertou\"\n",
    "        if comp[\"descritores_malignidade\"][\"acertou\"]:\n",
    "            acertos_descritores += 1\n",
    "        \n",
    "        # Para cada campo numérico/textual\n",
    "        for campo in [\n",
    "            \"grau_histologico\", \n",
    "            \"grau_nuclear\", \n",
    "            \"formacao_tubulos\", \n",
    "            \"indice_mitotico\", \n",
    "            \"tipo_histologico\"\n",
    "        ]:\n",
    "            if comp[campo][\"acertou\"]:\n",
    "                acertos_campos[campo] += 1\n",
    "\n",
    "    resultado = {\n",
    "        \"descritores_malignidade\": {\n",
    "            \"acertos\": acertos_descritores,\n",
    "            \"total\": total_laudos,\n",
    "            \"taxa_acerto\": acertos_descritores / total_laudos if total_laudos > 0 else 0.0\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for campo in [\n",
    "        \"grau_histologico\", \n",
    "        \"grau_nuclear\", \n",
    "        \"formacao_tubulos\", \n",
    "        \"indice_mitotico\", \n",
    "        \"tipo_histologico\"\n",
    "    ]:\n",
    "        acertou = acertos_campos[campo]\n",
    "        resultado[campo] = {\n",
    "            \"acertos\": acertou,\n",
    "            \"total\": total_laudos,\n",
    "            \"taxa_acerto\": acertou / total_laudos if total_laudos > 0 else 0.0\n",
    "        }\n",
    "\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b449f5e",
   "metadata": {},
   "source": [
    "## Processamento Principal e Geração de Métricas\n",
    "\n",
    "Esta célula contém o núcleo do processamento do notebook, onde todas as funções definidas anteriormente são utilizadas para extrair, processar, validar e analisar os dados dos laudos anatomopatológicos. Este bloco de código é executado condicionalmente, apenas se houver dados disponíveis para processamento (`num_linhas > 0`).\n",
    "\n",
    "### Fluxo de Processamento\n",
    "\n",
    "O código segue um fluxo sequencial lógico:\n",
    "\n",
    "1. **Inicialização do Cliente de API**:\n",
    "   - Configura o cliente OpenAI usando o token Databricks e o endpoint específico\n",
    "   - Define o papel do modelo como \"médico oncologista especialista em laudos de mamografia\"\n",
    "\n",
    "2. **Limitação do Dataset** (para testes):\n",
    "   ```python\n",
    "   df_anatomopatologico = df_anatomopatologico.limit(200)\n",
    "   ```\n",
    "   Esta linha limita o processamento a 200 laudos para fins de teste. Em um ambiente de produção, esta linha seria removida ou ajustada.\n",
    "\n",
    "3. **Extração dos Laudos**:\n",
    "   - Coleta os textos dos laudos do DataFrame em uma lista Python\n",
    "   - Facilita o processamento em lote pelo modelo de IA\n",
    "\n",
    "4. **Processamento com o Modelo de IA**:\n",
    "   - Chama a função `batch_generate()` com tamanho de lote 10\n",
    "   - Processa todos os laudos coletados, gerando respostas estruturadas\n",
    "\n",
    "5. **Conversão e Limpeza das Respostas**:\n",
    "   - Aplica a função `limpar_e_converter()` a cada resposta\n",
    "   - Transforma as respostas textuais em dicionários Python estruturados\n",
    "\n",
    "6. **Criação de DataFrame com Resultados**:\n",
    "   - Define um schema Spark para os dados extraídos\n",
    "   - Cria um novo DataFrame com as extrações do modelo\n",
    "\n",
    "7. **Indexação e Join dos DataFrames**:\n",
    "   - Adiciona um índice sequencial a ambos os DataFrames\n",
    "   - Realiza um join para combinar os dados originais com as extrações\n",
    "\n",
    "8. **Avaliação e Validação**:\n",
    "   - Compara cada extração com seu correspondente \"pseudo-gold\"\n",
    "   - Gera métricas detalhadas para cada campo extraído\n",
    "\n",
    "9. **Análise de Resultados**:\n",
    "   - Cria um DataFrame de métricas com informações detalhadas\n",
    "   - Gera um resumo agregado de desempenho com `agrega_resultados()`\n",
    "\n",
    "### Aspectos Importantes\n",
    "\n",
    "#### Código Comentado\n",
    "\n",
    "A célula contém várias seções comentadas que representam funcionalidades potencialmente úteis:\n",
    "\n",
    "1. **Criação da Tabela Feature Store**:\n",
    "   ```python\n",
    "   #fs = FeatureStoreClient()\n",
    "   #fs.create_table(...)\n",
    "   ```\n",
    "   Este código criaria uma tabela permanente para armazenar os resultados.\n",
    "\n",
    "2. **Persistência dos Resultados**:\n",
    "   ```python\n",
    "   #fs = FeatureStoreClient()\n",
    "   #if num_linhas > 0:\n",
    "   #    print(f\"Há {num_linhas} registros para inserir — executando gravação…\")\n",
    "   #    ...\n",
    "   ```\n",
    "   Este código salvaria os resultados na tabela Feature Store.\n",
    "\n",
    "3. **Registro de Métricas no MLflow**:\n",
    "   ```python\n",
    "   # mlflow.set_experiment(...)\n",
    "   # with mlflow.start_run(run_name=\"Extracao_Laudos_Run_Threshold\"):\n",
    "   #     ...\n",
    "   ```\n",
    "   Este código registraria as métricas de desempenho no MLflow para acompanhamento.\n",
    "\n",
    "#### Resultados Gerados\n",
    "\n",
    "A execução desta célula produz:\n",
    "\n",
    "1. **DataFrame Final (`df_final`)**:\n",
    "   - Contém os dados originais dos laudos\n",
    "   - Inclui todas as extrações do modelo de IA\n",
    "\n",
    "2. **Métricas Detalhadas (`df_metrics`)**:\n",
    "   - DataFrame pandas com resultados detalhados para cada laudo\n",
    "   - Inclui comparações entre extração baseada em regras e IA\n",
    "\n",
    "3. **Métricas Agregadas (`json_metricas`)**:\n",
    "   - Resumo do desempenho da extração\n",
    "   - Taxas de acerto por campo extraído\n",
    "\n",
    "### Considerações de Desempenho\n",
    "\n",
    "- O processamento está limitado a 200 registros para testes\n",
    "- O tamanho de lote está configurado para 10, o que equilibra eficiência e carga na API\n",
    "- As etapas de validação são computacionalmente intensivas mas necessárias para garantir qualidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb5709a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_linhas > 0:\n",
    "    llm_client = openai.OpenAI(api_key=DATABRICKS_TOKEN,\n",
    "                           base_url=\"https://dbc-d80f50a9-af23.cloud.databricks.com/serving-endpoints\"\n",
    "                           )\n",
    "    descricao_agente = \"Atue como um médico oncologista especialista em laudos de mamografia.\"\n",
    "\n",
    "    ###################### Apenas para testes #################\n",
    "    df_anatomopatologico = df_anatomopatologico.limit(200)\n",
    "    ###########################################################\n",
    "\n",
    "    rows = df_anatomopatologico.select(\"laudo_tratado\").collect()\n",
    "    laudos = [row.laudo_tratado for row in rows]\n",
    "\n",
    "    respostas = batch_generate(descricao_agente, laudos, llm_client, batch_size=10)\n",
    "\n",
    "    lista_dicts = [limpar_e_converter(item) for item in respostas]\n",
    "\n",
    "    schema = StructType([\n",
    "        StructField(\"descritores_malignidade\", ArrayType(StringType()), True),\n",
    "        StructField(\"grau_histologico\", StringType(), True),\n",
    "        StructField(\"grau_nuclear\", StringType(), True),\n",
    "        StructField(\"formacao_tubulos\", StringType(), True),\n",
    "        StructField(\"indice_mitotico\", StringType(), True),\n",
    "        StructField(\"tipo_histologico\", StringType(), True),\n",
    "    ])\n",
    "\n",
    "    df_lista = spark.createDataFrame(lista_dicts, schema=schema)\n",
    "\n",
    "    w = Window.orderBy(F.lit(1))\n",
    "\n",
    "    df_imuno_indexed = (\n",
    "        df_anatomopatologico\n",
    "        .withColumn(\"row_id\", F.row_number().over(w) - 1)  # subtrai 1 para ficar zero‐based\n",
    "    )\n",
    "\n",
    "    df_lista_indexed = (\n",
    "        df_lista\n",
    "        .withColumn(\"row_id\", F.row_number().over(w) - 1)\n",
    "    )\n",
    "\n",
    "    df_final = df_imuno_indexed.join(df_lista_indexed, on=\"row_id\").drop(\"row_id\")\n",
    "\n",
    "    # Base histórica\n",
    "    #fs = FeatureStoreClient()\n",
    "    #fs = FeatureStoreClient()\n",
    "    #fs.create_table(\n",
    "    #    name=\"refined.saude_preventiva.pardini_laudos_mamo_anatomia_patologica\",\n",
    "    #    primary_keys=[\"id_unidade\", \"id_cliente\", \"id_item\", \"id_subitem\", \"id_exame\"],\n",
    "    #    schema=df_final.schema,\n",
    "    #    description=\"Features extraídas de laudos de mamografia/biopsia (Anatomia Patológica). Siglas: \"\n",
    "    #)\n",
    "\n",
    "    # Append em prd\n",
    "    #num_linhas = df_final.count()\n",
    "    #fs = FeatureStoreClient()\n",
    "    #if num_linhas > 0:\n",
    "    #    print(f\"Há {num_linhas} registros para inserir — executando gravação…\")\n",
    "    #    primary_keys = [\"id_unidade\", \"id_cliente\", \"id_item\", \"id_subitem\", \"id_exame\"]\n",
    "    #    ###### Apenas para testes ##############\n",
    "    #    df_final = df_final.dropna()\n",
    "    #    df_final = df_final.dropDuplicates(primary_keys)\n",
    "    #    ########################################\n",
    "    #    primary_keys = [\"id_unidade\", \"id_cliente\", \"id_item\", \"id_subitem\", \"id_exame\"]\n",
    "    #    fs.write_table(\n",
    "    #        name=\"refined.saude_preventiva.pardini_laudos_mamo_anatomia_patologica\",\n",
    "    #        df=df_final,\n",
    "    #        mode=\"merge\",\n",
    "    #    )\n",
    "    #else:\n",
    "    #    print(\"Nenhum registro encontrado; nada a fazer.\")\n",
    "\n",
    "    lista_laudos = laudos\n",
    "    resultados = []\n",
    "    for laudo_txt, json_mod in zip(lista_laudos, lista_dicts):\n",
    "        pseudo_gold, compar = avalia_extracao_sem_ground_truth(laudo_txt, json_mod)\n",
    "        resultados.append(compar)\n",
    "\n",
    "    df_metrics = pd.DataFrame()\n",
    "    df_metrics[\"laudos\"] = laudos\n",
    "    df_metrics[\"resultados\"] = resultados\n",
    "    resultados_expandidos = pd.json_normalize(df_metrics[\"resultados\"])\n",
    "    df_metrics = pd.concat(\n",
    "        [df_metrics.drop(columns=[\"resultados\"]), resultados_expandidos],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    json_metricas = agrega_resultados(resultados)\n",
    "\n",
    "    # mlflow.set_experiment(\"/Users/aureliano.paiva@grupofleury.com.br/anatomopatologico_pardini_metricas\")\n",
    "\n",
    "    # threshold = 0.8\n",
    "\n",
    "    # with mlflow.start_run(run_name=\"Extracao_Laudos_Run_Threshold\"):\n",
    "    #     for campo, stats in json_metricas.items():\n",
    "    #         taxa = stats[\"taxa_acerto\"]\n",
    "            \n",
    "    #         # Registrar a taxa de acerto\n",
    "    #         mlflow.log_metric(f\"{campo}_taxa_acerto\", taxa)\n",
    "            \n",
    "    #         # Registrar flag de aprovação no threshold\n",
    "    #         passou_flag = 1 if taxa >= threshold else 0\n",
    "    #         mlflow.log_metric(f\"{campo}_passou_threshold\", passou_flag)\n",
    "            \n",
    "    #         # Opcional: registrar acertos e total\n",
    "    #         mlflow.log_metric(f\"{campo}_acertos\", stats[\"acertos\"])\n",
    "    #         mlflow.log_metric(f\"{campo}_total\", stats[\"total\"])\n",
    "        \n",
    "    #     run_id = mlflow.active_run().info.run_id\n",
    "    #     print(f\"Run registrada: {run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a77723",
   "metadata": {},
   "source": [
    "## Exportação de Dados para Excel (Comentado)\n",
    "\n",
    "Esta célula contém código comentado para exportar os resultados processados para um arquivo Excel. Esta funcionalidade seria útil para análise detalhada fora do ambiente Databricks ou para compartilhamento dos resultados com stakeholders que preferem trabalhar com planilhas.\n",
    "\n",
    "### Funcionalidades Comentadas\n",
    "\n",
    "1. **Instalação do Módulo openpyxl**:\n",
    "   ```python\n",
    "   #%pip install openpyxl\n",
    "   ```\n",
    "   O módulo `openpyxl` é necessário para que o pandas consiga exportar dados para o formato Excel (.xlsx).\n",
    "\n",
    "2. **Conversão do DataFrame Spark para Pandas**:\n",
    "   ```python\n",
    "   #df_pandas = df_final.toPandas()\n",
    "   ```\n",
    "   Esta linha converteria o DataFrame Spark (`df_final`) para um DataFrame pandas, necessário para a exportação para Excel.\n",
    "\n",
    "3. **Exportação para Arquivo Excel**:\n",
    "   ```python\n",
    "   #df_pandas.to_excel(\"fleury_laudos_mamografia_anatomia_patologica.xlsx\", index=False)\n",
    "   ```\n",
    "   Esta linha salvaria os dados no arquivo especificado, sem incluir o índice do DataFrame.\n",
    "\n",
    "### Considerações de Uso\n",
    "\n",
    "Quando descomentado, este código:\n",
    "\n",
    "1. Consumiria memória adicional para converter o DataFrame Spark em pandas\n",
    "2. Criaria um arquivo local no ambiente de execução\n",
    "3. Seria ideal para conjuntos de dados menores devido às limitações de memória\n",
    "\n",
    "Esta funcionalidade seria particularmente útil durante a fase de desenvolvimento e validação do processamento, permitindo análises detalhadas dos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d775dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install openpyxl\n",
    "#df_pandas = df_final.toPandas()\n",
    "#df_pandas.to_excel(\"fleury_laudos_mamografia_anatomia_patologica.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d08553",
   "metadata": {},
   "source": [
    "## Análise Específica de Registros com Grau Histológico (Comentado)\n",
    "\n",
    "Esta célula final contém código comentado para realizar uma análise específica dos laudos que contêm informações sobre grau histológico. O código filtraria os registros relevantes, exportaria um subconjunto para Excel e mostraria os primeiros 100 registros para análise visual.\n",
    "\n",
    "### Funcionalidades Comentadas\n",
    "\n",
    "1. **Configuração de Exibição Expandida do Pandas**:\n",
    "   ```python\n",
    "   #pd.set_option('display.max_colwidth', None)\n",
    "   ```\n",
    "   Esta configuração permitiria visualizar o conteúdo completo das células, sem truncamento, útil para analisar textos longos como os laudos.\n",
    "\n",
    "2. **Filtragem de Registros com Grau Histológico**:\n",
    "   ```python\n",
    "   #df_pandas2 = df_pandas[df_pandas[\"grau_histologico\"] != \"NÃO INFORMADO\"].head(100)\n",
    "   ```\n",
    "   Esta linha:\n",
    "   - Filtraria apenas os registros onde o grau histológico foi extraído com sucesso\n",
    "   - Limitaria o resultado aos primeiros 100 registros\n",
    "   - Criaria um novo DataFrame `df_pandas2` com esse subconjunto\n",
    "\n",
    "3. **Exportação para Excel do Subconjunto**:\n",
    "   ```python\n",
    "   #df_pandas2.to_excel(\"fleury_laudos_mamografia_anatomia_patologica_grauhistologico.xlsx\", index=False)\n",
    "   ```\n",
    "   Salvaria o subconjunto filtrado em um arquivo Excel específico.\n",
    "\n",
    "4. **Visualização dos Dados**:\n",
    "   ```python\n",
    "   #df_pandas2.head(100)\n",
    "   ```\n",
    "   Mostraria os registros no próprio notebook para análise visual imediata.\n",
    "\n",
    "### Utilidade da Análise\n",
    "\n",
    "Este código seria particularmente útil para:\n",
    "1. Análise focada nos casos onde o grau histológico foi identificado\n",
    "2. Validação manual da qualidade da extração desse campo específico\n",
    "3. Criação de exemplos para treinamento ou ajuste do sistema\n",
    "\n",
    "Descomentando e adaptando este código, os usuários poderiam realizar análises semelhantes para outros campos de interesse, como grau nuclear ou tipo histológico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc4190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_colwidth', None)\n",
    "#df_pandas2 = df_pandas[df_pandas[\"grau_histologico\"] != \"NÃO INFORMADO\"].head(100)\n",
    "#df_pandas2.to_excel(\"fleury_laudos_mamografia_anatomia_patologica_grauhistologico.xlsx\", index=False)\n",
    "#df_pandas2.head(100)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
