{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8f2aba0",
   "metadata": {},
   "source": [
    "# Documentação Técnica: Extração de Dados de Anatomia Patológica - Fleury\n",
    "\n",
    "## Objetivo Principal\n",
    "**Este notebook realiza a extração e classificação automática de informações clínicas relevantes em laudos de anatomia patológica de mama do Fleury.** Utilizando técnicas de processamento de linguagem natural (NLP) com modelos de linguagem avançados (LLMs), o notebook identifica descritores de malignidade, graus histológicos e nucleares, formação de túbulos, índices mitóticos e tipos histológicos em laudos médicos de anatomia patológica mamária.\n",
    "\n",
    "## Tecnologias Utilizadas\n",
    "- **OpenAI/Databricks LLM API**: Para processamento e extração de informações dos textos dos laudos\n",
    "- **PySpark**: Framework principal para processamento distribuído de dados\n",
    "- **MLflow**: Para registro de métricas, experimentos e monitoramento dos resultados de extração\n",
    "- **Delta Lake**: Sistema de armazenamento para tabelas de destino\n",
    "- **Pandas**: Manipulação de dataframes para processamento local\n",
    "- **Expressões Regulares (re)**: Validação e extração de padrões específicos nos textos dos laudos\n",
    "- **Octoops**: Monitoramento e alertas de falhas\n",
    "\n",
    "## Fluxo de Trabalho/Etapas Principais\n",
    "1. **Definição dos Parâmetros**: Configuração de tabelas, filtros e critérios de extração\n",
    "2. **Consulta de Dados**: Extração de laudos recentes da base de dados do Fleury\n",
    "3. **Processamento via LLM**:\n",
    "   - Definição do prompt especializado para extração de informações\n",
    "   - Processamento batch dos laudos via API de LLM\n",
    "   - Extração estruturada das informações relevantes\n",
    "4. **Validação dos Resultados**:\n",
    "   - Comparação entre extração via regex e via LLM\n",
    "   - Cálculo de métricas de precisão\n",
    "   - Registro de métricas no MLflow\n",
    "5. **Persistência dos Dados**: Salvamento dos dados processados em tabela Delta\n",
    "\n",
    "## Dados Envolvidos\n",
    "- **Fonte**: Tabela `refined.saude_preventiva.fleury_laudos`\n",
    "- **Filtros**:\n",
    "  - Linha de cuidado: \"mama\"\n",
    "  - Sexo: \"F\" (feminino)\n",
    "  - Siglas de exame: \"ANATPATP\", \"CTPUNC\", \"FISHHER\"\n",
    "  - Laudos contendo \"Topografia: mama\"\n",
    "- **Tabela de Destino**: `refined.saude_preventiva.fleury_laudos_mama_anatomia_patologica_v2`\n",
    "- **Informações Extraídas**:\n",
    "  - **Descritores de Malignidade**: carcinoma, invasivo, invasor, sarcoma, metástase, metastático, maligno, maligna, cdi, cli, cdis\n",
    "  - **Grau Histológico**: 1, 2 ou 3\n",
    "  - **Grau Nuclear**: 1, 2 ou 3\n",
    "  - **Formação de Túbulos**: 1, 2 ou 3\n",
    "  - **Índice Mitótico**: valor numérico\n",
    "  - **Tipo Histológico**: classificação específica do tipo de carcinoma\n",
    "\n",
    "## Resultados/Saídas Esperadas\n",
    "- DataFrame enriquecido com os campos extraídos dos laudos\n",
    "- Registro de métricas de qualidade da extração via MLflow\n",
    "- Dados persistidos na tabela Delta `refined.saude_preventiva.fleury_laudos_mama_anatomia_patologica_v2`\n",
    "- Alertas via Sentinel (Octoops) em caso de falhas ou ausência de dados\n",
    "\n",
    "## Pré-requisitos\n",
    "- Ambiente Databricks configurado\n",
    "- Acesso ao endpoint LLM Databricks (`databricks-llama-4-maverick` ou `teste-maverick`)\n",
    "- Permissões de acesso às tabelas de origem e destino\n",
    "- Bibliotecas instaladas: openai, mlflow, pandas, tqdm, databricks-feature-store, octoops\n",
    "\n",
    "## Considerações Importantes/Observações\n",
    "- A extração via LLM é comparada com uma extração via regex (considerada pseudo-gold) para validação\n",
    "- O threshold definido para aceitação da qualidade da extração é de 80%\n",
    "- O modelo está otimizado para identificar termos específicos de malignidade e classificações dentro do contexto oncológico mamário\n",
    "- Os resultados são registrados no experimento MLflow `/Shared/saude_preventiva_mama/experiments_fleury_anatomopatologico`\n",
    "- A persistência utiliza estratégia de merge (upsert) para garantir a atualização de registros já existentes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be8f4f6",
   "metadata": {},
   "source": [
    "# Extração de dados - Anatomo Patologico\n",
    "Serão analisados os descritores de malignidade.\n",
    "**Descritores de MALIGNIDADE:**\n",
    "- carcinoma\n",
    "- invasivo\n",
    "- invasor\n",
    "- sarcoma\n",
    "- metástase\n",
    "- metastático\n",
    "- maligno\n",
    "- maligna\n",
    "- cdi, cli, cdis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f638f81e",
   "metadata": {},
   "source": [
    "Outros labels a serem extraídos:\n",
    "\n",
    "- **Grau histológico:** será sempre um algarismo 1, 2 ou 3 (apenas três categorias). Para encontrar, basta procurar o primeiro algarismo numérico após o termo **\"grau histológico\"**.\n",
    "\n",
    "- **Grau nuclear:** será sempre um algarismo 1, 2 ou 3 (apenas três categorias). Para encontrar, basta procurar o primeiro algarismo numérico após o termo **\"grau nuclear\"**.\n",
    "\n",
    "- **Formação de túbulos:** será sempre um algarismo 1, 2 ou 3 (apenas três categorias). Para encontrar, basta procurar o primeiro algarismo numérico após o termo **\"formação de túbulos\"**.\n",
    "\n",
    "- **Índice mitótico:** será sempre um algarismo 1, 2 ou 3 (apenas três categorias). Para encontrar, basta procurar o primeiro algarismo numérico após o termo **\"mm2\"**. Nesse caso, é melhor procurar o termo **\"mm2\"** ao invés de **\"índice mitótico\"**.\n",
    "\n",
    "- **Labels de tipos histológicos:**\n",
    "  - Carcinoma de mama ductal invasivo (CDI)/SOE\n",
    "  - Carcinoma de mama ductal in situ\n",
    "  - Carcinoma de mama lobular invasivo\n",
    "  - Carcinoma de mama lobular\n",
    "  - Carcinoma de mama papilífero\n",
    "  - Carcinoma de mama metaplásico\n",
    "  - Carcinoma de mama mucinoso\n",
    "  - Carcinoma de mama tubular\n",
    "  - Carcinoma de mama cístico adenoide\n",
    "  - Carcinoma de mama medular\n",
    "  - Carcinoma de mama micropapilar\n",
    "  - Carcinoma de mama misto (ductal e lobular) invasivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26afa1dd",
   "metadata": {},
   "source": [
    "### Instalação de pacotes necessários\n",
    "**Objetivo da Célula:** Instalar as bibliotecas necessárias para executar o notebook.\n",
    "\n",
    "**Pacotes Instalados:**\n",
    "- **openai**: Cliente para comunicação com a API OpenAI/Databricks LLM\n",
    "- **databricks-feature-store**: Biblioteca para interagir com o Feature Store do Databricks\n",
    "- **octoops**: Biblioteca para monitoramento e alertas\n",
    "\n",
    "A instalação é feita usando o comando mágico `%pip`, que é específico para ambientes Jupyter/Databricks. O parâmetro `-q` (quiet) é usado em algumas instalações para reduzir a verbosidade da saída."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b90dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai\n",
    "# %pip install tqdm -q\n",
    "# %pip install pandarallel -q\n",
    "%pip install databricks-feature-store -q\n",
    "%pip install octoops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b783373d",
   "metadata": {},
   "source": [
    "### Reinicialização do ambiente Python\n",
    "**Objetivo da Célula:** Reiniciar o kernel Python para garantir que as bibliotecas recém-instaladas sejam carregadas corretamente.\n",
    "\n",
    "Esta célula executa o comando `dbutils.library.restartPython()`, que é específico do ambiente Databricks. Este comando reinicia o interpretador Python, garantindo que todas as bibliotecas instaladas na célula anterior sejam devidamente carregadas no ambiente de execução. Isso é necessário porque, em ambientes Jupyter/Databricks, as bibliotecas instaladas durante a execução do notebook só ficam disponíveis após a reinicialização do kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6a8ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e98aa0d",
   "metadata": {},
   "source": [
    "### Importação de bibliotecas e configuração do ambiente\n",
    "**Objetivo da Célula:** Importar todas as bibliotecas necessárias para o processamento de dados e desativar exibições automáticas do MLflow.\n",
    "\n",
    "**Dependências:**\n",
    "- Bibliotecas instaladas nas células anteriores\n",
    "\n",
    "**Bibliotecas Importadas:**\n",
    "- **re**: Para manipulação de expressões regulares\n",
    "- **os, sys**: Manipulação do sistema e ambiente\n",
    "- **json, time**: Processamento de JSON e controle de tempo\n",
    "- **warnings**: Controle de mensagens de aviso\n",
    "- **mlflow**: Rastreamento de experimentos e métricas\n",
    "- **tqdm**: Barras de progresso para processos iterativos\n",
    "- **pandas, numpy**: Manipulação e análise de dados\n",
    "- **typing**: Anotações de tipo para melhor documentação do código\n",
    "- **openai**: Cliente para API de LLM\n",
    "- **dateutil.relativedelta**: Cálculos avançados de datas\n",
    "- **pyspark.sql**: Componentes do Spark SQL\n",
    "- **databricks.feature_store**: Cliente para Feature Store do Databricks\n",
    "\n",
    "**Configurações Realizadas:**\n",
    "- Desativa a exibição automática do MLflow no notebook com `mlflow.tracing.disable_notebook_display()`\n",
    "\n",
    "**Variáveis/Objetos Criados:**\n",
    "- Não cria variáveis persistentes além das importações\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- Prepara o ambiente de execução com todas as dependências necessárias\n",
    "- Desativa logs automáticos do MLflow que poderiam sobrecarregar a interface do notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8153cbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "import mlflow\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Any\n",
    "import openai\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "from databricks.feature_store import FeatureStoreClient\n",
    "\n",
    "mlflow.tracing.disable_notebook_display()\n",
    "\n",
    "# spark = SparkSession.builder.appName(\"LLM_Extractor\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff80d5c2",
   "metadata": {},
   "source": [
    "### Definição de tabelas e filtros para extração de dados\n",
    "**Objetivo da Célula:** Configurar as variáveis de tabela de destino e definir os filtros SQL para seleção de dados recentes e relevantes.\n",
    "\n",
    "**Variáveis/Objetos Criados:**\n",
    "- `table_anatom`: String com o nome completo da tabela de destino (refined.saude_preventiva.fleury_laudos_mama_anatomia_patologica_v2)\n",
    "- `where_clause`: String contendo cláusula SQL WHERE para selecionar apenas registros novos (com datestamp maior que o último processado)\n",
    "- `filtro_extracao`: String contendo filtros para seleção de registros específicos de mama feminina\n",
    "\n",
    "**Lógica Detalhada:**\n",
    "- Define a tabela de destino para resultados de anatomia patológica\n",
    "- Cria uma cláusula WHERE que seleciona apenas registros mais recentes que o último datestamp na tabela de destino (processamento incremental)\n",
    "- Define filtros para extração que limitam os registros aos laudos:\n",
    "  - Da linha de cuidado \"mama\"\n",
    "  - De pacientes do sexo feminino (UPPER(sexo_cliente) = 'F')\n",
    "  - Com siglas de exames específicas (ANATPATP, CTPUNC, FISHHER)\n",
    "  - Contendo a expressão \"Topografia: mama\" no texto do laudo\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- As variáveis definidas serão utilizadas posteriormente na consulta SQL para extrair dados relevantes de laudos de anatomia patológica mamária\n",
    "- A abordagem de filtro por datestamp garante processamento incremental, evitando reprocessamento de registros já analisados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db3e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtros de extração\n",
    "table_anatom = \"refined.saude_preventiva.fleury_laudos_mama_anatomia_patologica_v2\" \n",
    "\n",
    "where_clause = f\"\"\"\n",
    "WHERE\n",
    "    flr.`_datestamp` >= (\n",
    "        SELECT MAX(anatom._datestamp)\n",
    "        FROM {table_anatom} anatom\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    " \n",
    "filtro_extracao = \"\"\"\n",
    "    WHERE\n",
    "        linha_cuidado  = 'mama'\n",
    "        AND UPPER(sexo_cliente) = 'F'\n",
    "        AND sigla_exame IN (\"ANATPATP\", \"CTPUNC\", \"FISHHER\")\n",
    "        AND laudo_tratado RLIKE '(?i)Topografia: mama'\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee9b469",
   "metadata": {},
   "source": [
    "### Construção e execução da consulta SQL\n",
    "**Objetivo da Célula:** Criar uma consulta SQL para extrair laudos relevantes e executá-la para obter os dados a serem processados pelo modelo LLM.\n",
    "\n",
    "**Variáveis/Objetos Criados:**\n",
    "- `query`: String contendo a consulta SQL completa com placeholders para os filtros definidos anteriormente\n",
    "- `df_spk`: DataFrame Spark resultante da execução da consulta\n",
    "\n",
    "**Lógica Detalhada:**\n",
    "1. Define uma consulta SQL com Common Table Expression (CTE) chamada `base`\n",
    "2. Seleciona campos relevantes dos laudos: identificadores, datas, informações do exame e o conteúdo do laudo\n",
    "3. Aplica os filtros definidos anteriormente:\n",
    "   - Processamento incremental via `where_clause` (registros mais recentes que o último processado)\n",
    "   - Filtros específicos de mama via `filtro_extracao` (linha de cuidado, sexo, siglas de exame, conteúdo do laudo)\n",
    "4. Executa a consulta usando `spark.sql()`, formatando a string para incluir os filtros\n",
    "5. Exibe o resultado via `display(df_spk)`\n",
    "\n",
    "**Tabelas/Colunas Utilizadas:**\n",
    "- Tabela: `refined.saude_preventiva.fleury_laudos` (alias `flr`)\n",
    "- Colunas principais:\n",
    "  - Identificadores: `id_marca`, `id_unidade`, `id_cliente`, `id_ficha`, `ficha`, `id_item`, `id_subitem`, `id_exame`\n",
    "  - Datas: `dth_pedido`, `dth_resultado`\n",
    "  - Dados do exame: `sigla_exame`, `laudo_tratado`, `linha_cuidado`, `sexo_cliente`\n",
    "  - Metadata: `_datestamp`\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- Cria o DataFrame `df_spk` contendo os laudos de anatomia patológica mamária que serão processados\n",
    "- Exibe o conteúdo do DataFrame na interface do notebook para visualização prévia dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ca167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "WITH \n",
    "base AS (\n",
    "    SELECT\n",
    "        flr.id_marca,\n",
    "        flr.id_unidade,\n",
    "        flr.id_cliente, \n",
    "        flr.id_ficha,\n",
    "        flr.ficha,\n",
    "        flr.id_item, \n",
    "        flr.id_subitem, \n",
    "        flr.id_exame, \n",
    "        flr.dth_pedido,\n",
    "        flr.dth_resultado,\n",
    "        flr.sigla_exame,\n",
    "        flr.laudo_tratado,\n",
    "        flr.linha_cuidado,\n",
    "        flr.sexo_cliente,\n",
    "        flr.`_datestamp`\n",
    "    FROM refined.saude_preventiva.fleury_laudos flr \n",
    "    {where_clause}\n",
    " \n",
    "    \n",
    ")\n",
    "SELECT *\n",
    "FROM base\n",
    "{filtro_extracao}\n",
    "\"\"\"\n",
    "df_spk = spark.sql(query)\n",
    "display(df_spk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95743f3",
   "metadata": {},
   "source": [
    "### Obtenção do token de acesso Databricks\n",
    "**Objetivo da Célula:** Obter o token de autenticação do Databricks para ser utilizado nas chamadas à API do LLM.\n",
    "\n",
    "**Variáveis/Objetos Criados:**\n",
    "- `DATABRICKS_TOKEN`: Token de autenticação para acesso às APIs Databricks\n",
    "\n",
    "**Lógica Detalhada:**\n",
    "- Utiliza a API interna do Databricks para obter o token da sessão atual\n",
    "- A construção condicional verifica se o contexto do notebook está disponível\n",
    "- Se o contexto existir, obtém o token via API\n",
    "- Se não existir, define o token como None\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- O token será utilizado posteriormente para autenticar as chamadas ao serviço de LLM do Databricks\n",
    "- Este método de obtenção de token é mais seguro que armazenar o token diretamente no código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ebeccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABRICKS_TOKEN = (\n",
    "    dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "    if dbutils.notebook.entry_point.getDbutils().notebook().getContext() is not None\n",
    "    else None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5008ca",
   "metadata": {},
   "source": [
    "### Definição do prompt para extração de informações via LLM\n",
    "**Objetivo da Célula:** Criar uma função que gera o prompt especializado para extração de informações de laudos médicos através de um modelo de linguagem.\n",
    "\n",
    "**Função Definida:**\n",
    "- `prompt_laudo(laudo_texto: str) -> str`: Função que recebe o texto do laudo e retorna o prompt formatado\n",
    "\n",
    "**Lógica Detalhada:**\n",
    "1. A função recebe o texto do laudo como parâmetro\n",
    "2. Constrói um prompt estruturado com instruções específicas para o modelo LLM\n",
    "3. O prompt inclui:\n",
    "   - O texto do laudo entre aspas triplas\n",
    "   - Instruções detalhadas sobre quais informações extrair e como formatá-las\n",
    "   - Especificações sobre os descritores de malignidade, graus histológicos, nucleares, etc.\n",
    "   - Formato esperado da saída (dicionário Python)\n",
    "4. Retorna o prompt formatado como uma string\n",
    "\n",
    "**Critérios de Extração no Prompt:**\n",
    "- **Descritores de malignidade**: Lista de termos específicos (carcinoma, invasivo, etc.)\n",
    "- **Grau histológico**: Valor numérico (1, 2 ou 3)\n",
    "- **Grau nuclear**: Valor numérico (1, 2 ou 3)\n",
    "- **Formação de túbulos**: Valor numérico (1, 2 ou 3)\n",
    "- **Índice mitótico**: Valor numérico após \"mm2\"\n",
    "- **Tipo histológico**: Correspondência com uma lista de tipos específicos de carcinomas\n",
    "\n",
    "**Saída Esperada:**\n",
    "- Um dicionário Python com os campos extraídos ou \"NÃO INFORMADO\" quando a informação não está presente\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- Define a função que será utilizada posteriormente para criar prompts personalizados para cada laudo\n",
    "- A qualidade desta formatação de prompt é crucial para a precisão da extração de informações pelo LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1de97c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_laudo(laudo_texto: str) -> str:\n",
    "    prompt = f\"\"\"A seguir está um laudo médico de mamografia. Se alguma informação não estiver presente no texto, retorne \"NÃO INFORMADO\". Sempre retorne apenas o dicionário Python.\n",
    "\n",
    "    Laudo clínico:\n",
    "    \\\"\\\"\\\"{laudo_texto}\\\"\\\"\\\"\n",
    "\n",
    "    ### Critérios de extração:\n",
    "\n",
    "    - **Descritores de malignidade**: retorne uma **lista** com os termos de malignidade encontrados no texto (case-insensitive). Se nenhum for encontrado, retorne lista vazia `[]`. Lista de termos: ['carcinoma', \"invasivo\", \"invasor\", \"sarcoma\", \"metástase\", \"metastático\", \"maligno\", \"maligna\", \"cdi\", \"cli\", \"cdis\"]\n",
    "\n",
    "    - **Grau histológico**: retorne o valor numérico do grau histológico.\n",
    "\n",
    "    - **Grau nuclear**: retorne o valor numérico do grau nuclear.\n",
    "\n",
    "    - **Formação de túbulos**: retorne o valor numérico caso exista formação de túbulos.\n",
    "\n",
    "    - **Índice mitótico**: retorne o valor numérico do score do índice mitótico que aparece após o mm2.\n",
    "\n",
    "    - **Tipo histológico**: identifique e retorne a frase correspondente se algum dos seguintes for mencionado (case-insensitive, variações aceitas):\n",
    "      - Carcinoma de mama ductal invasivo\n",
    "      - Carcinoma de mama ductal in situ\n",
    "      - Carcinoma de mama lobular invasivo\n",
    "      - Carcinoma de mama lobular\n",
    "      - Carcinoma de mama papilífero\n",
    "      - Carcinoma de mama metaplásico\n",
    "      - Carcinoma de mama mucinoso\n",
    "      - Carcinoma de mama tubular\n",
    "      - Carcinoma de mama cístico adenoide\n",
    "      - Carcinoma de mama medular\n",
    "      - Carcinoma de mama micropapilar\n",
    "      - Carcinoma de mama misto (ductal e lobular) invasivo\n",
    "\n",
    "    ### Saída esperada (dicionário Python válido):\n",
    "    ```python\n",
    "    {{\n",
    "      \"descritores_malignidade\": [\"termo1\", \"termo2\", ...],\n",
    "      \"grau_histologico\": número | \"NÃO INFORMADO\",\n",
    "      \"grau_nuclear\": número | \"NÃO INFORMADO\",\n",
    "      \"formacao_tubulos\": número | \"NÃO INFORMADO\",\n",
    "      \"indice_mitotico\": número | \"NÃO INFORMADO\",\n",
    "      \"tipo_histologico\": \"texto correspondente ou 'NÃO INFORMADO'\n",
    "    }}\n",
    "    ```\n",
    "    \"\"\"\n",
    "    return prompt.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f7faac",
   "metadata": {},
   "source": [
    "### Funções para geração de respostas usando o LLM\n",
    "**Objetivo da Célula:** Definir funções que gerenciam as chamadas à API do LLM e processam respostas para análise de laudos médicos.\n",
    "\n",
    "**Funções Definidas:**\n",
    "1. `generate(descricao_agente:str, laudo:str, llm_client) -> str`: Função principal para enviar um laudo ao modelo e obter resposta\n",
    "2. `batch_generate(descricao_agente, laudos, llm_client, batch_size=25)`: Função para processar múltiplos laudos em lotes\n",
    "\n",
    "**Lógica Detalhada da Função `generate`:**\n",
    "1. Recebe os parâmetros: descrição do papel do LLM, texto do laudo, e o cliente da API\n",
    "2. Cria o prompt específico para o laudo usando a função `prompt_laudo()`\n",
    "3. Monta a estrutura de mensagens para a API:\n",
    "   - Mensagem de sistema definindo o papel do LLM\n",
    "   - Mensagem do usuário contendo o prompt com o laudo\n",
    "4. Define parâmetros para a chamada ao modelo:\n",
    "   - Modelo: \"teste-maverick\" (endpoint do Databricks)\n",
    "   - Temperatura: 0 (determinístico)\n",
    "   - Tokens máximos: 4000\n",
    "   - Outros parâmetros de controle da geração de texto\n",
    "5. Implementa mecanismo de retry (3 tentativas) em caso de falha de conexão\n",
    "6. Retorna o texto da resposta do modelo\n",
    "\n",
    "**Lógica Detalhada da Função `batch_generate`:**\n",
    "1. Recebe listas de laudos, descrição do agente, cliente da API e tamanho do lote\n",
    "2. Inicializa o cliente OpenAI com o token do Databricks\n",
    "3. Divide os laudos em lotes menores (padrão: 25 laudos por lote)\n",
    "4. Para cada lote, processa cada laudo individualmente usando a função `generate()`\n",
    "5. Exibe barra de progresso usando tqdm\n",
    "6. Retorna lista com todas as respostas do modelo\n",
    "\n",
    "**Dependências:**\n",
    "- Função `prompt_laudo()` definida anteriormente\n",
    "- Variável `DATABRICKS_TOKEN` para autenticação\n",
    "- Biblioteca tqdm para exibição de progresso\n",
    "- Cliente OpenAI para comunicação com a API\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- As funções definidas serão utilizadas posteriormente para processamento dos laudos extraídos\n",
    "- O mecanismo de retry aumenta a robustez do sistema a falhas temporárias de rede/API\n",
    "- O processamento em batch otimiza o uso da API e permite monitoramento de progresso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f43bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(descricao_agente:str, laudo:str, llm_client) -> str:\n",
    "    \"\"\"\n",
    "    Gera o resultado da análise de um laudo\n",
    "    Params:\n",
    "        descricao_agente: descricao do agente que a LLM representa (primeira mensagem enviada à LLM)\n",
    "        prompt: prompt base que será utilizado para gerar a análise\n",
    "        laudo: laudo a ser analisado (incluido dentro do prompt)\n",
    "        llm_client: cliente da API da LLM\n",
    "    Return:\n",
    "        response_message: resposta da LLM\n",
    "    \"\"\"\n",
    "    prompt = prompt_laudo(laudo)\n",
    "    messages = [\n",
    "        # Utilizamos o primeiro prompt para contextualizar o llm do que ele deve fazer. \n",
    "        # No exemplo utilizamos a abordagem Role, Task, Output, Prompting.\n",
    "        # Mas sintam-se a vontade para alterar de acordo com a necessidade\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": descricao_agente\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ]\n",
    "    model_params = {\n",
    "        \"model\": \"teste-maverick\",\n",
    "        #\"model\": \"databricks-llama-4-maverick\",\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0,\n",
    "        \"max_tokens\": 4000,\n",
    "        \"top_p\": 0.75,\n",
    "        \"frequency_penalty\": 0,\n",
    "        \"presence_penalty\": 0\n",
    "    }\n",
    "    connection_retry = 0\n",
    "    while connection_retry < 3:\n",
    "        try:\n",
    "            response = llm_client.chat.completions.create(**model_params)\n",
    "            response_message = response.choices[0].message.content            \n",
    "            # para obter qtde de tokens\n",
    "            # usage = response.usage        \n",
    "            # prompt_tokens = usage.prompt_tokens\n",
    "            # completion_tokens = usage.completion_tokens\n",
    "            # total_tokens = usage.total_tokens\n",
    "            break\n",
    "        # TODO: verificar se a excessao é de conexao\n",
    "        except (ConnectionError, TimeoutError) as e:\n",
    "            connection_retry += 1\n",
    "            print(\"Sem reposta do modelo\")\n",
    "            print(str(e))\n",
    "            print(\"Tentando novamente...\")\n",
    "            time.sleep(0.1)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    if connection_retry >= 3:\n",
    "        response_message = ''\n",
    "        #usage = ()\n",
    "        \n",
    "    \n",
    "    return response_message #,usage\n",
    "\n",
    "\n",
    "def batch_generate(descricao_agente, laudos, llm_client, batch_size=25):\n",
    "    responses = []\n",
    "    \n",
    "    llm_client = openai.OpenAI(\n",
    "        api_key=DATABRICKS_TOKEN,\n",
    "        base_url=\"https://dbc-d80f50a9-af23.cloud.databricks.com/serving-endpoints\"\n",
    "    )\n",
    "    \n",
    "    # Dividir em lotes\n",
    "    for i in range(0, len(laudos), batch_size):\n",
    "        laudos_batch = laudos[i:i+batch_size]\n",
    "        for laudo in tqdm(laudos_batch, desc=f\"Processando lote {i//batch_size + 1}\", total=len(laudos_batch)):\n",
    "            responses.append(generate(descricao_agente, laudo, llm_client))\n",
    "    \n",
    "    return responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1c549a",
   "metadata": {},
   "source": [
    "### Implementação alternativa do cliente OpenAI (comentada)\n",
    "**Objetivo da Célula:** Manter uma implementação alternativa do cliente OpenAI para referência futura.\n",
    "\n",
    "Esta célula contém uma implementação alternativa para a comunicação com o modelo LLM que está atualmente comentada. A implementação define uma função `generate` simplificada que:\n",
    "\n",
    "1. Utiliza o cliente OpenAI diretamente instanciado na célula\n",
    "2. Tenta estabelecer a conexão com até 3 tentativas em caso de erro\n",
    "3. Inclui tratamento de exceções mais genérico\n",
    "\n",
    "Esta implementação foi provavelmente substituída pela versão atual na célula anterior, mas foi mantida como referência para possíveis ajustes futuros ou situações em que uma abordagem mais simples seja necessária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ec4f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # nova implementação\n",
    "# llm_client = OpenAI(\n",
    "#     api_key=DATABRICKS_TOKEN,\n",
    "#     base_url=\"https://dbc-d80f50a9-af23.cloud.databricks.com/serving-endpoints\"\n",
    "# )\n",
    "\n",
    "# def generate(descricao_agente: str, laudo: str) -> str:\n",
    "#     prompt = prompt_laudo(laudo)\n",
    "#     messages = [\n",
    "#         {\n",
    "#             \"role\": \"system\",\n",
    "#             \"content\": descricao_agente\n",
    "#         },\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": prompt\n",
    "#         }\n",
    "#     ]\n",
    "#     connection_retry = 0\n",
    "#     while connection_retry < 3:\n",
    "#         try:\n",
    "#             response = client.chat.completions.create(\n",
    "#                 model=\"teste-maverick\",\n",
    "#                 messages=messages,\n",
    "#                 max_tokens=4000,\n",
    "#                 temperature=0,\n",
    "#                 top_p=0.75,\n",
    "#                 frequency_penalty=0,\n",
    "#                 presence_penalty=0\n",
    "#             )\n",
    "#             response_message = response.choices[0].message.content\n",
    "#             break\n",
    "#         except Exception as e:\n",
    "#             print(f\"Erro na requisição: {e}\")\n",
    "#             connection_retry += 1\n",
    "#             print(\"Tentando novamente...\")\n",
    "#             time.sleep(0.1)\n",
    "\n",
    "#     if connection_retry >= 3:\n",
    "#         response_message = ''\n",
    "\n",
    "#     return response_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e714389",
   "metadata": {},
   "source": [
    "### Implementação para endpoint usando requests (comentada)\n",
    "**Objetivo da Célula:** Manter uma implementação alternativa para chamadas diretas ao endpoint usando a biblioteca requests.\n",
    "\n",
    "Esta célula contém outra abordagem comentada para comunicação com o endpoint LLM do Databricks, usando a biblioteca requests em vez do cliente OpenAI. Esta implementação:\n",
    "\n",
    "1. Faz chamadas HTTP POST diretas ao endpoint de serviço\n",
    "2. Gerencia cabeçalhos e payload da requisição manualmente\n",
    "3. Processa a resposta JSON diretamente\n",
    "4. Implementa um mecanismo de retry para lidar com falhas temporárias de conexão\n",
    "\n",
    "Esta implementação foi comentada e substituída pelo uso do cliente OpenAI oficial, provavelmente por oferecer uma interface mais limpa e gerenciar melhor as requisições. No entanto, é mantida como referência para casos onde o acesso direto via HTTP seja necessário ou para debugging de problemas de comunicação com o endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe63fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # implementação para o endpoint (Aguarando Ricardo_Arquitetura)\n",
    "\n",
    "# def generate(descricao_agente: str, laudo: str, llm_client) -> str:\n",
    "#     \"\"\"\n",
    "#     Gera o resultado da análise de um laudo\n",
    "#     Params:\n",
    "#         descricao_agente: descricao do agente que a LLM representa (primeira mensagem enviada à LLM)\n",
    "#         prompt: prompt base que será utilizado para gerar a análise\n",
    "#         laudo: laudo a ser analisado (incluido dentro do prompt)\n",
    "#         llm_client: cliente da API da LLM\n",
    "#     Return:\n",
    "#         response_message: resposta da LLM\n",
    "#     \"\"\"\n",
    "#     prompt = prompt_laudo(laudo)\n",
    "#     messages = [\n",
    "#         {\n",
    "#             \"role\": \"system\",\n",
    "#             \"content\": descricao_agente\n",
    "#         },\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": prompt\n",
    "#         }\n",
    "#     ]\n",
    "#     payload = {\n",
    "#         \"model\": \"databricks-llama-4-maverick\",\n",
    "#         \"messages\": messages,\n",
    "#         \"temperature\": 0,\n",
    "#         \"max_tokens\": 4000,\n",
    "#         \"top_p\": 0.75,\n",
    "#         \"frequency_penalty\": 0,\n",
    "#         \"presence_penalty\": 0\n",
    "#     }\n",
    "#     connection_retry = 0\n",
    "#     while connection_retry < 3:\n",
    "#         try:\n",
    "#             url =\"https://dbc-d80f50a9-af23.cloud.databricks.com/serving-endpoints/teste-maverick/invocations\"\n",
    "#             #\"https://dbc-d80f50a9-af23.cloud.databricks.com/serving-endpoints/batch-saudepreventiva/invocations\"\n",
    "#             response = requests.post(url, headers=headers, json=payload)\n",
    "#             response.raise_for_status()            \n",
    "#             data = response.json()\n",
    "#             response_message = data.choices[0].message.content \n",
    "#             #data[\"choices\"][0][\"message\"][\"content\"]                      \n",
    "#             usage = data[\"usage\"]\n",
    "#             prompt_tokens = usage[\"prompt_tokens\"]\n",
    "#             completion_tokens = usage[\"completion_tokens\"]\n",
    "#             total_tokens = usage[\"total_tokens\"]\n",
    "#             print(\"Requisição bem-sucedida!\")\n",
    "#             print(data)\n",
    "#             break\n",
    "#         except requests.exceptions.RequestException as e:\n",
    "#             print(f\"Erro na requisição: {e}\")\n",
    "#             if response:\n",
    "#                 print(f\"Status Code: {response.status_code}\")\n",
    "#                 print(f\"Resposta do servidor: {response.text}\")\n",
    "#             connection_retry += 1\n",
    "#             print(\"Tentando novamente...\")\n",
    "#             time.sleep(0.1)\n",
    "#         except Exception as e:\n",
    "#             raise e\n",
    "\n",
    "#     if connection_retry >= 3:\n",
    "#         response_message = ''\n",
    "\n",
    "#     return response_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc5e164",
   "metadata": {},
   "source": [
    "### Implementação alternativa para polling de endpoint (comentada)\n",
    "**Objetivo da Célula:** Manter uma referência de como fazer polling de um endpoint Databricks usando o cliente OpenAI.\n",
    "\n",
    "Esta célula comentada contém código que mostra uma implementação alternativa para inicializar o cliente OpenAI e configurar headers para chamadas diretas ao endpoint. Embora não esteja em uso, fornece um exemplo útil para casos em que seja necessário configurar manualmente headers e realizar polling de endpoints em situações específicas.\n",
    "\n",
    "O código está estruturado para inicializar o cliente OpenAI com o token Databricks e configurar headers de autorização para requisições HTTP, o que pode ser útil em contextos onde a API cliente padrão não atende a todas as necessidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed01afeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_client = openai.OpenAI(\n",
    "#     api_key=DATABRICKS_TOKEN,\n",
    "#     base_url= \"https://dbc-d80f50a9-af23.cloud.databricks.com/serving-endpoints/teste-maverick/invocations\"\n",
    "#     #\"https://dbc-d80f50a9-af23.cloud.databricks.com/serving-endpoints/batch-saudepreventiva/invocations\"\n",
    "    \n",
    "# ) \n",
    "\n",
    "# headers = {\n",
    "# \"Authorization\": f\"Bearer {DATABRICKS_TOKEN}\",\n",
    "# \"Content-Type\": \"application/json\"\n",
    "# }\n",
    "\n",
    "\n",
    "# def batch_generate(descricao_agente, laudos, llm_client, batch_size=25):\n",
    "#     responses = [] \n",
    "\n",
    "#     # Dividir em lotes\n",
    "#     for i in range(0, len(laudos), batch_size):\n",
    "#         laudos_batch = laudos[i:i+batch_size]\n",
    "#         for laudo in tqdm(laudos_batch, desc=f\"Processando lote {i//batch_size + 1}\", total=len(laudos_batch)):\n",
    "#             responses.append(generate(descricao_agente, laudo, llm_client))\n",
    "    \n",
    "#     return responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42726c97",
   "metadata": {},
   "source": [
    "### Função para limpeza e conversão de respostas JSON\n",
    "**Objetivo da Célula:** Definir uma função que limpa as respostas do LLM e as converte para formato dicionário Python.\n",
    "\n",
    "**Função Definida:**\n",
    "- `limpar_e_converter(item)`: Processa strings de resposta do LLM para obter dicionários Python estruturados\n",
    "\n",
    "**Lógica Detalhada:**\n",
    "1. Remove marcadores de código Markdown (```python, ```) da resposta\n",
    "2. Faz o parse do texto resultante como JSON para obter um dicionário Python\n",
    "3. Em caso de erro, retorna um dicionário padrão com valores \"NÃO INFORMADO\" e lista vazia para descritores\n",
    "\n",
    "**Tratamento de Erros:**\n",
    "- Captura exceções durante a conversão e as registra\n",
    "- Garante que sempre retorne um dicionário válido mesmo em caso de falha de parsing\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- Transforma as respostas textuais do LLM em objetos Python estruturados que podem ser facilmente processados\n",
    "- Garante resiliência através do fornecimento de valores padrão em caso de falha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e2f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpar_e_converter(item):\n",
    "    try:\n",
    "        item_limpo = re.sub(r\"```(?:python)?\", \"\", item).replace(\"```\", \"\").strip()\n",
    "        return json.loads(item_limpo)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao converter resposta: {e}\")\n",
    "        return {\n",
    "            'descritores_malignidade': [],\n",
    "            'grau_histologico': \"NÃO INFORMADO\",\n",
    "            'grau_nuclear': \"NÃO INFORMADO\",\n",
    "            'formacao_tubulos': \"NÃO INFORMADO\",\n",
    "            'indice_mitotico': \"NÃO INFORMADO\",\n",
    "            'tipo_histologico': \"NÃO INFORMADO\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b8ad9d",
   "metadata": {},
   "source": [
    "### Funções para extração por RegEx e validação das respostas do LLM\n",
    "**Objetivo da Célula:** Implementar um conjunto de funções que extraem informações dos laudos usando expressões regulares e comparam com as respostas do LLM.\n",
    "\n",
    "**Funções Definidas:**\n",
    "1. Funções de extração por RegEx:\n",
    "   - `extrai_descritores`: Encontra descritores de malignidade no texto\n",
    "   - `extrai_grau_histologico`: Extrai o grau histológico (1, 2 ou 3)\n",
    "   - `extrai_grau_nuclear`: Extrai o grau nuclear (1, 2 ou 3)\n",
    "   - `extrai_formacao_tubulos`: Extrai o valor de formação de túbulos (1, 2 ou 3)\n",
    "   - `extrai_indice_mitotico`: Extrai o índice mitótico\n",
    "   - `extrai_tipo_histologico`: Identifica o tipo histológico específico\n",
    "\n",
    "2. Função de avaliação:\n",
    "   - `avalia_extracao_sem_ground_truth`: Compara a extração do LLM com a extração por RegEx\n",
    "\n",
    "**Lógica Detalhada:**\n",
    "- `extrai_descritores`: Procura por cada termo da lista TERMS no texto usando regex case-insensitive\n",
    "- `extrai_grau_histologico`, `extrai_grau_nuclear`, `extrai_formacao_tubulos`: Procuram por padrões específicos seguidos de um dígito\n",
    "- `extrai_indice_mitotico`: Procura por um valor numérico próximo ao termo \"mm2\" ou \"mitoses\"\n",
    "- `extrai_tipo_histologico`: Compara o texto com uma lista predefinida de tipos histológicos\n",
    "- `avalia_extracao_sem_ground_truth`: \n",
    "  1. Gera um pseudo-gold standard usando as funções de extração por RegEx\n",
    "  2. Compara campo a campo com as extrações do LLM\n",
    "  3. Retorna um relatório detalhado de concordância\n",
    "\n",
    "**Constantes Definidas:**\n",
    "- `TERMS`: Lista de termos associados a malignidade\n",
    "- `TIPOS`: Lista de padrões de tipos histológicos a serem buscados\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- As funções serão utilizadas para avaliar a qualidade das extrações do modelo LLM\n",
    "- A avaliação usa as extrações por RegEx como pseudo-gold standard\n",
    "- Os resultados da comparação serão utilizados para métricas e monitoramento do desempenho do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728ef6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TERMS = ['carcinoma', 'invasivo', 'invasor', 'sarcoma', \n",
    "         'metástase', 'metastático', 'maligno', 'maligna', \n",
    "         'cdi', 'cli', 'cdis']\n",
    "\n",
    "def extrai_descritores(txt):\n",
    "    achados = set()\n",
    "    for termo in TERMS:\n",
    "        # insensível a maiúsculas e minúsculas, plenos caracteres\n",
    "        if re.search(rf\"\\b{re.escape(termo)}\\b\", txt, flags=re.IGNORECASE):\n",
    "            achados.add(termo.lower())\n",
    "    return sorted(achados)  # lista em ordem alfabética\n",
    "\n",
    "def extrai_grau_histologico(txt):\n",
    "    # Captura algo como \"Grau histológico: 2\" ou \"grau histológico 2\"\n",
    "    m = re.search(r\"grau\\s+histol[oó]gico\\s*[:\\-]?\\s*(\\d)\", txt, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        return int(m.group(1))\n",
    "    return None\n",
    "\n",
    "def extrai_grau_nuclear(txt):\n",
    "    # Captura algo como \"Grau nuclear: 3\" ou \"grau nuclear 1\"\n",
    "    m = re.search(r\"grau\\s+nuclear\\s*[:\\-]?\\s*(\\d)\", txt, flags=re.IGNORECASE)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def extrai_formacao_tubulos(txt):\n",
    "    # Ex.: \"formação de túbulos: 2\" ou \"formação de túbulos 3\"\n",
    "    m = re.search(r\"forma[cç][aã]o\\s+de\\s+t[uú]bulos\\s*[:\\-]?\\s*(\\d)\", txt, flags=re.IGNORECASE)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "# def extrai_indice_mitotico(txt):\n",
    "#     # Ex.: \"índice mitótico 3/10 mm2\" ou \"mitótico: 2 mm2\"\n",
    "#     m = re.search(r\"mit[oó]tico\\s*[:\\-]?\\s*(\\d+)\\s*/?\\s*\\d*\\s*mm2\", txt, flags=re.IGNORECASE)\n",
    "#     if m:\n",
    "#         return int(m.group(1))\n",
    "#     return None\n",
    "\n",
    "def extrai_indice_mitotico(txt):\n",
    "    # Ex.: \"índice mitótico 3/10 mm2\", \"mitótico: 2 mm2\", \"Índice mitótico: 1 mitose / mm2\", \"Índice mitótico: 11 mitoses / mm2\"\n",
    "    m = re.search(r\"mit[oó]tico\\s*[:\\-]?\\s*(\\d+)(?:\\s*/\\s*\\d+)?\\s*(?:mitoses?|mitose)?\\s*/?\\s*mm2\", txt, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        return int(m.group(1))\n",
    "    return None\n",
    "\n",
    "TIPOS = [\n",
    "  \"carcinoma de mama ductal invasivo\",\n",
    "  \"carcinoma de mama ductal in situ\",\n",
    "  \"carcinoma de mama lobular invasivo\",\n",
    "  \"carcinoma de mama lobular\",\n",
    "  \"carcinoma de mama papilífero\",\n",
    "  \"carcinoma de mama metapl[aá]sico\",\n",
    "  \"carcinoma de mama mucinoso\",\n",
    "  \"carcinoma de mama tubular\",\n",
    "  \"carcinoma de mama c[ií]stico adenoide\",\n",
    "  \"carcinoma de mama medular\",\n",
    "  \"carcinoma de mama micropapilar\",\n",
    "  \"carcinoma de mama misto (ductal e lobular) invasivo\"\n",
    "]\n",
    "\n",
    "def extrai_tipo_histologico(txt):\n",
    "    txt_lower = txt.lower()\n",
    "    for tipo in TIPOS:\n",
    "        # usar comparação simplificada, removendo acentos se quiser\n",
    "        padrao = tipo.lower()\n",
    "        if padrao in txt_lower:\n",
    "            return tipo  # retorna exatamente a frase padronizada\n",
    "    return None\n",
    "\n",
    "def avalia_extracao_sem_ground_truth(laudo_texto, json_modelo):\n",
    "    # 1. Gera pseudo-gold\n",
    "    descrs_hei = extrai_descritores(laudo_texto)\n",
    "    gr_hist_hei = extrai_grau_histologico(laudo_texto)\n",
    "    gr_nuc_hei  = extrai_grau_nuclear(laudo_texto)\n",
    "    form_tub_hei= extrai_formacao_tubulos(laudo_texto)\n",
    "    ind_mit_hei = extrai_indice_mitotico(laudo_texto)\n",
    "    tipo_histo_hei = extrai_tipo_histologico(laudo_texto)\n",
    "\n",
    "    json_heu = {\n",
    "        \"descritores_malignidade\": descrs_hei,\n",
    "        \"grau_histologico\": gr_hist_hei if gr_hist_hei is not None else \"NÃO INFORMADO\",\n",
    "        \"grau_nuclear\": gr_nuc_hei if gr_nuc_hei is not None else \"NÃO INFORMADO\",\n",
    "        \"formacao_tubulos\": form_tub_hei if form_tub_hei is not None else \"NÃO INFORMADO\",\n",
    "        \"indice_mitotico\": ind_mit_hei if ind_mit_hei is not None else \"NÃO INFORMADO\",\n",
    "        \"tipo_histologico\": tipo_histo_hei if tipo_histo_hei is not None else \"NÃO INFORMADO\"\n",
    "    }\n",
    "\n",
    "    # 2. Prepara json_modelo – já é recebido do ChatGPT como dicionário Python\n",
    "\n",
    "    # 3. Comparações campo a campo:\n",
    "    comparacoes = {}\n",
    "\n",
    "    # 3.1. Descritores de malignidade: compara igualdade exata (acertos ou não)\n",
    "    val_heu_desc = set(json_heu[\"descritores_malignidade\"])\n",
    "    val_mod_desc = set(json_modelo.get(\"descritores_malignidade\", []))\n",
    "    acertou_desc = (val_heu_desc == val_mod_desc)\n",
    "    comparacoes[\"descritores_malignidade\"] = {\n",
    "        \"pseudo_gold\": json_heu[\"descritores_malignidade\"],\n",
    "        \"IA\": json_modelo.get(\"descritores_malignidade\", []),\n",
    "        \"acertou\": acertou_desc\n",
    "    }\n",
    "\n",
    "    # 3.2. Para cada campo numérico ou de texto, basta verificar igualdade exata\n",
    "    def compara_campo(nome):\n",
    "        val_heu = json_heu[nome]\n",
    "        val_mod = json_modelo.get(nome, \"NÃO INFORMADO\")\n",
    "        acertou = (val_heu == val_mod)\n",
    "        return {\n",
    "            \"pseudo_gold\": val_heu,\n",
    "            \"IA\": val_mod,\n",
    "            \"acertou\": acertou\n",
    "        }\n",
    "\n",
    "    for campo in [\"grau_histologico\", \"grau_nuclear\", \"formacao_tubulos\", \"indice_mitotico\", \"tipo_histologico\"]:\n",
    "        comparacoes[campo] = compara_campo(campo)\n",
    "\n",
    "    return json_heu, comparacoes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91fa155",
   "metadata": {},
   "source": [
    "### Função para agregação e análise de resultados\n",
    "**Objetivo da Célula:** Implementar uma função que agrega os resultados das comparações entre LLM e regex para calcular métricas de precisão.\n",
    "\n",
    "**Função Definida:**\n",
    "- `agrega_resultados(lista_comparacoes)`: Calcula estatísticas agregadas sobre a precisão da extração por campo\n",
    "\n",
    "**Lógica Detalhada:**\n",
    "1. Recebe uma lista de resultados de comparações (geradas pela função `avalia_extracao_sem_ground_truth`)\n",
    "2. Calcula para cada campo de interesse:\n",
    "   - Número total de acertos\n",
    "   - Taxa de acerto (acertos ÷ total)\n",
    "3. Estrutura os resultados em um dicionário aninhado por campo\n",
    "4. Usa um `Counter` para facilitar a contagem de acertos por campo\n",
    "\n",
    "**Campos Analisados:**\n",
    "- `descritores_malignidade`: Acurácia na extração da lista de termos de malignidade\n",
    "- `grau_histologico`: Acurácia na extração do grau histológico\n",
    "- `grau_nuclear`: Acurácia na extração do grau nuclear\n",
    "- `formacao_tubulos`: Acurácia na extração dos valores de formação de túbulos\n",
    "- `indice_mitotico`: Acurácia na extração do índice mitótico\n",
    "- `tipo_histologico`: Acurácia na extração do tipo histológico\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- Retorna um dicionário estruturado com estatísticas detalhadas sobre a precisão da extração\n",
    "- Este dicionário será utilizado para registro de métricas no MLflow e para avaliação da qualidade do modelo\n",
    "- As taxas de acerto servirão para determinar se o modelo atende ao threshold de qualidade estabelecido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45e1c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def agrega_resultados(lista_comparacoes):\n",
    "    total_laudos = len(lista_comparacoes)\n",
    "    \n",
    "    # Conta quantos acertos em descritores_malignidade\n",
    "    acertos_descritores = 0\n",
    "    \n",
    "    # Conta acertos por campo numérico/textual\n",
    "    acertos_campos = Counter()\n",
    "    \n",
    "    for comp in lista_comparacoes:\n",
    "        # Para descritores_malignidade, só existe \"acertou\"\n",
    "        if comp[\"descritores_malignidade\"][\"acertou\"]:\n",
    "            acertos_descritores += 1\n",
    "        \n",
    "        # Para cada campo numérico/textual\n",
    "        for campo in [\n",
    "            \"grau_histologico\", \n",
    "            \"grau_nuclear\", \n",
    "            \"formacao_tubulos\", \n",
    "            \"indice_mitotico\", \n",
    "            \"tipo_histologico\"\n",
    "        ]:\n",
    "            if comp[campo][\"acertou\"]:\n",
    "                acertos_campos[campo] += 1\n",
    "\n",
    "    resultado = {\n",
    "        \"descritores_malignidade\": {\n",
    "            \"acertos\": acertos_descritores,\n",
    "            \"total\": total_laudos,\n",
    "            \"taxa_acerto\": acertos_descritores / total_laudos if total_laudos > 0 else 0.0\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for campo in [\n",
    "        \"grau_histologico\", \n",
    "        \"grau_nuclear\", \n",
    "        \"formacao_tubulos\", \n",
    "        \"indice_mitotico\", \n",
    "        \"tipo_histologico\"\n",
    "    ]:\n",
    "        acertou = acertos_campos[campo]\n",
    "        resultado[campo] = {\n",
    "            \"acertos\": acertou,\n",
    "            \"total\": total_laudos,\n",
    "            \"taxa_acerto\": acertou / total_laudos if total_laudos > 0 else 0.0\n",
    "        }\n",
    "\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906a59d4",
   "metadata": {},
   "source": [
    "### Processamento e avaliação dos laudos com o modelo LLM\n",
    "**Objetivo da Célula:** Processar os laudos extraídos utilizando o modelo LLM, avaliar a qualidade das extrações e preparar os dados para persistência.\n",
    "\n",
    "**Dependências:**\n",
    "- DataFrames e funções definidas anteriormente\n",
    "- Token de autenticação Databricks\n",
    "- Cliente OpenAI configurado\n",
    "\n",
    "**Lógica Detalhada:**\n",
    "1. Verifica se há dados disponíveis para processamento (`df_spk.count() > 0`)\n",
    "2. Inicializa o cliente OpenAI com o token Databricks e configuração do endpoint\n",
    "3. Define o contexto do agente LLM como \"médico oncologista especialista em laudos de mamografia\"\n",
    "4. Converte o DataFrame Spark para Pandas para processamento local (limitado a 15 registros para teste)\n",
    "5. Processa os laudos em batch utilizando a função `batch_generate`\n",
    "6. Limpa e converte as respostas do LLM para formato estruturado utilizando `limpar_e_converter`\n",
    "7. Avalia a qualidade das extrações comparando com extrações via RegEx\n",
    "8. Calcula métricas agregadas de precisão\n",
    "\n",
    "**Variáveis/Objetos Criados:**\n",
    "- `llm_client`: Cliente para comunicação com a API do LLM\n",
    "- `descricao_agente`: Descrição do papel do LLM na análise\n",
    "- `df_local`: DataFrame Pandas para processamento local\n",
    "- `df_respostas`: DataFrame Spark com as respostas processadas\n",
    "- `resultados`: Lista de comparações entre extrações via LLM e RegEx\n",
    "- `json_metricas`: Estatísticas agregadas sobre a qualidade da extração\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- Cria um DataFrame enriquecido com as informações extraídas dos laudos\n",
    "- Exibe o DataFrame processado via `display(df_respostas)`\n",
    "- Prepara os dados para registro de métricas no MLflow e persistência em tabela Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8875a656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, LongType, IntegerType\n",
    "from pyspark.sql.functions import from_json, col\n",
    "from pyspark.sql.functions import col, pandas_udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import requests\n",
    "\n",
    "# Iniciar sessão Spark\n",
    "spark = SparkSession.builder.appName(\"DfPandasparaSpark\").getOrCreate()\n",
    "\n",
    "# realizar extração\n",
    "\n",
    "if df_spk.count() > 0:\n",
    "    llm_client = openai.OpenAI(api_key=DATABRICKS_TOKEN,\n",
    "                           base_url=\"https://dbc-d80f50a9-af23.cloud.databricks.com/serving-endpoints\"\n",
    "                           #\"https://dbc-d80f50a9-af23.cloud.databricks.com/serving-endpoints\"\n",
    "                           )\n",
    "    descricao_agente = \"Atue como um médico oncologista especialista em laudos de mamografia.\"\n",
    "\n",
    "    # Coleta os dados localmente    \n",
    "    df_local = df_spk.select(\"ficha\", \"id_item\", \"id_subitem\", \"id_cliente\", \"dth_pedido\", \"dth_resultado\", \"sigla_exame\", \"laudo_tratado\", \"linha_cuidado\", \"_datestamp\").limit(15).toPandas()\n",
    "    \n",
    "\n",
    "    # Aplica o LLM localmente\n",
    "    # respostas = batch_generate(descricao_agente, df_local[\"laudo_tratado\"].tolist(), llm_client, batch_size=100)\n",
    "    #respostas_limpa = [limpar_e_converter(item) for item in respostas]\n",
    "    # df_local[\"resposta_llm\"] = batch_generate(descricao_agente, df_local[\"laudo_tratado\"].tolist(), llm_client, batch_size=100)\n",
    "    df_local.loc[:, \"resposta_llm\"] = batch_generate(descricao_agente, df_local[\"laudo_tratado\"].tolist(), llm_client, batch_size=100)\n",
    "    df_local= df_local.join(df_local[\"resposta_llm\"].apply(limpar_e_converter).apply(pd.Series)) \n",
    "    \n",
    "    # Converte de volta para Spark\n",
    "    df_respostas = spark.createDataFrame(df_local) \n",
    "    display(df_respostas)\n",
    "\n",
    "\n",
    "   # FeatureStore - Base histórica\n",
    "    #fs = FeatureStoreClient()\n",
    "    #fs.create_table(\n",
    "    #    name=\"refined.saude_preventiva.fleury_laudos_mamo_anatomia_patologica\",\n",
    "    #    primary_keys=[\"id_unidade\", \"id_cliente\", \"id_item\", \"id_subitem\", \"id_exame\"],\n",
    "    #    schema=df_final.schema,\n",
    "    #    description=\"Features extraídas de laudos de mamografia/biopsia (Anatomia Patológica). Siglas: ANATPATP, CTPUNC, FISHHER\"\n",
    "    #)\n",
    "\n",
    "    # Definição de métricas regex vs llm\n",
    "    lista_laudos = df_respostas.collect()\n",
    "    #display(lista_laudos)\n",
    "    resultados = []\n",
    "    for row in lista_laudos:\n",
    "        laudo_txt = row[\"laudo_tratado\"]\n",
    "        json_mod = limpar_e_converter(row[\"resposta_llm\"])\n",
    "        pseudo_gold, compar = avalia_extracao_sem_ground_truth(laudo_txt, json_mod)\n",
    "        resultados.append(compar)\n",
    "\n",
    "\n",
    "    df_metrics = pd.DataFrame()\n",
    "    df_metrics[\"laudos\"] = df_respostas.select(\"laudo_tratado\").toPandas()[\"laudo_tratado\"]\n",
    "    df_metrics[\"resultados\"] = resultados\n",
    "    resultados_expandidos = pd.json_normalize(df_metrics[\"resultados\"])\n",
    "    df_metrics = pd.concat(\n",
    "        [df_metrics.drop(columns=[\"resultados\"]), resultados_expandidos],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    json_metricas = agrega_resultados(resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a226da65",
   "metadata": {},
   "source": [
    "### Registro de métricas e experimentos no MLflow\n",
    "**Objetivo da Célula:** Criar ou recuperar um experimento no MLflow e registrar as métricas de qualidade da extração.\n",
    "\n",
    "**Dependências:**\n",
    "- Variável `json_metricas` com resultados agregados da avaliação\n",
    "- Bibliotecas mlflow e json\n",
    "\n",
    "**Funções Definidas:**\n",
    "- `get_or_create_experiment(experiment_name)`: Obtém ID de experimento existente ou cria um novo\n",
    "\n",
    "**Lógica Detalhada:**\n",
    "1. Define a função `get_or_create_experiment` para encontrar ou criar um experimento MLflow\n",
    "2. Obtém o ID do experimento para saúde preventiva mamária\n",
    "3. Configura o MLflow para registro automático de informações adicionais (`mlflow.autolog()`)\n",
    "4. Define um threshold de qualidade (80%) para avaliar se as extrações são aceitáveis\n",
    "5. Inicia uma nova execução (run) do MLflow\n",
    "6. Para cada campo avaliado, registra:\n",
    "   - Taxa de acerto (métrica principal)\n",
    "   - Flag indicando se passou no threshold\n",
    "   - Contagens absolutas de acertos e total\n",
    "7. Registra o ID da execução para referência futura\n",
    "\n",
    "**Parâmetros Registrados:**\n",
    "- `modelo`: Nome do modelo LLM utilizado (\"databricks-llama-4-maverick\")\n",
    "\n",
    "**Métricas Registradas:**\n",
    "- Para cada campo (`descritores_malignidade`, `grau_histologico`, etc.):\n",
    "  - `{campo}_taxa_acerto`: Porcentagem de extrações corretas\n",
    "  - `{campo}_passou_threshold`: Flag binária (1 = passou, 0 = falhou)\n",
    "  - `{campo}_acertos`: Número absoluto de extrações corretas\n",
    "  - `{campo}_total`: Número total de documentos avaliados\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- Cria um registro permanente da qualidade do modelo no sistema MLflow\n",
    "- Permite comparação da performance entre diferentes versões do modelo\n",
    "- Fornece ID de execução para referência e rastreabilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dfd61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# import requests\n",
    "import mlflow\n",
    "\n",
    "def get_or_create_experiment(experiment_name):\n",
    "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "    if experiment:\n",
    "        experiment_id = experiment.experiment_id\n",
    "    else:\n",
    "        experiment_id = mlflow.create_experiment(experiment_name)\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    return experiment_id\n",
    "\n",
    "\n",
    "# # criar experimento\n",
    "experiment_id = get_or_create_experiment(\"/Shared/saude_preventiva_mama/experiments_fleury_anatomopatologico\")\n",
    "mlflow.autolog()\n",
    "\n",
    "threshold = 0.8\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id) as run:\n",
    "        #mlflow.log_param(\"modelo\", payload[\"model\"])\n",
    "        mlflow.log_param(\"modelo\", \"databricks-llama-4-maverick\")\n",
    "        # mlflow.log_param(\"prompt_tokens\", usage.prompt_tokens)\n",
    "        # mlflow.log_param(\"completion_tokens\", usage.completion_tokens)\n",
    "        # mlflow.log_param(\"total_tokens\",usage.total_tokens)\n",
    "        for campo, stats in json_metricas.items():\n",
    "            taxa = stats[\"taxa_acerto\"]\n",
    "            mlflow.log_metric(f\"{campo}_taxa_acerto\", taxa)\n",
    "            passou_flag = 1 if taxa >= threshold else 0\n",
    "            mlflow.log_metric(f\"{campo}_passou_threshold\", passou_flag)\n",
    "            mlflow.log_metric(f\"{campo}_acertos\", stats[\"acertos\"])\n",
    "            mlflow.log_metric(f\"{campo}_total\", stats[\"total\"])\n",
    "            \n",
    "            run_id = mlflow.active_run().info.run_id\n",
    "            print(f\"Run registrada: {run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d51445",
   "metadata": {},
   "source": [
    "### Visualização das métricas de qualidade da extração\n",
    "**Objetivo da Célula:** Exibir as métricas de qualidade da extração para análise visual.\n",
    "\n",
    "Esta célula usa a função `display()` para mostrar o dicionário de métricas `json_metricas` que foi calculado anteriormente. Estas métricas fornecem uma visão detalhada do desempenho da extração de informações pelo modelo LLM em comparação com a extração por RegEx, incluindo taxas de acerto para cada campo extraído."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb834c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(json_metricas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae22b538",
   "metadata": {},
   "source": [
    "### Persistência dos dados na tabela Delta\n",
    "**Objetivo da Célula:** Salvar os dados processados na tabela Delta de destino usando uma estratégia de merge.\n",
    "\n",
    "**Dependências:**\n",
    "- DataFrame `df_respostas` contendo os dados processados\n",
    "- Biblioteca Delta para operações de merge em tabelas\n",
    "- Octoops (Sentinel) para monitoramento e alertas\n",
    "\n",
    "**Funções Definidas:**\n",
    "- `insert_data(df_spk, output_data_path)`: Realiza o merge dos dados na tabela Delta especificada\n",
    "\n",
    "**Lógica Detalhada:**\n",
    "1. Define a constante `WEBHOOK_DS_AI_BUSINESS_STG` como 'stg' (ambiente de staging)\n",
    "2. Define a constante `OUTPUT_DATA_PATH` com o nome da tabela de destino\n",
    "3. Implementa a função `insert_data`:\n",
    "   - Carrega a tabela Delta existente\n",
    "   - Realiza um merge usando o DataFrame como origem\n",
    "   - Utiliza chaves de junção: ficha, id_item e id_subitem\n",
    "   - Atualiza registros existentes e insere novos registros\n",
    "4. Em um bloco try-except:\n",
    "   - Verifica se o DataFrame tem registros (`df_respostas.count() > 0`)\n",
    "   - Em caso positivo, chama `insert_data` para persistir os dados\n",
    "   - Em caso negativo, envia alerta via Sentinel informando ausência de laudos para extração\n",
    "   - Em caso de exceção, captura o erro, imprime o traceback e relança a exceção\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- Os dados processados são salvos na tabela Delta usando estratégia de merge\n",
    "- O sistema registra a quantidade de registros salvos\n",
    "- Em caso de falha ou ausência de dados, um alerta é enviado via Sentinel para monitoramento\n",
    "- Exceções são devidamente registradas e relançadas para o sistema de monitoramento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d92e2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "import traceback\n",
    "from octoops import Sentinel\n",
    "\n",
    "WEBHOOK_DS_AI_BUSINESS_STG = 'stg'\n",
    "\n",
    "OUTPUT_DATA_PATH = \"refined.saude_preventiva.fleury_laudos_mama_anatomia_patologica_v2\"\n",
    "\n",
    "# função para salvar dados na tabela\n",
    "def insert_data(df_spk, output_data_path):  \n",
    "    # Carrega a tabela Delta existente\n",
    "    delta_table = DeltaTable.forName(spark, output_data_path)\n",
    "\n",
    "    # Faz o merge (upsert)\n",
    "    (delta_table.alias(\"target\")\n",
    "        .merge(\n",
    "            df_spk.alias(\"source\"),\n",
    "            \"target.ficha = source.ficha AND target.id_item = source.id_item AND target.id_subitem = source.id_subitem\"\n",
    "           \n",
    "        )\n",
    "        .whenMatchedUpdateAll() #atualiza todos os campos se o ID já existir\n",
    "        .whenNotMatchedInsertAll() #insere se o ID não existir\n",
    "        .execute())\n",
    "\n",
    "try:\n",
    "    if df_respostas.count() > 0:        \n",
    "        # Inserir tabela catalog\n",
    "    #    fs.write_table(\n",
    "    #         name=\"refined.saude_preventiva.fleury_laudos_mamo_anatomia_patologica\",\n",
    "    #         df=df_final,\n",
    "    #         mode=\"merge\",\n",
    "    #     )\n",
    "        insert_data(df_respostas, OUTPUT_DATA_PATH)\n",
    "        print('Total de registros salvos na tabela:', df_respostas.count())\n",
    "    else: \n",
    "        error_message = traceback.format_exc()\n",
    "        error_message = \"Fleury AnatomoPatologico - Não há laudos para extração.\"\n",
    "        sentinela_ds_ai_business = Sentinel(\n",
    "            project_name='Monitor_Linhas_Cuidado_Mama',\n",
    "            env_type=WEBHOOK_DS_AI_BUSINESS_STG,\n",
    "            task_title='Fleury AnatomoPatologico'\n",
    "        )\n",
    "\n",
    "        sentinela_ds_ai_business.alerta_sentinela(\n",
    "            categoria='Alerta', \n",
    "            mensagem=error_message,\n",
    "            job_id_descritivo='3_fleury_mama_anatomopatologico'\n",
    "        )\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a948bf75",
   "metadata": {},
   "source": [
    "### Teste do cliente OpenAI com o endpoint Databricks\n",
    "**Objetivo da Célula:** Testar a conexão e funcionamento do cliente OpenAI com o endpoint Databricks.\n",
    "\n",
    "**Dependências:**\n",
    "- Token de autenticação Databricks\n",
    "- Biblioteca OpenAI\n",
    "\n",
    "**Lógica Detalhada:**\n",
    "1. Importa a classe OpenAI da biblioteca openai\n",
    "2. Inicializa o cliente com o token Databricks e o URL do endpoint\n",
    "3. Realiza uma chamada de teste para uma conversa simples com o modelo\n",
    "4. Imprime a resposta do modelo\n",
    "\n",
    "**Parâmetros da Requisição:**\n",
    "- `messages`: Lista contendo duas mensagens (sistema e usuário)\n",
    "- `model`: \"teste-maverick\" (modelo do Databricks)\n",
    "- `max_tokens`: 256 (limite máximo de tokens na resposta)\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- Exibe a resposta textual do modelo, verificando se a conexão e o processamento estão funcionando corretamente\n",
    "- Serve como teste independente para diagnóstico de problemas com a API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8079baa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=DATABRICKS_TOKEN,\n",
    "    base_url=\"https://dbc-d80f50a9-af23.cloud.databricks.com/serving-endpoints\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  messages=[\n",
    "  {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"You are an AI assistant\"\n",
    "  },\n",
    "  {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"Tell me about Large Language Models\"\n",
    "  }\n",
    "  ],\n",
    "  model=\"teste-maverick\",\n",
    "  max_tokens=256\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cff274",
   "metadata": {},
   "source": [
    "### Versão alternativa de teste do cliente OpenAI\n",
    "**Objetivo da Célula:** Demonstrar uma maneira alternativa de obter o token e usar o cliente OpenAI com o endpoint Databricks.\n",
    "\n",
    "**Dependências:**\n",
    "- Acesso ao ambiente Databricks\n",
    "- Biblioteca OpenAI\n",
    "\n",
    "**Lógica Detalhada:**\n",
    "1. Importa as bibliotecas necessárias (OpenAI e os)\n",
    "2. Adiciona um comentário explicando como obter tokens Databricks através do link de documentação\n",
    "3. Obtém o token diretamente do contexto do notebook Databricks\n",
    "4. Inicializa o cliente OpenAI com o token e URL do endpoint\n",
    "5. Cria uma requisição de chat completion com os mesmos parâmetros da célula anterior\n",
    "6. Imprime a resposta do modelo\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- Proporciona um exemplo mais documentado da configuração do cliente OpenAI\n",
    "- Demonstra a possibilidade de obtenção do token através de diferentes métodos\n",
    "- Serve como referência para futuras implementações ou debuggings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4158b605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# How to get your Databricks token: https://docs.databricks.com/en/dev-tools/auth/pat.html\n",
    "#DATABRICKS_TOKEN = os.environ.get('DATABRICKS_TOKEN') or 'your_actual_token_here'\n",
    "# Alternatively in a Databricks notebook you can use this:\n",
    "DATABRICKS_TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=DATABRICKS_TOKEN,\n",
    "  base_url=\"https://dbc-d80f50a9-af23.cloud.databricks.com/serving-endpoints\"\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "  messages=[\n",
    "  {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"You are an AI assistant\"\n",
    "  },\n",
    "  {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"Tell me about Large Language Models\"\n",
    "  }\n",
    "  ],\n",
    "  model=\"teste-maverick\",\n",
    "  max_tokens=256\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
