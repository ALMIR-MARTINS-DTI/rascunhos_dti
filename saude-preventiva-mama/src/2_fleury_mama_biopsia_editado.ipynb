{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bc68612",
   "metadata": {},
   "source": [
    "# Documentação Técnica do Notebook: Extração de Dados de Biopsia de Mama - Fleury\n",
    "\n",
    "## Objetivo Principal\n",
    "**Este notebook realiza a extração, filtragem e persistência dos dados de exames de biópsia de mama do Fleury, com foco na detecção de casos de carcinoma.** O objetivo é identificar laudos que mencionam a topografia \"MAMA\" e, dentro desses, extrair frases associadas ao termo \"carcinoma\" para monitoramento e análise clínica.\n",
    "\n",
    "## Tecnologias Utilizadas\n",
    "- **PySpark**: Manipulação de dados em larga escala, consultas SQL, transformações e persistência em Delta Lake.\n",
    "- **Databricks Feature Store**: Gerenciamento de features e tabelas Delta.\n",
    "- **Octoops**: Monitoramento, alertas e integração com sistemas de controle de execução.\n",
    "- **Delta Lake**: Persistência dos dados processados.\n",
    "- **Python (logging, traceback, etc.)**: Controle de fluxo, tratamento de erros e registro de eventos.\n",
    "\n",
    "## Fluxo de Trabalho/Etapas Principais\n",
    "1. **Instalação de dependências**: Instalação do pacote `octoops` para monitoramento.\n",
    "2. **Configuração do ambiente**: Reinicialização do kernel (Databricks) e importação das bibliotecas necessárias.\n",
    "3. **Definição de filtros e tabelas**: Configuração dos filtros SQL para seleção incremental e extração dos dados relevantes.\n",
    "4. **Consulta SQL principal**: Extração dos laudos que mencionam \"MAMA\" e \"CARCINOMA\", com uso de expressões regulares para identificar frases relevantes.\n",
    "5. **Visualização dos dados extraídos**: Exibição dos resultados para validação.\n",
    "6. **Persistência dos dados**: Salvamento dos dados processados na tabela Delta, com merge/upsert para garantir atualização incremental.\n",
    "7. **Monitoramento e alertas**: Envio de alertas via Sentinel em caso de erros ou ausência de dados.\n",
    "\n",
    "## Dados Envolvidos\n",
    "- **Fonte**: Tabela `refined.saude_preventiva.fleury_laudos`.\n",
    "- **Tabela de destino**: `refined.saude_preventiva.fleury_laudos_mama_biopsia_v2`.\n",
    "- **Colunas importantes**:\n",
    "    - `laudo_tratado`: Texto do laudo médico.\n",
    "    - `RAW_CARCINOMA`: Frase extraída contendo \"carcinoma\" relacionada à \"MAMA\".\n",
    "    - `HAS_CARCINOMA`: Indicador booleano da presença de carcinoma.\n",
    "    - Identificadores: `ficha`, `id_item`, `id_subitem`, `id_cliente`, etc.\n",
    "\n",
    "## Resultados/Saídas Esperadas\n",
    "- DataFrame filtrado com laudos de biópsia de mama e indicação de presença de carcinoma.\n",
    "- Persistência dos dados na tabela Delta para uso em análises clínicas e notificações.\n",
    "- Alertas automáticos em caso de falhas ou ausência de dados.\n",
    "\n",
    "## Pré-requisitos\n",
    "- Ambiente Databricks ou Spark configurado.\n",
    "- Pacotes: `octoops`, `databricks-feature-store`, `delta`.\n",
    "- Acesso às tabelas Delta e permissões de escrita.\n",
    "\n",
    "## Considerações Importantes\n",
    "- O notebook utiliza expressões regulares avançadas para garantir a correta identificação de frases relevantes.\n",
    "- O merge/upsert garante que os dados estejam sempre atualizados sem duplicidade.\n",
    "- O monitoramento via Octoops/Sentinel facilita a rastreabilidade e resposta rápida a falhas.\n",
    "- O filtro de idade e sexo garante que apenas pacientes do público-alvo sejam analisados.\n",
    "\n",
    "---\n",
    "A seguir, cada célula de código é precedida por uma explicação técnica detalhada sobre sua função e impacto no fluxo do notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191a1236",
   "metadata": {},
   "source": [
    "## Instalação do pacote octoops\n",
    "Esta célula instala o pacote `octoops`, utilizado para monitoramento, alertas e integração com sistemas de controle de execução. O comando `%pip install` garante que o pacote esteja disponível no ambiente do notebook. Caso o ambiente já possua o pacote, a instalação será ignorada. O pacote é fundamental para o envio de alertas automáticos em etapas críticas do processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa21a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install databricks-feature-store -q\n",
    "%pip install octoops\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6aa5fd",
   "metadata": {},
   "source": [
    "## Reinicialização do ambiente Python (Databricks)\n",
    "Esta célula reinicia o kernel Python no ambiente Databricks, garantindo que todas as dependências recém-instaladas estejam disponíveis. O comando `dbutils.library.restartPython()` é específico do Databricks e não deve ser executado em ambientes fora dele. A reinicialização é útil após a instalação de novos pacotes para evitar conflitos de versões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe6ec49",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14046314",
   "metadata": {},
   "source": [
    "## Importação de bibliotecas\n",
    "Esta célula importa todas as bibliotecas necessárias para o processamento dos dados:\n",
    "- **PySpark**: Manipulação de DataFrames, funções SQL, tipos de dados e cálculos de datas.\n",
    "- **Octoops**: Classes para monitoramento (`OctoOps`, `Sentinel`, `FeatureStoreManager`).\n",
    "- **Databricks Feature Store**: Gerenciamento de tabelas Delta e features.\n",
    "- **Logging, traceback, sys**: Controle de fluxo, registro de eventos e tratamento de erros.\n",
    "Essas bibliotecas são essenciais para todas as etapas do notebook, desde a extração até a persistência e monitoramento dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e9ed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, year, month, dayofmonth, when, lit, expr, to_timestamp\n",
    "from pyspark.sql.types import DateType\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import datediff, to_date\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import sys\n",
    "import traceback\n",
    "from octoops import OctoOps\n",
    "from octoops import Sentinel\n",
    "from octoops import FeatureStoreManager\n",
    "from databricks.feature_store import FeatureStoreClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1fc650",
   "metadata": {},
   "source": [
    "## Configuração do logger\n",
    "Esta célula configura um logger Python para registrar mensagens de log durante a execução do notebook. O logger é utilizado para registrar informações, avisos e erros, facilitando o monitoramento e a depuração do fluxo. O objeto `logger` é criado com o nome do módulo atual (`__name__`) e será utilizado em funções de transformação e persistência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffe0507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# O código configura um logger para registrar mensagens de log no módulo atual (__name__).\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272ccaaf",
   "metadata": {},
   "source": [
    "## Definição de filtros e tabelas\n",
    "Esta célula define os filtros SQL e os nomes das tabelas Delta utilizadas no processamento:\n",
    "- `table_biopsia`: Nome da tabela Delta de destino para persistência dos dados extraídos.\n",
    "- `where_clause`: Filtro incremental para garantir que apenas novos dados sejam processados, comparando o campo `_datestamp` com o máximo já presente na tabela de destino.\n",
    "- `filtro_extracao`: Filtro para selecionar apenas laudos de biópsia de mama, considerando siglas específicas de exames, sexo feminino e faixa etária de 40 a 75 anos.\n",
    "Esses filtros garantem que apenas dados relevantes e novos sejam processados e persistidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc3e2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtros para a extração\n",
    "table_biopsia = \"refined.saude_preventiva.fleury_laudos_mama_biopsia_v2\" \n",
    "\n",
    "where_clause = f\"\"\"\n",
    "    WHERE\n",
    "        _datestamp > (\n",
    "            SELECT MAX(biop._datestamp)\n",
    "            FROM {table_biopsia} biop\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    " \n",
    "filtro_extracao = \"\"\"\n",
    "    WHERE\n",
    "        linha_cuidado   = 'mama'\n",
    "        AND sigla_exame IN (\n",
    "            \"BIOMAMUSCORE\",\n",
    "            \"BIOMAMUSPAAF\",\n",
    "            \"BIOMAMUS\",\n",
    "            \"MAMOTOMIA\",\n",
    "            \"MAMOTOMUS\",\n",
    "            \"MAMCLIPE\",\n",
    "            \"MAMOTORM\"\n",
    "        )\n",
    "        AND UPPER(sexo_cliente) = 'F'\n",
    "        AND (\n",
    "            idade_cliente >= 40 AND idade_cliente < 76\n",
    "        ) \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c1a7c5",
   "metadata": {},
   "source": [
    "## Consulta SQL principal para extração de carcinoma\n",
    "Esta célula constrói e executa a consulta SQL que extrai os laudos de biópsia de mama e identifica a presença de carcinoma:\n",
    "- Utiliza `REGEXP_EXTRACT` para buscar a ocorrência da palavra \"CARCINOMA\" relacionada à \"MAMA\" no campo `laudo_tratado`.\n",
    "- O padrão regex considera casos em que \"CARCINOMA\" aparece antes ou depois de \"Topografia: MAMA\".\n",
    "- Cria a coluna `RAW_CARCINOMA` com a frase extraída e `HAS_CARCINOMA` como indicador booleano.\n",
    "- Seleciona diversas colunas de identificação e características do laudo.\n",
    "- Aplica os filtros incremental (`where_clause`) e de extração (`filtro_extracao`).\n",
    "O resultado é um DataFrame com laudos filtrados e enriquecidos para análise clínica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6a1f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Utiliza REGEXP_EXTRACT para buscar, no texto do campo 'laudo_tratado', \n",
    "# a ocorrência da palavra \"CARCINOMA\" relacionada à \"MAMA\" (seja antes ou depois de \"Topografia\").\n",
    "# O padrão regex considera maiúsculas/minúsculas e múltiplas linhas.\n",
    "# Se encontrar, extrai \"CARCINOMA\" para a coluna RAW_CARCINOMA; caso contrário, retorna string vazia.\n",
    "# O CASE seguinte verifica se RAW_CARCINOMA está vazia:\n",
    "# - Se estiver vazia, HAS_CARCINOMA recebe FALSE (não há carcinoma relacionado à mama no laudo).\n",
    "# - Se não estiver vazia, HAS_CARCINOMA recebe TRUE (há carcinoma relacionado à mama no laudo).\n",
    "query = f\"\"\"\n",
    "WITH base AS (\n",
    "    SELECT\n",
    "        flr.id_marca,\n",
    "        flr.id_unidade,\n",
    "        flr.id_cliente, \n",
    "        flr.id_ficha,\n",
    "        flr.ficha,\n",
    "        flr.id_item, \n",
    "        flr.id_subitem, \n",
    "        flr.id_exame, \n",
    "        flr.dth_pedido,\n",
    "        flr.dth_resultado,\n",
    "        flr.sigla_exame,\n",
    "        flr.laudo_tratado,\n",
    "        flr.linha_cuidado,\n",
    "        flr.sexo_cliente,\n",
    "        flr.`_datestamp`,\n",
    "        (\n",
    "          TIMESTAMPDIFF(DAY, flr.dth_nascimento_cliente, CURDATE()) / 365.25\n",
    "        ) AS idade_cliente,\n",
    "        REGEXP_EXTRACT(\n",
    "            flr.laudo_tratado,\n",
    "            r'(?mi).*Topografia:.*MAMA.*(CARCINOMA).*|.*(CARCINOMA).*Topografia:.*MAMA.*',\n",
    "            1\n",
    "        ) AS RAW_CARCINOMA,\n",
    "        CASE\n",
    "            WHEN REGEXP_EXTRACT(\n",
    "                    flr.laudo_tratado,\n",
    "                    r'(?mi).*Topografia:.*MAMA.*(CARCINOMA).*|.*(CARCINOMA).*Topografia:.*MAMA.*',\n",
    "                    1\n",
    "                 ) = ''\n",
    "            THEN FALSE\n",
    "            ELSE TRUE\n",
    "        END AS HAS_CARCINOMA\n",
    "    FROM refined.saude_preventiva.fleury_laudos flr\n",
    "    {where_clause}\n",
    ")\n",
    "SELECT *\n",
    "FROM base\n",
    "{filtro_extracao}\n",
    "\"\"\"\n",
    "df_spk_biopsia = spark.sql(query)\n",
    "display(df_spk_biopsia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afdbf42",
   "metadata": {},
   "source": [
    "## Visualização dos dados extraídos\n",
    "Esta célula exibe o DataFrame resultante da consulta SQL anterior utilizando o comando `display`. Permite a inspeção visual dos dados extraídos, incluindo as colunas `RAW_CARCINOMA` e `HAS_CARCINOMA`, além dos identificadores dos laudos. É útil para validação dos resultados antes da persistência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd141616",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_spk_biopsia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e9b3be",
   "metadata": {},
   "source": [
    "## Criação de tabela no Feature Store (comentado)\n",
    "Esta célula contém código comentado para criação de uma tabela no Databricks Feature Store. O código define o nome da tabela, as chaves primárias (`ficha`, `id_item`, `id_subitem`), o schema baseado no DataFrame extraído e uma descrição detalhada. Caso seja necessário criar a tabela, basta descomentar e executar. O Feature Store facilita o gerenciamento de features para modelos de machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6c39db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FeatureStore\n",
    "# fs = FeatureStoreClient()\n",
    "# fs.create_table(\n",
    "#     name=\"refined.saude_preventiva.fleury_laudos_mama_biopsia\",\n",
    "#     primary_keys=[\"ficha\",'id_item','id_subitem'],\n",
    "#     schema=df_spk.schema,    \n",
    "#     description=\"Jornada de Mama - Features extraídas de laudos de biopsia Fleury. Siglas: BIOMAMUSCORE, BIOMAMUSPAAF, BIOMAMUS, MAMOTOMIA, MAMOTOMUS, MAMCLIPE, MAMOTORM\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9ef55c",
   "metadata": {},
   "source": [
    "## Seleção de colunas e persistência dos dados\n",
    "Esta célula realiza várias operações:\n",
    "- Importa módulos para tratamento de erros e integração com Delta Lake.\n",
    "- Define o caminho da tabela Delta de destino (`OUTPUT_DATA_PATH`).\n",
    "- Seleciona as colunas de interesse do DataFrame extraído, incluindo identificadores, datas, sigla do exame, texto do laudo, indicadores de carcinoma, etc.\n",
    "- Define a função `insert_data` para realizar merge/upsert dos dados na tabela Delta, garantindo atualização incremental sem duplicidade.\n",
    "- Executa o salvamento dos dados se houver registros, imprimindo o total salvo. Caso não haja dados, envia alerta via Sentinel.\n",
    "- Em caso de exceção, imprime o traceback e relança o erro.\n",
    "Esta célula é responsável pela persistência final dos dados processados e pelo monitoramento de falhas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2625ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import traceback\n",
    "from octoops import Sentinel\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "WEBHOOK_DS_AI_BUSINESS_STG = 'prd'\n",
    "\n",
    "\n",
    "#OUTPUT_DATA_PATH = dbutils.widgets.get('OUTPUT_DATA_PATH')\n",
    "OUTPUT_DATA_PATH = 'refined.saude_preventiva.fleury_laudos_mama_biopsia_v2'\n",
    "\n",
    "# Selecionar colunas de interesse\n",
    "df_spk = df_spk_biopsia.select(\"ficha\",\"id_item\",\"id_subitem\",\"id_cliente\",\"dth_pedido\",\"dth_resultado\", \"sigla_exame\",\"laudo_tratado\",\"linha_cuidado\",\"_datestamp\",\"RAW_CARCINOMA\",\"HAS_CARCINOMA\").display()\n",
    "\n",
    "# função para salvar dados na tabela\n",
    "def insert_data(df_spk, output_data_path):  \n",
    "\n",
    "    # Carrega a tabela Delta existente\n",
    "    delta_table = DeltaTable.forName(spark, output_data_path)\n",
    "\n",
    "    # Faz o merge (upsert)\n",
    "    (delta_table.alias(\"target\")\n",
    "     .merge(\n",
    "         df_spk.alias(\"source\"),\n",
    "         \"target.ficha = source.ficha AND target.id_item = source.id_item AND target.id_subitem = source.id_subitem\"\n",
    "     )\n",
    "     .whenMatchedUpdateAll()\n",
    "     .whenNotMatchedInsertAll()\n",
    "     .execute())      \n",
    "try:\n",
    "    if df_spk.count() > 0:\n",
    "        \n",
    "        #1/0 \n",
    "        insert_data(df_spk, OUTPUT_DATA_PATH)\n",
    "        # fs.write_table(\n",
    "        #     name=\"refined.saude_preventiva.fleury_laudos_mama_biopsia\",\n",
    "        #     df=df_spk,\n",
    "        #     mode=\"merge\",\n",
    "        # )\n",
    "        print(f'Total de registros salvos na tabela: {df_spk.count()}')\n",
    "            \n",
    "    else:\n",
    "        error_message = traceback.format_exc()\n",
    "        summary_message = f\"\"\"Não há laudos para extração.\\n{error_message}\"\"\"\n",
    "        sentinela_ds_ai_business = Sentinel(\n",
    "            project_name='Monitor_Linhas_Cuidado_Mama',\n",
    "            env_type=WEBHOOK_DS_AI_BUSINESS_STG,\n",
    "            task_title='Fleury Mama Biopsia'\n",
    "        )\n",
    "\n",
    "        sentinela_ds_ai_business.alerta_sentinela(\n",
    "            categoria='Alerta', \n",
    "            mensagem=summary_message,\n",
    "            job_id_descritivo='2_fleury_mama_biopsia'\n",
    "        )\n",
    "except Exception as e:\n",
    "    traceback.print_exc()        \n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
