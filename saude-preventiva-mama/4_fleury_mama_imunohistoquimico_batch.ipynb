{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "808720b8-637f-4134-b87a-b4c95bb85c32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Visão Geral do Notebook: Extração e Classificação de Marcadores Imunohistoquímicos de Mama com LLM\n",
    "\n",
    "Este notebook implementa um pipeline completo para extração automatizada de informações de laudos médicos de câncer de mama, utilizando **Large Language Models (LLMs)** integrados ao ambiente Databricks. O objetivo principal é identificar e classificar marcadores imunohistoquímicos essenciais para a definição de subtipos moleculares do câncer de mama, facilitando análises clínicas e epidemiológicas.\n",
    "\n",
    "---\n",
    "\n",
    "## Principais Bibliotecas e Frameworks Utilizados\n",
    "\n",
    "- **PySpark**: Para processamento distribuído de grandes volumes de dados, manipulação de DataFrames e execução de queries SQL.\n",
    "- **Databricks Foundation Models**: Uso do modelo LLM `databricks-llama-4-maverick` via função `ai_query` para extração de informações textuais.\n",
    "- **Pandas e NumPy**: Manipulação e análise de dados tabulares em memória local.\n",
    "- **OpenAI**: Integração com APIs de modelos de linguagem (quando necessário).\n",
    "- **Regex (re)**: Expressões regulares para extração heurística de marcadores (validação).\n",
    "- **openpyxl**: Exportação e formatação de relatórios em Excel.\n",
    "- **octoops**: Framework para monitoramento e alertas (integração com Sentinel).\n",
    "- **MLflow**: Rastreamento de experimentos e modelos.\n",
    "- **Jinja2**: Geração dinâmica de templates de prompt para o LLM.\n",
    "\n",
    "---\n",
    "\n",
    "## Fluxo de Trabalho/Etapas Principais\n",
    "\n",
    "1. **Configuração do Ambiente**: Instalação de dependências e inicialização do Spark.\n",
    "2. **Extração de Dados**: Query SQL incremental sobre a tabela `refined.saude_preventiva.fleury_laudos`, filtrando apenas laudos de mama, pacientes do sexo feminino e exames relevantes (`IH-NEO`, `IHMAMA`).\n",
    "3. **Processamento via LLM**: Geração de prompts dinâmicos e extração dos marcadores imunohistoquímicos usando o LLM da Databricks.\n",
    "4. **Classificação Molecular**: Aplicação de regras clínicas para classificar os casos em subtipos como Luminal A, Luminal B, HER-2 Superexpresso, Triplo Negativo, etc.\n",
    "5. **Validação Heurística**: Implementação de funções regex para extração heurística dos mesmos marcadores, permitindo comparação e cálculo de métricas de acurácia.\n",
    "6. **Exportação e Auditoria**: Geração de relatórios Excel com formatação condicional e persistência dos resultados em tabela Delta Lake.\n",
    "\n",
    "---\n",
    "\n",
    "## Dados Envolvidos\n",
    "\n",
    "- **Tabela de Origem**: `refined.saude_preventiva.fleury_laudos`\n",
    "- **Tabela de Destino**: `refined.saude_preventiva.fleury_laudos_mama_imunohistoquimico`\n",
    "- **Colunas Importantes**:\n",
    "  - `laudo_tratado`: Texto do laudo médico (input para o LLM)\n",
    "  - `sigla_exame`, `linha_cuidado`, `sexo_cliente`: Filtros de seleção\n",
    "  - `id_ficha`, `id_item`, `id_subitem`: Chaves para merge/upsert\n",
    "  - `_datestamp`: Controle de incrementalidade\n",
    "\n",
    "---\n",
    "\n",
    "## Funções e Componentes de Destaque\n",
    "\n",
    "- **prompt_laudo_template()**: Gera o template de prompt para o LLM, detalhando os critérios de extração dos marcadores.\n",
    "- **Funções de Extração Heurística**: `extrai_receptor_estrogeno`, `extrai_receptor_progesterona`, `extrai_status_her2`, `extrai_ki67_percentual`, `extrai_status_ck5_6`.\n",
    "- **avalia_extracao_sem_ground_truth_imuno**: Compara a extração do LLM com a heurística, campo a campo.\n",
    "- **agrega_resultados_dinamico**: Consolida métricas de acurácia por campo.\n",
    "- **configura_excel**: Gera planilha Excel com formatação condicional para auditoria dos resultados.\n",
    "\n",
    "---\n",
    "\n",
    "## Resultados/Saídas Esperadas\n",
    "\n",
    "- **DataFrame Estruturado**: Com marcadores extraídos e classificação molecular.\n",
    "- **Planilha Excel**: Relatório de validação com destaques visuais para erros.\n",
    "- **Tabela Delta Atualizada**: Persistência dos resultados processados para uso futuro e integração com outros sistemas.\n",
    "\n",
    "---\n",
    "\n",
    "## Pré-requisitos\n",
    "\n",
    "- Ambiente Databricks com acesso ao Spark e Foundation Models.\n",
    "- Permissões de leitura/escrita nas tabelas de origem e destino.\n",
    "- Instalação dos pacotes Python necessários (`octoops`, `openpyxl`, `jinja2`, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "## Considerações Importantes\n",
    "\n",
    "- **Incrementalidade**: O pipeline processa apenas registros novos, evitando retrabalho.\n",
    "- **Validação Dupla**: Combinação de LLM e heurística aumenta a confiabilidade dos resultados.\n",
    "- **Custo Computacional**: O uso de LLMs pode ser custoso; recomenda-se limitar o volume de dados em testes.\n",
    "- **Flexibilidade**: O pipeline pode ser adaptado para outros tipos de laudos ou marcadores, bastando ajustar o template de prompt e as funções heurísticas.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42df8bbf-dd86-4dbf-ba28-d95d2a8fbca2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Extração de dado - Imunohistoquimico\n",
    "**Extrair os seguintes labels estruturados:**\n",
    "- Receptor de Estrógeno (categórica): POSITIVO ou NEGATIVO \n",
    "  - \"RECEPTOR DE ESTRÓGENO - POSITIVO \" \n",
    "  - \"RECEPTOR DE ESTRÓGENO – NEGATIVO\" \n",
    "\n",
    "- Receptor de Progesterona (categórica): POSITIVO ou NEGATIVO \n",
    "  - \"RECEPTOR DE PROGESTERONA - POSITIVO\" \n",
    "  - \"RECEPTOR DE PROGESTERONA - NEGATIVO\" \n",
    "\n",
    "- Status do HER-2 (categórica): Negativo, inconclusivo ou positivo \n",
    "  - \"HER-2 - ESCORE 0\" = Negativo \n",
    "  - \"HER-2 - ESCORE 1+\" = Negativo \n",
    "  - \"HER-2  -  ESCORE  2+\" = Inconclusivo \n",
    "  - \"HER-2  -  ESCORE  3+\" = Positivo \n",
    "\n",
    "- Porcentagem do Ki-67 (numérica):  \"KI-67 - POSITIVO EM 20% DAS CÉLULAS NEOPLÁSICAS\"\n",
    "  - Deve ser extraído esse número da porcentagem nessa frase \n",
    "\n",
    "- Status CK5/6 (categórica): POSITIVO ou NEGATIVO \n",
    "  - \"CK5/6 - POSITIVO \"ou \"CK5/6 - NEGATIVO\" \n",
    "  \n",
    "+ Para laudos que não possuem carcinoma, ou seja, casos negativos para câncer não devem se processados no LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67e45f93-3128-4ac5-b41e-c830bd751be4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Instalação de Dependências\n",
    "\n",
    "Esta célula instala o pacote `octoops`, que é utilizado para monitoramento e alertas no ambiente Databricks. As outras dependências necessárias (como openai, tqdm, pandas e databricks-feature-store) estão comentadas pois provavelmente já estão instaladas no ambiente ou serão instaladas por outro processo.\n",
    "\n",
    "O pacote Octoops permite configurar alertas e notificações em caso de falhas no pipeline, sendo uma peça importante na infraestrutura de monitoramento do processo de extração de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9b29ecb-a8a8-4fe0-b616-1ce4f3f28e10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %pip install openai -q\n",
    "# %pip install tqdm -q\n",
    "# %pip install pandarallel -q\n",
    "# %pip install databricks-feature-store -q\n",
    "# %pip install ace_tools -q\n",
    "%pip install octoops openpyxl jinja2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b25aa4b8-1ecd-456f-92fc-fef1e743f071",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Reinicialização do Python\n",
    "\n",
    "Após a instalação de novas dependências, é necessário reiniciar o interpretador Python para garantir que as bibliotecas recém-instaladas estejam disponíveis no ambiente de execução. O comando `dbutils.library.restartPython()` realiza essa reinicialização, garantindo que todas as dependências estejam carregadas corretamente antes de prosseguir com a execução do notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1eab456a-4772-49ce-aefc-eb2e341b4cff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73aebd59-604c-4ebc-ad1e-ffd784ec13f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Importação de Bibliotecas e Configuração Inicial\n",
    "\n",
    "Esta célula realiza a importação de todas as bibliotecas necessárias para o processamento dos laudos e inicializa o ambiente Spark.\n",
    "\n",
    "**Objetivos principais:**\n",
    "1. Importar bibliotecas para manipulação de dados (PySpark, pandas, numpy)\n",
    "2. Importar bibliotecas para processamento de texto e regex\n",
    "3. Importar ferramentas para logging e monitoramento (mlflow)\n",
    "4. Importar bibliotecas para integração com APIs externas (openai)\n",
    "5. Inicializar a sessão Spark\n",
    "6. Obter o token de autenticação Databricks\n",
    "\n",
    "**Bibliotecas principais:**\n",
    "- **PySpark**: Framework para processamento distribuído de dados\n",
    "- **pandas/numpy**: Ferramentas para manipulação e análise de dados\n",
    "- **openai**: Cliente para comunicação com APIs de modelos de linguagem\n",
    "- **mlflow**: Plataforma para gerenciamento do ciclo de vida de modelos de ML\n",
    "- **tqdm**: Biblioteca para barras de progresso\n",
    "- **re**: Biblioteca para processamento de expressões regulares\n",
    "\n",
    "A sessão Spark é configurada com o nome \"LLM_Extractor\", e o token Databricks é obtido do contexto do notebook para autenticação com serviços externos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35781952-2bfe-4067-8a5e-d38f1b2d12c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import ast\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import mlflow\n",
    "import time\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Any\n",
    "import openai\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "from databricks.feature_store import FeatureStoreClient\n",
    "from pyspark.sql import Row\n",
    "\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"LLM_Extractor\").getOrCreate()\n",
    "\n",
    "DATABRICKS_TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get() if dbutils.notebook.entry_point.getDbutils().notebook().getContext() is not None else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b89b212c-165f-4fb9-8111-3515b0c855cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Desativação de Exibição MLflow no Notebook\n",
    "\n",
    "Esta célula desativa a exibição automática de informações do MLflow no notebook, configurando o comportamento do MLflow para evitar que ele adicione visualizações e saídas extras durante o rastreamento de experimentos. Isto é particularmente útil em notebooks de produção onde queremos controlar precisamente o que é exibido, sem poluição visual extra criada pelo rastreamento automático do MLflow.\n",
    "\n",
    "O comando `mlflow.tracing.disable_notebook_display()` evita que artefatos, métricas e parâmetros sejam automaticamente exibidos no notebook quando são registrados, mantendo a saída limpa e focada apenas no que está sendo explicitamente exibido pelo código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ce4f6a7-3a7f-431c-8b5d-591fea3b011b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# mlflow.tracing.disable_notebook_display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b940f0cd-a3af-4183-af76-53a0ade158e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Configuração dos Parâmetros de Consulta\n",
    "\n",
    "Esta célula define os parâmetros de consulta para extrair laudos de imunohistoquímica específicos para câncer de mama. São configurados:\n",
    "\n",
    "1. **Tabela de Destino** (`table_imuno`): Define o nome da tabela Delta onde os resultados serão armazenados.\n",
    "\n",
    "2. **Cláusula WHERE para Incremento** (`where_clause`): Implementa uma estratégia de carga incremental, buscando apenas registros com timestamp mais recente que o último carregamento na tabela de destino.\n",
    "\n",
    "3. **Filtros de Extração** (`filtro_extracao`): Define critérios específicos para selecionar apenas laudos relevantes:\n",
    "   - Linha de cuidado específica para mama\n",
    "   - Pacientes do sexo feminino\n",
    "   - Siglas de exame específicas de imunohistoquímica (IH-NEO, IHMAMA)\n",
    "   - Presença dos termos \"mama\" e \"carcinoma\" nos laudos\n",
    "\n",
    "Esses filtros garantem que apenas os laudos de imunohistoquímica relevantes para câncer de mama feminino sejam processados, otimizando o uso de recursos computacionais e do modelo de linguagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2de59eb9-5017-4604-acfd-fb4848bf18a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "table_imuno = \"refined.saude_preventiva.fleury_laudos_mama_imunohistoquimico\" \n",
    "\n",
    "where_clause = f\"\"\"\n",
    "WHERE\n",
    "    flr.`_datestamp` >= (\n",
    "        SELECT MAX(imuno._datestamp)\n",
    "        FROM {table_imuno} imuno\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    " \n",
    "filtro_extracao = \"\"\"\n",
    "    WHERE\n",
    "        linha_cuidado  = 'mama'\n",
    "        AND UPPER(sexo_cliente) = 'F'\n",
    "        AND sigla_exame IN (\"IH-NEO\", \"IHMAMA\")\n",
    "        AND laudo_tratado RLIKE '(?i)mama' AND laudo_tratado RLIKE '(?i)carcinoma'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bd5342d-0d42-447b-ab7d-e0c4305dd275",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Execução da Consulta SQL e Carregamento dos Dados\n",
    "\n",
    "Esta célula constrói e executa uma consulta SQL para extrair laudos de exames imunohistoquímicos relevantes para análise. \n",
    "\n",
    "**Processo detalhado:**\n",
    "\n",
    "1. **Construção da Consulta**: A consulta SQL é construída usando um Common Table Expression (CTE) chamado `base` que:\n",
    "   - Seleciona colunas relevantes da tabela principal de laudos (`refined.saude_preventiva.fleury_laudos`)\n",
    "   - Aplica o filtro incremental definido em `where_clause` para obter apenas registros novos\n",
    "   - Usa a cláusula `filtro_extracao` para filtrar apenas laudos de mama com carcinoma\n",
    "\n",
    "2. **Seleção de Campos**: A consulta extrai informações essenciais como:\n",
    "   - Identificadores (id_marca, id_unidade, id_cliente, id_ficha, etc.)\n",
    "   - Datas (dth_pedido, dth_resultado)\n",
    "   - Tipo de exame (sigla_exame)\n",
    "   - Conteúdo do laudo (laudo_tratado)\n",
    "   - Informações da linha de cuidado e sexo do cliente\n",
    "\n",
    "3. **Execução da Consulta**: A consulta é executada através do Spark SQL, criando um DataFrame `df_spk`\n",
    "\n",
    "4. **Visualização**: O DataFrame resultante é exibido na interface para verificação inicial dos dados carregados\n",
    "\n",
    "Esta etapa é fundamental para preparar o conjunto de dados que será processado pelo modelo de linguagem nas etapas subsequentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4ba455f-7a82-4b0c-a565-2407710f66cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "WITH base AS (\n",
    "    SELECT\n",
    "        flr.id_marca,\n",
    "        flr.id_unidade,\n",
    "        flr.id_cliente, \n",
    "        flr.id_ficha,\n",
    "        flr.ficha,\n",
    "        flr.id_item, \n",
    "        flr.id_subitem, \n",
    "        flr.id_exame, \n",
    "        flr.dth_pedido,\n",
    "        flr.dth_resultado,\n",
    "        flr.sigla_exame,\n",
    "        flr.laudo_tratado,\n",
    "        flr.linha_cuidado,\n",
    "        flr.sexo_cliente,\n",
    "        flr.`_datestamp`\n",
    "    FROM refined.saude_preventiva.fleury_laudos flr    \n",
    "    {where_clause}\n",
    ")\n",
    "SELECT * FROM base\n",
    "{filtro_extracao}\n",
    "\"\"\"\n",
    "df_spk = spark.sql(query)\n",
    "display(df_spk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1073e130-ac8d-4777-b567-1b1a7613e052",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Verificação de Sexo e Tipos de Exame\n",
    "\n",
    "Esta célula executa uma verificação básica dos dados carregados, exibindo os valores distintos para duas colunas críticas: `sexo_cliente` e `sigla_exame`. \n",
    "\n",
    "O objetivo desta verificação é:\n",
    "1. Confirmar que apenas pacientes do sexo feminino (F) foram incluídos no dataset, conforme especificado no filtro\n",
    "2. Verificar quais siglas de exames de imunohistoquímica estão presentes nos dados carregados\n",
    "3. Validar que os filtros da consulta SQL foram aplicados corretamente\n",
    "\n",
    "Esta etapa de validação rápida ajuda a garantir a qualidade dos dados antes de prosseguir com análises mais detalhadas e o processamento pelo modelo de linguagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65f39712-1f8a-4a4c-b256-f86b16f330c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_spk.select(\"sexo_cliente\", \"sigla_exame\").distinct())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95c3b68b-a6fe-4f25-8a29-2b46a67a1e9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Contagem de Registros\n",
    "\n",
    "Esta célula simples realiza a contagem do número total de registros no DataFrame `df_spk` carregado pela consulta SQL. O comentário \"# 3635\" indica que, em uma execução anterior, foram encontrados 3.635 registros.\n",
    "\n",
    "Conhecer o volume de dados é importante para:\n",
    "1. Estimar o tempo total de processamento pelo modelo de linguagem\n",
    "2. Verificar se o volume está de acordo com o esperado\n",
    "3. Avaliar a necessidade de processamento em lotes ou amostragem para testes\n",
    "\n",
    "Esta contagem serve como referência para monitoramento do pipeline em execuções futuras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c2dfde8-84a9-48de-83fe-b0e5979670df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_spk.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1885932b-ae16-4878-8bcb-89205f229fc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def prompt_laudo_template() -> str:\n",
    "    # REMOVER O 'f' ANTES DAS ASPAS TRIPLAS\n",
    "    # ESCAPAR O '%' LITERAL COM '%%'\n",
    "    prompt = \"\"\"A seguir está um laudo médico de mamografia, conforme indicado abaixo. Se alguma informação não estiver presente no texto, retorne \"NÃO INFORMADO\". Sempre retorne apenas o dicionário Python.\n",
    "\n",
    "    Laudo clínico:\n",
    "    \\\"\\\"\\\"{laudo_texto}\\\"\\\"\\\"\n",
    "\n",
    "    ### Critérios de extração:\n",
    "\n",
    "    - **Receptor de Estrogênio**: retorne se é \"POSITIVO\", \"NEGATIVO\" ou \"NÃO INFORMADO\".\n",
    "\n",
    "    - **Receptor de Progesterona**: retorne se é \"POSITIVO\", \"NEGATIVO\" ou \"NÃO INFORMADO\".\n",
    "\n",
    "    - **Status do HER-2**: retorne se o Status do HER-2 é \"NEGATIVO\", \"INCONCLUSIVO\", \"POSITIVO\" ou \"NÃO INFORMADO\". Com base no score seguindo as regras:\n",
    "    - \"HER-2 - ESCORE 0\" ou \"1+\" → \"NEGATIVO\"\n",
    "    - \"HER-2 - ESCORE 2+\" → \"INCONCLUSIVO\"\n",
    "    - \"HER-2 - ESCORE 3+\" → \"POSITIVO\"\n",
    "\n",
    "    - **Ki-67 (%%)**: retorne o valor numérico da porcentagem de positividade do KI-67 entre aspas, como uma **string**, caso seja um intervalo de valores retorne o valor máximo.\n",
    "\n",
    "    - **Status do CK5/6**: retorne \"POSITIVO\", \"NEGATIVO\" ou \"NÃO INFORMADO\" do Status do CK5/6.\n",
    "\n",
    "    ### Saída esperada (dicionário Python válido):\n",
    "    ```python\n",
    "    {\n",
    "    \"receptor_estrogeno\": \"POSITIVO\" | \"NEGATIVO\" |  \"NÃO INFORMADO\",\n",
    "    \"receptor_progesterona\": \"POSITIVO\" | \"NEGATIVO\" |  \"NÃO INFORMADO\",\n",
    "    \"status_her2\": \"POSITIVO\" | \"POSITIVO\" | \"INCONCLUSIVO\" |  \"NÃO INFORMADO\",\n",
    "    \"ki67_percentual\": float |  0,\n",
    "    \"status_ck5_6\": \"POSITIVO\" | \"NEGATIVO\" |  \"NÃO INFORMADO\"\n",
    "    }\n",
    "    \"\"\" \n",
    "    return prompt.strip()\n",
    "    \n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, StringType # Importações necessárias\n",
    "\n",
    "# --- Schema para o JSON de saída do LLM (usado por from_json) ---\n",
    "# Este schema define a estrutura esperada do JSON retornado pelo LLM\n",
    "llm_output_schema = StructType([\n",
    "StructField(\"receptor_estrogeno\", StringType(), True),\n",
    "StructField(\"receptor_progesterona\", StringType(), True),\n",
    "StructField(\"status_her2\", StringType(), True),\n",
    "StructField(\"ki67_percentual\", StringType(), True), # Manter como StringType para lidar com \"NÃO INFORMADO\" ou intervalos\n",
    "StructField(\"status_ck5_6\", StringType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9dd022d-6142-43c9-9f1e-0707bf49d872",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Funções de Extração Heurística (Pseudo-Gold)\n",
    "\n",
    "Esta célula define um conjunto de funções para extração heurística de informações dos laudos médicos, utilizando expressões regulares. Estas extrações servem como um \"pseudo-gold standard\" para avaliar o desempenho do LLM.\n",
    "\n",
    "### Funções de Extração Individual\n",
    "\n",
    "1. **`extrai_receptor_estrogeno`**: Identifica o status do receptor de estrogênio\n",
    "   - Reconhece padrões como \"receptor de estrogênio: positivo\"\n",
    "   - Identifica abreviações como \"ER+\" e \"ER-\"\n",
    "\n",
    "2. **`extrai_receptor_progesterona`**: Identifica o status do receptor de progesterona\n",
    "   - Reconhece padrões como \"receptor de progesterona: positivo\" \n",
    "   - Identifica abreviações como \"PR+\" e \"PR-\"\n",
    "\n",
    "3. **`extrai_status_her2`**: Determina o status do HER-2 baseado em escores\n",
    "   - Processa padrões como \"HER-2 ESCORE X+\"\n",
    "   - Mapeia escores 0/1+ como \"NEGATIVO\", 2+ como \"INCONCLUSIVO\", 3+ como \"POSITIVO\"\n",
    "\n",
    "4. **`extrai_ki67_percentual`**: Extrai o valor percentual do Ki-67\n",
    "   - Processa padrões como \"Ki-67: 20%\"\n",
    "   - Caso o resultado seja uma faixa de valores, extrai o valor máximo da faixa\n",
    "\n",
    "5. **`extrai_status_ck5_6`**: Identifica o status do CK5/6\n",
    "   - Reconhece padrões como \"CK5/6 - POSITIVO\"\n",
    "   - Identifica abreviações como \"CK5/6+\" e \"CK5/6-\"\n",
    "\n",
    "### Função de Avaliação\n",
    "\n",
    "**`avalia_extracao_sem_ground_truth_imuno`**: Função chave que compara extrações do LLM com extrações heurísticas\n",
    "   - Gera extrações heurísticas para todos os campos\n",
    "   - Compara campo a campo os resultados do modelo vs. heurísticas\n",
    "   - Produz métricas de avaliação por campo (acertou/não acertou)\n",
    "\n",
    "Este sistema de avaliação permite medir a qualidade das extrações do LLM sem necessidade de anotação manual de dados, sendo uma ferramenta crucial para validação contínua do pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91df42b4-3cbb-48fe-a688-c1082e6e49af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# Funções de extração heurística (pseudo-gold) para o novo prompt\n",
    "# =================================================================\n",
    "\n",
    "def extrai_receptor_estrogeno(txt: str) -> str:\n",
    "    \"\"\"\n",
    "    Extrai o status de Receptor de Estrogênio: valores possíveis\n",
    "    \"POSITIVO\", \"NEGATIVO\" ou retorna \"NÃO INFORMADO\".\n",
    "    \"\"\"\n",
    "\n",
    "    # Padrões comuns: \"receptor de estrogênio: positivo\" ou \"er+: positivo\" etc.\n",
    "    # Adicionado flags=re.IGNORECASE para ignorar maiúsculas/minúsculas em toda a string\n",
    "    # Ajustado [eê]genio para [eê]g[eê]nio|ogeno para cobrir todas as variações de \"estrogênio\" e \"estrogeno\"\n",
    "    # estr[oó]g[eê]\\w+\n",
    "    if re.search(r\"receptor\\s+de\\s+estr[oó]g(?:[eê]nio|eno)\\s*[:\\-]?\\s*positivo\", txt, flags=re.IGNORECASE):\n",
    "        return \"POSITIVO\"\n",
    "    if re.search(r\"receptor\\s+de\\s+estr[oó]g(?:[eê]nio|eno)\\s*[:\\-]?\\s*negativo\", txt, flags=re.IGNORECASE):\n",
    "        return \"NEGATIVO\"\n",
    "\n",
    "    # Abreviações: \"ER+\" / \"ER-\" (estes já usavam re.IGNORECASE, então não precisam de alteração)\n",
    "    if re.search(r\"\\ber\\s*[\\+]\\b\", txt, flags=re.IGNORECASE):\n",
    "        return \"POSITIVO\"\n",
    "    if re.search(r\"\\ber\\s*[\\-]\\b\", txt, flags=re.IGNORECASE):\n",
    "        return \"NEGATIVO\"\n",
    "\n",
    "    return \"NÃO INFORMADO\"\n",
    "\n",
    "def extrai_receptor_progesterona(txt: str) -> str:\n",
    "    \"\"\"\n",
    "    Extrai o status de Receptor de Progesterona: valores possíveis\n",
    "    \"POSITIVO\", \"NEGATIVO\" ou retorna \"NÃO INFORMADO\".\n",
    "    Ajustado para capturar padrões como \"RECEPTOR DE PROGESTERONA - ESCORE 1+ (NEGATIVO)\".\n",
    "    \"\"\"\n",
    "    txt_lower = txt.lower()\n",
    "\n",
    "    # Define um limite de caracteres para a busca do status após \"receptor de progesterona\".\n",
    "    # Este valor deve ser ajustado com base na variabilidade dos seus relatórios.\n",
    "    # Deve ser suficiente para cobrir um resultado direto (ex: \"RP - ESCORE 1+ (NEGATIVO)\")\n",
    "    # e pequeno o suficiente para não pular para seções de referência distantes.\n",
    "    max_chars_between_rp_and_status = 45 # Um valor como 50-100 caracteres é um bom ponto de partida.\n",
    "\n",
    "    # Padrão para \"receptor de progesterona ... positivo\"\n",
    "    # O `.{0,X}?` permite texto intermediário de forma não-gananciosa.\n",
    "    if re.search(\n",
    "        r\"receptor\\s+de\\s+progesterona[*]?(.{0,\" + str(max_chars_between_rp_and_status) + r\"}?)positivo\\b\",\n",
    "        txt_lower\n",
    "    ):\n",
    "        return \"POSITIVO\"\n",
    "\n",
    "    # Padrão para \"receptor de progesterona ... negativo\"\n",
    "    # O `.{0,X}?` permite texto intermediário de forma não-gananciosa.\n",
    "    if re.search(\n",
    "        r\"receptor\\s+de\\s+progesterona[*]?(.{0,\" + str(max_chars_between_rp_and_status) + r\"}?)negativo\\b\",\n",
    "        txt_lower\n",
    "    ):\n",
    "        return \"NEGATIVO\"\n",
    "\n",
    "    # Abreviações: \"PR+\" / \"PR-\"\n",
    "    # Estes são mais específicos e não precisam da limitação de distância tão complexa.\n",
    "    # Mantemos a busca no 'txt' original com IGNORECASE para estas abreviações.\n",
    "    if re.search(r\"\\bpr\\s*[\\+]\\b\", txt, flags=re.IGNORECASE):\n",
    "        return \"POSITIVO\"\n",
    "    if re.search(r\"\\bpr\\s*[\\-]\\b\", txt, flags=re.IGNORECASE):\n",
    "        return \"NEGATIVO\"\n",
    "\n",
    "    return \"NÃO INFORMADO\"\n",
    "    \n",
    "\n",
    "    # Abreviações: \"PR+\" / \"PR-\"\n",
    "    # Estes são mais específicos e não precisam da limitação de distância tão complexa.\n",
    "    # Mantemos a busca no 'txt' original com IGNORECASE para estas abreviações.\n",
    "    if re.search(r\"\\bpr\\s*[\\+]\\b\", txt, flags=re.IGNORECASE):\n",
    "        return \"POSITIVO\"\n",
    "    if re.search(r\"\\bpr\\s*[\\-]\\b\", txt, flags=re.IGNORECASE):\n",
    "        return \"NEGATIVO\"\n",
    "\n",
    "    return \"NÃO INFORMADO\"\n",
    "\n",
    "def extrai_status_her2(txt: str) -> str:\n",
    "    \"\"\"\n",
    "    Extrai o Status do HER-2 baseado em termos de score:\n",
    "    - \"HER-2 - ESCORE 0\" ou \"1+\" → \"NEGATIVO\"\n",
    "    - \"HER-2 - ESCORE 2+\" → \"INCONCLUSIVO\"\n",
    "    - \"HER-2 - ESCORE 3+\" → \"POSITIVO\"\n",
    "    - Novos formatos: \"HER-2 - POSITIVO\", \"HER-2 - NEGATIVO\"\n",
    "    \"\"\"\n",
    "    txt_lower = txt.lower()\n",
    "\n",
    "    # Padrão para \"HER-2 - POSITIVO\"\n",
    "    if re.search(r\"her[-\\s]?2\\s*[:\\-]?\\s*positivo\\b\", txt_lower, flags=re.IGNORECASE):\n",
    "        return \"POSITIVO\"\n",
    "\n",
    "    # Padrão para \"HER-2 - NEGATIVO\"\n",
    "    if re.search(r\"her[-\\s]?2\\s*[:\\-]?\\s*negativo\\b\", txt_lower, flags=re.IGNORECASE):\n",
    "        return \"NEGATIVO\"\n",
    "\n",
    "    # Primeiro, busca padrão \"her-2 ... escore X+\"\n",
    "    m = re.search(r\"her[-\\s]?2.*?s?core\\s*[:\\-]?\\s*([0-3]\\+?)\", txt_lower, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        score = m.group(1)\n",
    "        if score.startswith(\"0\") or score == \"1+\":\n",
    "            return \"NEGATIVO\"\n",
    "        if score == \"2+\":\n",
    "            return \"INCONCLUSIVO\"\n",
    "        if score == \"3+\":\n",
    "            return \"POSITIVO\"\n",
    "\n",
    "    # Outra forma: \"her2 3+\" isolado\n",
    "    m2 = re.search(r\"\\bher[-]?2\\s*[:\\-]?\\s*([0-3]\\+)\\b\", txt_lower, flags=re.IGNORECASE)\n",
    "    if m2:\n",
    "        score2 = m2.group(1)\n",
    "        if score2 == \"1+\":\n",
    "            return \"NEGATIVO\"\n",
    "        if score2 == \"2+\":\n",
    "            return \"INCONCLUSIVO\"\n",
    "        if score2 == \"3+\":\n",
    "            return \"POSITIVO\"\n",
    "\n",
    "    return \"NÃO INFORMADO\"\n",
    "\n",
    "def extrai_ki67_percentual(txt: str) -> float:\n",
    "    \"\"\"\n",
    "    Extrai o valor de Ki-67 em porcentagem.\n",
    "    Exemplo no texto: \"Ki-67: 20%\", \"Ki 67 15 %\", etc.\n",
    "    Se não encontrar, retorna 0.0.\n",
    "    Ajustado para evitar a captura de percentuais de outras seções (e.g., valores de referência).\n",
    "    \"\"\"\n",
    "    txt_lower = txt.lower()\n",
    "\n",
    "    # Define um limite de caracteres para a busca do percentual após \"KI67\".\n",
    "    # Este valor deve ser ajustado com base na variabilidade dos seus relatórios.\n",
    "    # Deve ser suficiente para cobrir um resultado direto (ex: \"KI67 - POSITIVO EM 10% DAS CÉLULAS\")\n",
    "    # e pequeno o suficiente para não pular para seções de referência distantes.\n",
    "    # Um valor como 50-100 caracteres deve ser razoável para a maioria dos casos.\n",
    "    max_chars_between_ki67_and_percent = 100 # Ajuste conforme a necessidade real dos seus dados\n",
    "\n",
    "    # O padrão busca \"ki67\", então *qualquer coisa* (não-ganancioso)\n",
    "    # até o limite de 'max_chars_between_ki67_and_percent', e então o percentual.\n",
    "    m = re.search(\n",
    "        r\"ki[-\\s]?67.{0,\" + str(max_chars_between_ki67_and_percent) + r\"}?[:\\-]?\\s*(\\d{1,3}(?:[.,]\\d+)?)\\s*%\",\n",
    "        txt_lower,\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "    if m:\n",
    "        try:\n",
    "            # Substitui vírgula por ponto para garantir a conversão correta para float\n",
    "            percent_str = m.group(1).replace(',', '.')\n",
    "            return float(percent_str)\n",
    "        except ValueError:\n",
    "            # Em caso de erro na conversão (improvável com o regex atual, mas boa prática)\n",
    "            return 0.0\n",
    "    return 0.0\n",
    "\n",
    "def extrai_status_ck5_6(txt: str) -> str:\n",
    "    \"\"\"\n",
    "    Extrai o status do CK5/6: \"POSITIVO\", \"NEGATIVO\" ou retorna \"NÃO INFORMADO\".\n",
    "    Esta versão mantém a verificação de distância e resolve o problema de ambiguidade.\n",
    "    \"\"\"\n",
    "    txt_lower = txt.lower()\n",
    "\n",
    "    # 1. Verificar abreviações (CK5/6+ ou CK5/6-) - Estes são os mais específicos e diretos.\n",
    "    # Mantemos a busca no 'txt' original com IGNORECASE para estas abreviações.\n",
    "    if re.search(r\"\\bck5\\s*\\/\\s*6\\s*[\\+]\\b\", txt, flags=re.IGNORECASE):\n",
    "        return \"POSITIVO\"\n",
    "    if re.search(r\"\\bck5\\s*\\/\\s*6\\s*[\\-]\\b\", txt, flags=re.IGNORECASE):\n",
    "        return \"NEGATIVO\"\n",
    "\n",
    "    # 2. Procurar por \"CK5/6\" e o status mais próximo a ele.\n",
    "    # max_chars_after_ck5_6 é a sua verificação de distância!\n",
    "    # Ela define o quão longe o regex pode \"olhar\" após encontrar \"CK5/6\".\n",
    "    max_chars_after_ck5_6 = 70 # Ajuste este valor conforme a variabilidade dos seus relatórios\n",
    "\n",
    "    # O padrão busca \"ck5/6\", então *qualquer coisa* (não-ganancioso)\n",
    "    # até o limite de 'max_chars_after_ck5_6', e então o *primeiro* \"negativo\" ou \"positivo\".\n",
    "    match = re.search(\n",
    "        r\"ck5\\s*\\/\\s*6.{0,\" + str(max_chars_after_ck5_6) + r\"}?(\\bnegativo\\b|\\bpositivo\\b)\",\n",
    "        txt_lower\n",
    "    )\n",
    "\n",
    "    if match:\n",
    "        status_found = match.group(1) # Captura o que foi matched no primeiro grupo (negativo ou positivo)\n",
    "        if status_found == \"positivo\":\n",
    "            return \"POSITIVO\"\n",
    "        elif status_found == \"negativo\":\n",
    "            return \"NEGATIVO\"\n",
    "\n",
    "    # Se nenhuma das condições acima foi atendida\n",
    "    return \"NÃO INFORMADO\"\n",
    "\n",
    "# ==========================================================================\n",
    "# Função de avaliação sem ground truth completo (novo conjunto de campos)\n",
    "# ==========================================================================\n",
    "\n",
    "def avalia_extracao_sem_ground_truth_imuno(laudo_texto: str, json_modelo: dict):\n",
    "    \"\"\"\n",
    "    Gera pseudo-gold (json_heu) para os campos do novo prompt\n",
    "    e compara com json_modelo (saída da IA).\n",
    "    Retorna:\n",
    "      - json_heu: dicionário com valores heurísticos\n",
    "      - comparacoes: dicionário que, para cada campo, traz:\n",
    "          * valor_heu\n",
    "          * valor_mod\n",
    "          * acertou (boolean)\n",
    "    \"\"\"\n",
    "    # 1. Gera pseudo-gold (json_heu)\n",
    "    rei = extrai_receptor_estrogeno(laudo_texto)\n",
    "    rpr = extrai_receptor_progesterona(laudo_texto)\n",
    "    her = extrai_status_her2(laudo_texto)\n",
    "    ki6 = extrai_ki67_percentual(laudo_texto)\n",
    "    ck6 = extrai_status_ck5_6(laudo_texto)\n",
    "\n",
    "    json_heu = {\n",
    "        \"receptor_estrogeno\": rei,\n",
    "        \"receptor_progesterona\": rpr,\n",
    "        \"status_her2\": her,\n",
    "        \"ki67_percentual\": ki6,\n",
    "        \"status_ck5_6\": ck6\n",
    "    }\n",
    "\n",
    "    # 2. Prepara json_modelo: se não for dict, converte para dict vazio\n",
    "    if not isinstance(json_modelo, dict):\n",
    "        json_modelo = {}\n",
    "\n",
    "    # 3. Comparações campo a campo\n",
    "    comparacoes = {}\n",
    "\n",
    "    # Campos categóricos (strings)\n",
    "    for campo in [\"receptor_estrogeno\", \"receptor_progesterona\", \"status_her2\", \"status_ck5_6\"]:\n",
    "        val_heu = json_heu[campo]\n",
    "        val_mod = json_modelo.get(campo, \"NÃO INFORMADO\")\n",
    "        comparacoes[campo] = {\n",
    "            \"valor_heu\": val_heu,\n",
    "            \"valor_mod\": val_mod,\n",
    "            \"acertou\": (val_heu == val_mod)\n",
    "        }\n",
    "\n",
    "    # Campo Ki-67 (%)\n",
    "    val_heu_ki = json_heu[\"ki67_percentual\"]\n",
    "    try:\n",
    "        val_mod_ki = float(json_modelo.get(\"ki67_percentual\", 0))\n",
    "    except (ValueError, TypeError):\n",
    "        val_mod_ki = 0.0\n",
    "    comparacoes[\"ki67_percentual\"] = {\n",
    "        \"valor_heu\": val_heu_ki,\n",
    "        \"valor_mod\": val_mod_ki,\n",
    "        \"acertou\": (val_heu_ki == val_mod_ki)\n",
    "    }\n",
    "\n",
    "    return json_heu, comparacoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "408da633-74b1-4495-b4d3-6d47d2536ca4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Função de Agregação de Resultados\n",
    "\n",
    "Esta célula define uma função especializada para agregar resultados de avaliação de múltiplos laudos, calculando métricas de desempenho para cada campo extraído.\n",
    "\n",
    "**Objetivo da Função:**\n",
    "`agrega_resultados_dinamico` processa uma lista de comparações (gerada pela função `avalia_extracao_sem_ground_truth_imuno`) e calcula estatísticas agregadas, incluindo:\n",
    "- Número total de acertos por campo\n",
    "- Total de laudos analisados\n",
    "- Taxa de acerto (acertos/total) para cada campo\n",
    "\n",
    "**Detalhamento da Implementação:**\n",
    "1. Utiliza `Counter` para contabilizar os acertos por campo de forma eficiente\n",
    "2. Itera por todas as comparações e todos os campos dentro de cada comparação\n",
    "3. Verifica o atributo \"acertou\" de cada campo para contabilizar os acertos\n",
    "4. Gera um dicionário estruturado com as estatísticas de cada campo\n",
    "5. Garante que todos os campos estão representados no resultado, mesmo os que não tiveram acertos\n",
    "\n",
    "**Características Importantes:**\n",
    "- É uma função genérica que não assume um conjunto fixo de campos, podendo processar qualquer estrutura de comparações\n",
    "- Trata adequadamente o caso de divisão por zero quando não há laudos\n",
    "- Mantém consistência na estrutura de saída para facilitar análises posteriores\n",
    "\n",
    "Esta função é crucial para avaliar quantitativamente o desempenho do modelo de extração em todo o conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7da0a5a-93e0-450e-bb6c-ebdfcc2069e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def agrega_resultados_dinamico(lista_comparacoes):\n",
    "    \"\"\"\n",
    "    Agraga resultados de uma lista de dicionários de comparações, retornando para cada campo:\n",
    "      - acertos: número de vezes que 'acertou' == True\n",
    "      - total: número total de laudos (len(lista_comparacoes))\n",
    "      - taxa_acerto: acertos / total (ou 0.0 se total == 0)\n",
    "    \n",
    "    Suporta qualquer conjunto de chaves em cada dict, desde que cada valor seja outro dict contendo a chave 'acertou'.\n",
    "    \"\"\"\n",
    "    total_laudos = len(lista_comparacoes)\n",
    "    acertos_por_campo = Counter()\n",
    "\n",
    "    # Para cada comparação, percorremos todas as chaves e contamos os acertos\n",
    "    for comp in lista_comparacoes:\n",
    "        for campo, info in comp.items():\n",
    "            # Supondo que info seja um dict com a chave \"acertou\"\n",
    "            if info.get(\"acertou\", False):\n",
    "                acertos_por_campo[campo] += 1\n",
    "\n",
    "    # Monta o dicionário de saída\n",
    "    resultado = {}\n",
    "    for campo, acertos in acertos_por_campo.items():\n",
    "        resultado[campo] = {\n",
    "            \"acertos\": acertos,\n",
    "            \"total\": total_laudos,\n",
    "            \"taxa_acerto\": (acertos / total_laudos) if total_laudos > 0 else 0.0\n",
    "        }\n",
    "\n",
    "    # É possível que exista algum campo em alguma comparação que nunca teve 'acertou' == True.\n",
    "    # Se quisermos incluir também esses campos (com acertos = 0), podemos varrer as chaves da primeira entrada:\n",
    "    if lista_comparacoes:\n",
    "        primeira = lista_comparacoes[0]\n",
    "        for campo in primeira.keys():\n",
    "            if campo not in resultado:\n",
    "                resultado[campo] = {\n",
    "                    \"acertos\": 0,\n",
    "                    \"total\": total_laudos,\n",
    "                    \"taxa_acerto\": 0.0\n",
    "                }\n",
    "\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53c3999c-8fcb-470e-ae87-d80c52125cc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Verificação de Contagem de Registros\n",
    "\n",
    "Esta célula executa uma verificação rápida de quantos registros estão disponíveis para processamento no DataFrame `df_spk`. \n",
    "\n",
    "Esta contagem é importante para:\n",
    "1. Verificar se temos dados para processar\n",
    "2. Dimensionar o tempo de execução esperado\n",
    "3. Avaliar se o processo de filtragem nos retornou um conjunto de dados compatível com o esperado\n",
    "\n",
    "O valor retornado será o número total de laudos de imunohistoquímica de mama com menção a carcinoma que estão disponíveis para processamento pelo modelo de linguagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57abf05c-858a-424f-a0bf-06f8adbb2e32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_spk.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bf3845d-c26a-47a9-9493-c59fc7dd559b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Extração de Marcadores com LLM e Classificação Molecular\n",
    "\n",
    "Esta célula implementa o core do pipeline de processamento dos laudos, envolvendo a extração de informações estruturadas dos laudos médicos utilizando um modelo de linguagem e a subsequente classificação molecular dos casos de câncer. Este é o ponto central do notebook, onde o processamento efetivo dos dados acontece.\n",
    "\n",
    "**Objetivo:**\n",
    "1. Configurar o cliente LLM para comunicação com o endpoint Databricks\n",
    "2. Processar os laudos médicos para extração de biomarcadores \n",
    "3. Classificar os tumores em subtipos moleculares com base nos biomarcadores extraídos\n",
    "\n",
    "**Fluxo de Processamento:**\n",
    "1. **Inicialização do Cliente LLM**: Configura o cliente OpenAI para se comunicar com o endpoint Databricks\n",
    "2. **Definição de Persona**: Define o papel do modelo como \"médico oncologista especialista\"\n",
    "3. **Amostragem de Dados**: Limita a análise a 15 registros para processamento local\n",
    "4. **Processamento em Lote**: Envia os laudos para o modelo em lotes\n",
    "5. **Pós-processamento**: Converte as respostas do modelo em formato estruturado\n",
    "6. **Classificação Molecular**: Aplica regras específicas para determinar o subtipo molecular:\n",
    "   - **Luminal A**: ER+ ou PR+, HER2-, Ki-67 < 14%\n",
    "   - **Luminal B**: ER+ ou PR+, HER2-, Ki-67 ≥ 14%\n",
    "   - **Luminal com HER2 Positivo**: ER+ ou PR+, HER2+\n",
    "   - **HER-2 Superexpresso**: ER-, PR-, HER2+\n",
    "   - **Triplo Negativo**: ER-, PR-, HER2-\n",
    "\n",
    "A célula contém também código comentado que representa versões anteriores ou alternativas do pipeline, incluindo opções para persistência dos dados e registro de métricas, que podem ser descomentadas conforme necessário."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração via LLM, Parsing e Classificação Molecular\n",
    "\n",
    "Esta célula implementa o núcleo do pipeline de extração e classificação dos marcadores imunohistoquímicos dos laudos médicos utilizando um modelo de linguagem (LLM) distribuído no Databricks.\n",
    "\n",
    "**Principais etapas e lógica:**\n",
    "\n",
    "- **Importação de funções e tipos Spark:** São importados tipos de dados (`StructType`, `StringType`, `DoubleType`, etc.) e funções para manipulação de DataFrames (`from_json`, `col`), além do pandas para eventuais operações locais.\n",
    "- **Verificação de existência de dados:** O bloco só é executado se o DataFrame `df_spk` possuir registros.\n",
    "- **Preparação do prompt:** O template do prompt é ajustado para uso com a função SQL `FORMAT_STRING`, permitindo injetar o texto do laudo em cada chamada ao LLM.\n",
    "- **Geração do prompt final:** Uma nova coluna é criada com o prompt específico para cada laudo, garantindo que o modelo receba o contexto correto.\n",
    "- **Chamada distribuída ao LLM:** Utiliza a função `ai_query` para enviar os prompts ao modelo `databricks-llama-4-maverick`, recebendo as respostas em formato JSON.\n",
    "- **Limpeza da resposta do LLM:** Remove marcadores de bloco de código (```python, ```) e espaços extras para garantir que o JSON seja parseável.\n",
    "- **Parsing das respostas:** Converte a resposta limpa do LLM em colunas estruturadas, extraindo os campos de interesse (`receptor_estrogeno`, `receptor_progesterona`, `status_her2`, `ki67_percentual`, `status_ck5_6`).\n",
    "- **Depuração:** Exibe as respostas parseadas para inspeção.\n",
    "- **Conversão do Ki-67 para float:** Cria uma coluna numérica para facilitar a classificação molecular.\n",
    "- **Classificação molecular:** Aplica regras clínicas para categorizar cada caso em subtipos como Luminal A, Luminal B, Luminal com HER2 Positivo, HER-2 Superexpresso, Triplo Negativo ou Indefinido, com base nos marcadores extraídos.\n",
    "\n",
    "**Impacto:** Ao final, o DataFrame resultante contém todos os marcadores extraídos e a classificação molecular de cada laudo, pronto para validação, exportação ou persistência.\n",
    "\n",
    "**Exemplo de regra de classificação:**\n",
    "```python\n",
    "F.when(\n",
    "    ((F.col(\"receptor_estrogeno\") == \"POSITIVO\") | (F.col(\"receptor_progesterona\") == \"POSITIVO\")) &\n",
    "    (F.col(\"status_her2\") == \"NEGATIVO\") &\n",
    "    (F.col(\"ki67_percentual_float\") < 14),\n",
    "    \"Luminal A\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27f57ecc-0753-4aa4-8f69-bfe15a28f85e",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1761232520889}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, LongType, IntegerType\n",
    "from pyspark.sql.functions import from_json, col\n",
    "from pyspark.sql.functions import col # F já está importado como F.col\n",
    "import pandas as pd\n",
    "\n",
    "# --- Bloco principal de execução (dentro do `if df_spk.count() > 0:`) ---\n",
    "\n",
    "if df_spk.count() > 0:\n",
    "    # Nome do modelo Foundation Model no Databricks\n",
    "    llm_model_name = \"databricks-llama-4-maverick\" # Ou o modelo que você estiver usando\n",
    "\n",
    "    # Preparamos o template do prompt para ser usado com a função SQL FORMAT_STRING.\n",
    "    # O placeholder para o laudo será '%s'.\n",
    "    # Precisamos escapar as aspas internas do template para que ele seja uma string SQL válida.\n",
    "    # O `json.dumps` faz isso para nós.\n",
    "    # A string resultante será algo como: \"A seguir está um laudo... \\\"\\\"\\\"%s\\\"\\\"\\\" ...\"\n",
    "    prompt_template_for_sql = json.dumps(prompt_laudo_template().replace('\"\"\"{laudo_texto}\"\"\"', '\"\"\"%s\"\"\"'))\n",
    "\n",
    "    # --- ADIÇÃO PARA DEPURAR: Verifique o prompt final enviado ao LLM ---\n",
    "    # Crie uma coluna temporária para o prompt final para inspecionar\n",
    "    # Usamos F.expr com FORMAT_STRING para injetar o laudo_tratado\n",
    "    df_with_prompts = df_spk.withColumn(\n",
    "        \"final_prompt_for_llm\",\n",
    "        F.expr(f\"FORMAT_STRING({prompt_template_for_sql}, laudo_tratado)\")\n",
    "    )\n",
    "    # print(\"--- df_with_prompts (mostrando o prompt final enviado ao LLM) ---\")\n",
    "    # df_with_prompts.select(\"laudo_tratado\", \"final_prompt_for_llm\").display()\n",
    "    # --- FIM DA ADIÇÃO ---\n",
    "\n",
    "    # Usa ai_query para invocar o LLM de forma distribuída\n",
    "    df_with_llm_raw_responses = df_with_prompts.withColumn(\n",
    "        \"llm_raw_response\",\n",
    "        F.expr(f\"\"\"\n",
    "            ai_query(\n",
    "                '{llm_model_name}',\n",
    "                TO_JSON(MAP(\n",
    "                    'prompt', final_prompt_for_llm,\n",
    "                    'temperature', 0.0,\n",
    "                    'max_tokens', 4000,\n",
    "                    'top_p', 0.75,\n",
    "                    'frequency_penalty', 0.0,\n",
    "                    'presence_penalty', 0.0\n",
    "                )),\n",
    "                'JSON'\n",
    "            )\n",
    "        \"\"\")\n",
    "    )\n",
    "\n",
    "    # --- ADIÇÃO PARA LIMPAR A SAÍDA BRUTA DO LLM ANTES DO from_json ---\n",
    "    # Remove os marcadores de bloco de código \"```python\" e \"```\"\n",
    "    df_cleaned_llm_responses = df_with_llm_raw_responses.withColumn(\n",
    "        \"llm_cleaned_response\",\n",
    "        F.regexp_replace(F.col(\"llm_raw_response\"), \"```python|```\", \"\") # Remove ambos os marcadores\n",
    "    )\n",
    "    # Remove espaços em branco extras no início e fim\n",
    "    df_cleaned_llm_responses = df_cleaned_llm_responses.withColumn(\n",
    "        \"llm_cleaned_response\",\n",
    "        F.trim(F.col(\"llm_cleaned_response\"))\n",
    "    )\n",
    "\n",
    "    # print(\"--- df_cleaned_llm_responses (mostrando a saída do LLM após limpeza) ---\")\n",
    "    # df_cleaned_llm_responses.select(\"laudo_tratado\", \"llm_raw_response\", \"llm_cleaned_response\").display()\n",
    "    # --- FIM DA ADIÇÃO ---\n",
    "\n",
    "    # Converte as strings JSON das respostas do LLM em colunas estruturadas\n",
    "    # AGORA USANDO A COLUNA LIMPA: \"llm_cleaned_response\"\n",
    "    df_llm_parsed = df_cleaned_llm_responses.withColumn(\n",
    "        \"llm_parsed_output\", F.from_json(F.col(\"llm_cleaned_response\"), llm_output_schema)\n",
    "    ).select(\n",
    "        \"*\", # Mantém todas as colunas originais\n",
    "        F.col(\"llm_parsed_output.receptor_estrogeno\").alias(\"receptor_estrogeno\"),\n",
    "        F.col(\"llm_parsed_output.receptor_progesterona\").alias(\"receptor_progesterona\"),\n",
    "        F.col(\"llm_parsed_output.status_her2\").alias(\"status_her2\"),\n",
    "        F.col(\"llm_parsed_output.ki67_percentual\").alias(\"ki67_percentual\"),\n",
    "        F.col(\"llm_parsed_output.status_ck5_6\").alias(\"status_ck5_6\")\n",
    "    ).drop(\"llm_raw_response\", \"llm_parsed_output\", \"llm_cleaned_response\") # Remove as colunas intermediárias\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # --- ADIÇÃO PARA DEPURAR: Verifique a saída bruta do LLM ---\n",
    "    # print(\"--- df_with_llm_raw_responses (mostrando a saída bruta do LLM) ---\")\n",
    "    # df_with_llm_raw_responses.select(\"laudo_tratado\", \"llm_raw_response\").display()\n",
    "    # --- FIM DA ADIÇÃO ---\n",
    "\n",
    "\n",
    "    # --- ADIÇÃO PARA DEPURAR: Verifique a saída parseada do LLM ---\n",
    "    print(\"--- df_llm_parsed (mostrando a saída parseada do LLM) ---\")\n",
    "    df_llm_parsed.select(\"laudo_tratado\", \"receptor_estrogeno\", \"receptor_progesterona\", \"status_her2\", \"ki67_percentual\", \"status_ck5_6\").display()\n",
    "    # --- FIM DA ADIÇÃO ---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Garante que ki67_percentual seja float para a classificação\n",
    "    df_llm_parsed = df_llm_parsed.withColumn(\n",
    "        \"ki67_percentual_float\",\n",
    "        F.when(\n",
    "            F.col(\"ki67_percentual\").cast(DoubleType()).isNotNull(),\n",
    "            F.col(\"ki67_percentual\").cast(DoubleType())\n",
    "        ).otherwise(0.0) # Se não for um número válido, assume 0.0\n",
    "    )\n",
    "\n",
    "    # print(\"DF com respostas LLM e parsing\")\n",
    "    # display(df_llm_parsed)\n",
    "\n",
    "    # --- Sua lógica de classificação final (mantida) ---\n",
    "    df_final_classif = df_llm_parsed.withColumn(\n",
    "            \"categoria_final\",\n",
    "            F.when(\n",
    "                (\n",
    "                    ((F.col(\"receptor_estrogeno\") == \"POSITIVO\") | (F.col(\"receptor_progesterona\") == \"POSITIVO\")) &\n",
    "                    (F.col(\"status_her2\") == \"NEGATIVO\") &\n",
    "                    (F.col(\"ki67_percentual_float\") < 14)\n",
    "                ),\n",
    "                \"Luminal A\"\n",
    "            ).when(\n",
    "                (\n",
    "                    ((F.col(\"receptor_estrogeno\") == \"POSITIVO\") | (F.col(\"receptor_progesterona\") == \"POSITIVO\")) &\n",
    "                    (F.col(\"status_her2\") == \"NEGATIVO\") &\n",
    "                    (F.col(\"ki67_percentual_float\") >= 14)\n",
    "                ),\n",
    "                \"Luminal B\"\n",
    "            ).when(\n",
    "                (\n",
    "                    ((F.col(\"receptor_estrogeno\") == \"POSITIVO\") | (F.col(\"receptor_progesterona\") == \"POSITIVO\")) &\n",
    "                    (F.col(\"status_her2\") == \"POSITIVO\")\n",
    "                ),\n",
    "                \"Luminal com HER2 Positivo\"\n",
    "            ).when(\n",
    "                (\n",
    "                    (F.col(\"receptor_estrogeno\") == \"NEGATIVO\") &\n",
    "                    (F.col(\"receptor_progesterona\") == \"NEGATIVO\") &\n",
    "                    (F.col(\"status_her2\") == \"POSITIVO\")\n",
    "                ),\n",
    "                \"HER-2 Superexpresso\"\n",
    "            ).when(\n",
    "                (\n",
    "                    (F.col(\"receptor_estrogeno\") == \"NEGATIVO\") &\n",
    "                    (F.col(\"receptor_progesterona\") == \"NEGATIVO\") &\n",
    "                    (F.col(\"status_her2\") == \"NEGATIVO\")\n",
    "                ),\n",
    "                \"Triplo Negativo\"\n",
    "            ).otherwise(\"Indefinido\")\n",
    "        )\n",
    "\n",
    "    # print(\"df_final_classif\")\n",
    "    # display(df_final_classif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f58f8927-e48d-48a7-9b99-e56207ffa201",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Processamento de Métricas de Avaliação (Código de Referência)\n",
    "\n",
    "Esta célula contém código de referência para processar métricas de avaliação do desempenho do modelo de extração. Embora não seja executado diretamente (pois depende de variáveis não definidas no fluxo principal), este código serve como template para avaliação de qualidade.\n",
    "\n",
    "O código demonstra como:\n",
    "1. Criar um DataFrame de métricas com laudos e resultados\n",
    "2. Converter estruturas de dados em formatos apropriados\n",
    "3. Executar a função de avaliação para cada laudo\n",
    "4. Transformar os resultados para facilitar análise\n",
    "\n",
    "Este tipo de avaliação é útil para monitorar a qualidade das extrações e identificar áreas para melhoria do prompt ou do processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2c7fe17-746e-43ce-a8ec-0d5dc25ba342",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Bloco de avaliação de métricas (após a geração de df_llm_parsed ou df_final_classif) ---\n",
    "\n",
    "# Para realizar a avaliação, você precisará coletar uma amostra dos dados para o driver.\n",
    "# Isso é aceitável para avaliação, mas não para o pipeline de inferência principal.\n",
    "# Ajuste o `limit(N)` conforme a quantidade de dados que você deseja avaliar.\n",
    "df_sample_for_eval = df_llm_parsed.toPandas() # Coleta uma amostra para avaliação local\n",
    "\n",
    "lista_laudos_eval = df_sample_for_eval[\"laudo_tratado\"].tolist()\n",
    "\n",
    "# Prepara a saída do LLM para a função de avaliação\n",
    "# O `json_model_output` deve ser um dicionário Python para cada linha\n",
    "lista_json_modelo_eval = []\n",
    "for index, row in df_sample_for_eval.iterrows():\n",
    "    lista_json_modelo_eval.append({\n",
    "        \"receptor_estrogeno\": row[\"receptor_estrogeno\"],\n",
    "        \"receptor_progesterona\": row[\"receptor_progesterona\"],\n",
    "        \"status_her2\": row[\"status_her2\"],\n",
    "        \"ki67_percentual\": row[\"ki67_percentual\"], # Use a string original do LLM\n",
    "        \"status_ck5_6\": row[\"status_ck5_6\"]\n",
    "    })\n",
    "\n",
    "lista_pseudo_gold_eval = []\n",
    "lista_comparacoes_eval = []\n",
    "\n",
    "# As funções avalia_extracao_sem_ground_truth_imuno e agrega_resultados_dinamico\n",
    "# devem estar definidas em células anteriores.\n",
    "for laudo_txt, json_mod in zip(lista_laudos_eval, lista_json_modelo_eval):\n",
    "    json_heu, comp = avalia_extracao_sem_ground_truth_imuno(laudo_txt, json_mod)\n",
    "    lista_pseudo_gold_eval.append(json_heu)\n",
    "    lista_comparacoes_eval.append(comp)\n",
    "\n",
    "# Agrega os resultados das comparações\n",
    "json_metricas = agrega_resultados_dinamico(lista_comparacoes_eval)\n",
    "\n",
    "print(\"Métricas de Avaliação:\")\n",
    "print(json.dumps(json_metricas, indent=2))\n",
    "\n",
    "# Opcional: Para visualizar os resultados detalhados da avaliação\n",
    "# df_metrics_eval = pd.DataFrame()\n",
    "# df_metrics_eval[\"laudos\"] = lista_laudos_eval\n",
    "# df_metrics_eval[\"json_modelo\"] = lista_json_modelo_eval\n",
    "# df_metrics_eval[\"json_heuristico\"] = lista_pseudo_gold_eval\n",
    "# df_metrics_eval[\"comparacoes\"] = lista_comparacoes_eval\n",
    "# display(df_metrics_eval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcb74631-b832-4b64-8980-91fc97d2de49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Visualização das Métricas de Avaliação\n",
    "\n",
    "Esta célula exibe o DataFrame `df_metrics`, que contém os resultados detalhados da avaliação das extrações do modelo em comparação com as extrações heurísticas (pseudo-gold).\n",
    "\n",
    "O DataFrame exibe:\n",
    "1. Os laudos médicos originais\n",
    "2. Para cada campo extraído (receptores de estrogênio, progesterona, status HER2, etc.):\n",
    "   - O valor extraído pelo método heurístico\n",
    "   - O valor extraído pelo modelo de linguagem\n",
    "   - Um indicador booleano de acerto (True/False)\n",
    "\n",
    "Esta visualização é fundamental para análise detalhada do desempenho do modelo campo a campo e laudo a laudo, permitindo identificar padrões de erros específicos e oportunidades de melhoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "045bc3bf-03ac-4a77-8c72-a42fba18d042",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Opcional: Para visualizar os resultados detalhados da avaliação\n",
    "df_metrics_eval = pd.DataFrame()\n",
    "df_metrics_eval[\"laudos\"] = lista_laudos_eval\n",
    "df_metrics_eval[\"json_modelo\"] = lista_json_modelo_eval\n",
    "df_metrics_eval[\"json_heuristico\"] = lista_pseudo_gold_eval\n",
    "df_metrics_eval[\"comparacoes\"] = lista_comparacoes_eval\n",
    "display(df_metrics_eval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d3502d1-faed-4279-8394-8272d534e550",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Contagem de Registros Classificados\n",
    "\n",
    "Esta célula realiza uma contagem simples do número de registros no DataFrame `df_final_classif`, que contém os laudos processados com suas respectivas classificações moleculares.\n",
    "\n",
    "Esta contagem serve para:\n",
    "1. Verificar quantos laudos foram processados com sucesso\n",
    "2. Confirmar que o processamento ocorreu como esperado\n",
    "3. Fornecer informação importante para monitoramento do pipeline\n",
    "\n",
    "O número retornado representa a quantidade total de laudos de imunohistoquímica de mama que foram classificados em subtipos moleculares pelo pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3104b340-34d3-40cc-a6f3-8af1fe75700b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_final_classif.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "419446bb-2a92-4ef3-99f5-727baed5ce55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Persistência dos Dados Processados em Delta Lake\n",
    "\n",
    "Esta célula final implementa a persistência dos dados processados em uma tabela Delta Lake, para uso posterior em análises e modelos preditivos. Utiliza o padrão de operação \"merge\" (upsert) para garantir idempotência e evitar duplicações.\n",
    "\n",
    "**Componentes principais:**\n",
    "1. **Configurações de Monitoramento**: Definição do webhook para alertas via Sentinel\n",
    "2. **Inicialização da Sessão Spark**: Configuração da sessão para operações com Delta\n",
    "3. **Definição do Caminho de Saída**: Especificação da tabela de destino\n",
    "4. **Função `insert_data`**: Encapsula a lógica de inserção/atualização:\n",
    "   - Verifica se a tabela Delta já existe\n",
    "   - Cria a tabela se necessário\n",
    "   - Executa uma operação de merge quando a tabela já existe\n",
    "   \n",
    "5. **Tratamento de Erros**: Estrutura try/except com:\n",
    "   - Verificação da existência de dados para inserção\n",
    "   - Chamada à função de inserção quando há dados\n",
    "   - Envio de notificação via Sentinel quando não há dados para processamento\n",
    "   - Captura e relato de exceções\n",
    "\n",
    "Esta persistência é essencial para que os dados estruturados extraídos dos laudos e as classificações moleculares possam ser utilizados por sistemas downstream, como dashboards de BI, modelos preditivos ou ferramentas de apoio à decisão clínica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36522fbd-e21d-47ce-88e3-751203868748",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import traceback\n",
    "# from octoops import Sentinel\n",
    "# from delta.tables import DeltaTable\n",
    "\n",
    "# WEBHOOK_DS_AI_BUSINESS_STG = 'stg'\n",
    "\n",
    "# # spark = SparkSession.builder.appName(\"DfPandasparaSpark\").getOrCreate() # REMOVIDO: SparkSession já é inicializada no Databricks\n",
    "\n",
    "# # OUTPUT_DATA_PATH = dbutils.widgets.get(\"OUTPUT_DATA_PATH\") # Mantido se for usado via widget\n",
    "# OUTPUT_DATA_PATH = \"refined.saude_preventiva.fleury_laudos_mama_imunohistoquimico\"\n",
    "\n",
    "# # função para salvar dados na tabela\n",
    "# # Renomeado o parâmetro para maior clareza\n",
    "# def insert_data(df_to_save, output_data_path):\n",
    "\n",
    "#     # Cria a tabela Delta se não existir\n",
    "#     if not DeltaTable.isDeltaTable(spark, output_data_path):\n",
    "#         df_to_save.write.format(\"delta\").saveAsTable(output_data_path)\n",
    "#     else:\n",
    "#         # Carrega a tabela Delta existente\n",
    "#         delta_table = DeltaTable.forPath(spark, output_data_path)\n",
    "\n",
    "#         # Faz o merge (upsert)\n",
    "#         (delta_table.alias(\"target\")\n",
    "#         .merge(\n",
    "#             df_to_save.alias(\"source\"), # Usando df_to_save\n",
    "#             \"target.ficha = source.ficha AND target.id_item = source.id_item AND target.id_subitem = source.id_subitem\"\n",
    "#         )\n",
    "#         .whenMatchedUpdateAll() #atualiza todos os campos se o ID já existir\n",
    "#         .whenNotMatchedInsertAll() #insere se o ID não existir\n",
    "#         .execute())\n",
    "\n",
    "# # salvar dados na tabela\n",
    "# try:\n",
    "#     # Calcula a contagem uma única vez para otimização\n",
    "#     num_records_to_save = df_final_classif.count()\n",
    "\n",
    "#     if num_records_to_save > 0:\n",
    "#         # Inserir tabela catalog\n",
    "#         insert_data(df_final_classif, OUTPUT_DATA_PATH)\n",
    "#         print(f'Total de registros salvos na tabela: {num_records_to_save}')\n",
    "#     else:\n",
    "#         # A mensagem de erro é mais específica para o caso de não haver laudos\n",
    "#         error_message = \"Fleury Imunuhistoquimico - Não há laudos para extração ou processamento.\"\n",
    "#         sentinela_ds_ai_business = Sentinel(\n",
    "#             project_name='Monitor_Linhas_Cuidado_Mama',\n",
    "#             env_type=WEBHOOK_DS_AI_BUSINESS_STG,\n",
    "#             task_title='Fleury Mama Imunuhistoquimico'\n",
    "#         )\n",
    "#         sentinela_ds_ai_business.alerta_sentinela(\n",
    "#             categoria='Alerta',\n",
    "#             mensagem=error_message,\n",
    "#             job_id_descritivo='4_fleury_mama_Imunuhistoquimico'\n",
    "#         )\n",
    "# except Exception as e:\n",
    "#     traceback.print_exc()\n",
    "#     raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39109042-2b2f-48cc-abfb-6a9328eab3b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Funções auxiliares para exportação de Excel (manter estas funções em uma célula) ---\n",
    "def salvar_excel(df, nome_arquivo):\n",
    "    \"\"\"\n",
    "    Salva um DataFrame em um arquivo Excel.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame a ser salvo.\n",
    "        nome_arquivo (str): Nome do arquivo Excel.\n",
    "    \"\"\"\n",
    "\n",
    "    # After installing, save the DataFrame to Excel again\n",
    "    df.to_excel(nome_arquivo, index=False)\n",
    "\n",
    "def conta_marcadores(txt: str, marcador: str) -> int:\n",
    "    \"\"\"\n",
    "    Conta quantas vezes uma marcador aparece no texto, ignorando maiúsculas/minúsculas.\n",
    "    \"\"\"\n",
    "    marcadores = {\n",
    "        'estrogenio': r\"\\b(receptor\\s+de\\s+estr[oó]g(?:[eê]nio|eno))\\b\",\n",
    "        'progesterona': r\"\\b(receptor\\s+de\\s+progesterona)\\b\",\n",
    "        'her2': r\"\\bher2\\b\",\n",
    "        'ck5_6': r\"\\bck5\\s*\\/\\s*6\\b\",\n",
    "        'ki67': r\"\\bki[-\\s]?67\\b\"\n",
    "    }\n",
    "    pattern = marcadores.get(marcador)\n",
    "    if not pattern:\n",
    "        raise ValueError(f\"marcador '{marcador}' não reconhecida. Use uma das seguintes: {list(marcadores.keys())}\")\n",
    "\n",
    "    matches = re.findall(pattern, txt, flags=re.IGNORECASE)\n",
    "    return len(matches)\n",
    "\n",
    "def pega_texto_marcador(txt: str, sigla: str) -> str: # Alterado para retornar str, não int\n",
    "    \"\"\"\n",
    "    Pega o texto que vem depois do marcador, limitado em 100 caracteres.\n",
    "    \"\"\"\n",
    "    siglas = {\n",
    "        'estrogenio': r\"\\b(receptor\\s+de\\s+estr[oó]g(?:[eê]nio|eno))\\b\",\n",
    "        'progesterona': r\"\\b(receptor\\s+de\\s+progesterona)\\b\",\n",
    "        'her2': r\"\\bher2\\b\",\n",
    "        'ck5_6': r\"\\bck5\\s*\\/\\s*6\\b\",\n",
    "        'ki67': r\"\\bki[-\\s]?67\\b\"\n",
    "    }\n",
    "    pattern = siglas.get(sigla)\n",
    "    if not pattern:\n",
    "        raise ValueError(f\"sigla '{sigla}' não reconhecida. Use uma das seguintes: {list(siglas.keys())}\")\n",
    "\n",
    "    match = re.search(pattern, txt, flags=re.IGNORECASE)\n",
    "    if match:\n",
    "        # Pega o texto após o marcador, limitado a 100 caracteres\n",
    "        start = match.end()\n",
    "        end = start + 100\n",
    "        return txt[start:end].strip()\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def configura_excel(df, nome_arquivo):\n",
    "    \"\"\"\n",
    "    Configura o DataFrame para salvar em Excel com as seguintes regras:\n",
    "    - Nas colunas booleanas (receptor_estrogeno.acertou, receptor_progesterona.acertou, status_her2.acertou, status_ck5_6.acertou, ki67_percentual.acertou), colorir de vermelho se False.\n",
    "    - Na coluna (erro), colorir de vermelho se True.\n",
    "    - Salvar em uma aba chamada 'Resultados' e outra aba chamada 'Resumo' com a contagem de erros e o percentual de erros por coluna em relação ao total de linhas, inserir uma linha com o total de erros e do percentual.\n",
    "    - Salvar o arquivo com o nome '{nome_arquivo}'\n",
    "    \"\"\"\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    # Função para aplicar a formatação condicional\n",
    "    def colorir_vermelho(val):\n",
    "        color = 'red' if val == False else ''\n",
    "        return f'background-color: {color}'\n",
    "    \n",
    "    # Função para aplicar a formatação condicional\n",
    "    def colorir_erro(val):\n",
    "        color = 'red' if val == True else ''\n",
    "        return f'background-color: {color}'\n",
    "    \n",
    "    # def colorir_verde(val):\n",
    "    #     color = 'green' if val == True else ''\n",
    "    #     return f'background-color: {color}'\n",
    "\n",
    "    # Seleciona as colunas booleanas para aplicar a formatação\n",
    "    colunas_booleanas = [\n",
    "        'receptor_estrogeno.acertou',\n",
    "        'receptor_progesterona.acertou',\n",
    "        'status_her2.acertou',\n",
    "        'status_ck5_6.acertou',\n",
    "        'ki67_percentual.acertou',\n",
    "    ]\n",
    "\n",
    "    # Cria um objeto Styler\n",
    "    styler = df.style\n",
    "\n",
    "    # Aplica a formatação condicional nas colunas booleanas\n",
    "    for coluna in colunas_booleanas:\n",
    "        if coluna in df.columns:\n",
    "            styler = styler.map(colorir_vermelho, subset=[coluna])\n",
    "    \n",
    "    # Aplica a formatação condicional na coluna 'erro'\n",
    "    if 'erro' in df.columns:\n",
    "        styler = styler.map(colorir_erro, subset=['erro'])\n",
    "\n",
    "    # Cria o resumo de erros por coluna\n",
    "    resumo = {coluna: df[coluna].value_counts().get(False, 0) for coluna in colunas_booleanas}\n",
    "    resumo_df = pd.DataFrame(list(resumo.items()), columns=['Coluna', 'Contagem de Erros'])\n",
    "    resumo_df['Percentual de Erros (%)'] = (resumo_df['Contagem de Erros'] / len(df)) * 100\n",
    "    resumo_df.loc['Total'] = resumo_df.sum(numeric_only=True)\n",
    "\n",
    "    # Salva em um arquivo Excel com duas abas\n",
    "    with pd.ExcelWriter(f'{nome_arquivo}', engine='openpyxl') as writer:\n",
    "        styler.to_excel(writer, sheet_name='Resultados', index=False)\n",
    "        resumo_df.to_excel(writer, sheet_name='Resumo', index=False)\n",
    "\n",
    "    print(f\"Arquivo Excel salvo como {nome_arquivo} com as abas 'Resultados' e 'Resumo'.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "077dc326-34c8-4db3-b587-0127e3e361c6",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1760995777355}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Bloco para gerar a planilha de comparação (em uma nova célula) ---\n",
    "\n",
    "# df_sample_for_eval e lista_comparacoes_eval devem ter sido gerados na célula de avaliação anterior.\n",
    "# Se a célula de avaliação não for executada, este bloco falhará.\n",
    "\n",
    "if 'df_sample_for_eval' in locals() and not df_sample_for_eval.empty:\n",
    "    # Cria uma cópia do DataFrame de amostra para não modificar o original\n",
    "    df_validacao = df_sample_for_eval[['laudo_tratado']].copy()\n",
    "\n",
    "    # Normaliza a lista de comparações para adicionar as colunas de acerto\n",
    "    # lista_comparacoes_eval deve vir da célula de avaliação\n",
    "    if 'lista_comparacoes_eval' in locals() and lista_comparacoes_eval:\n",
    "        resultados_expandidos = pd.json_normalize(lista_comparacoes_eval)\n",
    "        \n",
    "        # Adiciona um prefixo para evitar conflito de nomes de colunas\n",
    "        # resultados_expandidos = resultados_expandidos.add_prefix('comparacao_')\n",
    "        df_validacao = pd.concat(\n",
    "            [df_validacao.reset_index(drop=True), resultados_expandidos.reset_index(drop=True)],\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        # Contagem de quantas vezes cada sigla aparece no laudo\n",
    "        siglas = ['estrogenio', 'progesterona', 'her2', 'ck5_6', 'ki67']\n",
    "        for sigla in siglas:\n",
    "            df_validacao['ctg_' + sigla] = df_validacao['laudo_tratado'].apply(lambda x: conta_marcadores(x, sigla))\n",
    "            # Adiciona o texto do marcador para análise\n",
    "            df_validacao['txt_' + sigla] = df_validacao['laudo_tratado'].apply(lambda x: pega_texto_marcador(x, sigla))\n",
    "\n",
    "        # Insere coluna de erro genérico\n",
    "        df_validacao['erro'] = df_validacao.apply(lambda x:\n",
    "                                        (x.get('ki67_percentual.acertou', False) == False) or\n",
    "                                        (x.get('receptor_estrogeno.acertou', False) == False) or\n",
    "                                        (x.get('receptor_progesterona.acertou', False) == False) or\n",
    "                                        (x.get('status_her2.acertou', False) == False) or\n",
    "                                        (x.get('status_ck5_6.acertou', False) == False), axis=1)\n",
    "        \n",
    "        nome_arquivo_excel = \"df_validacao_laura.xlsx\"\n",
    "\n",
    "        # Aplica formatação condicional e configura as cores das céluas\n",
    "        configura_excel(df_validacao, nome_arquivo_excel)\n",
    "                \n",
    "        display(df_validacao.head(3))\n",
    "        print(df_validacao.columns)\n",
    "\n",
    "    else:\n",
    "        print(\"Lista de comparações vazia ou não encontrada. Não foi possível gerar a planilha de comparação.\")\n",
    "else:\n",
    "    print(\"DataFrame de amostra para avaliação (df_sample_for_eval) vazio ou não encontrado. Não foi possível gerar a planilha de comparação.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8521dacb-0c23-4855-a2fb-198b48014b70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_final_classif.describe()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4_fleury_mama_imunohistoquimico_batch",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "fleury",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
