{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cc9396a-c7bb-4da6-96f0-fbbbdbfb51ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Documentação Técnica: Extração de Dados de Anatomia Patológica - Fleury\n",
    "\n",
    "## Objetivo Principal\n",
    "**Este notebook realiza a extração e classificação automática de informações clínicas relevantes em laudos de anatomia patológica de mama do Fleury.** Utilizando técnicas de processamento de linguagem natural (NLP) com modelos de linguagem avançados (LLMs), o notebook identifica descritores de malignidade, graus histológicos e nucleares, formação de túbulos, índices mitóticos e tipos histológicos em laudos médicos de anatomia patológica mamária.\n",
    "\n",
    "## Tecnologias Utilizadas\n",
    "- **OpenAI/Databricks LLM API**: Para processamento e extração de informações dos textos dos laudos\n",
    "- **PySpark**: Framework principal para processamento distribuído de dados\n",
    "- **MLflow**: Para registro de métricas, experimentos e monitoramento dos resultados de extração\n",
    "- **Delta Lake**: Sistema de armazenamento para tabelas de destino\n",
    "- **Pandas**: Manipulação de dataframes para processamento local\n",
    "- **Expressões Regulares (re)**: Validação e extração de padrões específicos nos textos dos laudos\n",
    "- **Octoops**: Monitoramento e alertas de falhas\n",
    "\n",
    "## Fluxo de Trabalho/Etapas Principais\n",
    "1. **Definição dos Parâmetros**: Configuração de tabelas, filtros e critérios de extração\n",
    "2. **Consulta de Dados**: Extração de laudos recentes da base de dados do Fleury\n",
    "3. **Processamento via LLM**:\n",
    "   - Definição do prompt especializado para extração de informações\n",
    "   - Processamento batch dos laudos via API de LLM\n",
    "   - Extração estruturada das informações relevantes\n",
    "4. **Validação dos Resultados**:\n",
    "   - Comparação entre extração via regex e via LLM\n",
    "   - Cálculo de métricas de precisão\n",
    "   - Registro de métricas no MLflow\n",
    "5. **Persistência dos Dados**: Salvamento dos dados processados em tabela Delta\n",
    "\n",
    "## Dados Envolvidos\n",
    "- **Fonte**: Tabela `refined.saude_preventiva.fleury_laudos`\n",
    "- **Filtros**:\n",
    "  - Linha de cuidado: \"mama\"\n",
    "  - Sexo: \"F\" (feminino)\n",
    "  - Siglas de exame: \"ANATPATP\", \"CTPUNC\", \"FISHHER\"\n",
    "  - Laudos contendo \"Topografia: mama\"\n",
    "- **Tabela de Destino**: `refined.saude_preventiva.fleury_laudos_mama_anatomia_patologica_v2`\n",
    "- **Informações Extraídas**:\n",
    "  - **Descritores de Malignidade**: carcinoma, invasivo, invasor, sarcoma, metástase, metastático, maligno, maligna, cdi, cli, cdis\n",
    "  - **Grau Histológico**: 1, 2 ou 3\n",
    "  - **Grau Nuclear**: 1, 2 ou 3\n",
    "  - **Formação de Túbulos**: 1, 2 ou 3\n",
    "  - **Índice Mitótico**: valor numérico\n",
    "  - **Tipo Histológico**: classificação específica do tipo de carcinoma\n",
    "\n",
    "## Resultados/Saídas Esperadas\n",
    "- DataFrame enriquecido com os campos extraídos dos laudos\n",
    "- Registro de métricas de qualidade da extração via MLflow\n",
    "- Dados persistidos na tabela Delta `refined.saude_preventiva.fleury_laudos_mama_anatomia_patologica_v2`\n",
    "- Alertas via Sentinel (Octoops) em caso de falhas ou ausência de dados\n",
    "\n",
    "## Pré-requisitos\n",
    "- Ambiente Databricks configurado\n",
    "- Acesso ao endpoint LLM Databricks (`databricks-llama-4-maverick` ou `teste-maverick`)\n",
    "- Permissões de acesso às tabelas de origem e destino\n",
    "- Bibliotecas instaladas: openai, mlflow, pandas, tqdm, databricks-feature-store, octoops\n",
    "\n",
    "## Considerações Importantes/Observações\n",
    "- A extração via LLM é comparada com uma extração via regex (considerada pseudo-gold) para validação\n",
    "- O threshold definido para aceitação da qualidade da extração é de 80%\n",
    "- O modelo está otimizado para identificar termos específicos de malignidade e classificações dentro do contexto oncológico mamário\n",
    "- Os resultados são registrados no experimento MLflow `/Shared/saude_preventiva_mama/experiments_fleury_anatomopatologico`\n",
    "- A persistência utiliza estratégia de merge (upsert) para garantir a atualização de registros já existentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25bb71fd-3c2c-477b-a48e-9237f36e3d6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Extração de dados - Anatomo Patologico\n",
    "Serão analisados os descritores de malignidade.\n",
    "**Descritores de MALIGNIDADE:**\n",
    "- carcinoma\n",
    "- invasivo\n",
    "- invasor\n",
    "- sarcoma\n",
    "- metástase\n",
    "- metastático\n",
    "- maligno\n",
    "- maligna\n",
    "- cdi, cli, cdis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1916e94c-8e81-4c27-9c53-f5538a157781",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Outros labels a serem extraídos:\n",
    "\n",
    "- **Grau histológico:** será sempre um algarismo 1, 2 ou 3 (apenas três categorias). Para encontrar, basta procurar o primeiro algarismo numérico após o termo **\"grau histológico\"**.\n",
    "\n",
    "- **Grau nuclear:** será sempre um algarismo 1, 2 ou 3 (apenas três categorias). Para encontrar, basta procurar o primeiro algarismo numérico após o termo **\"grau nuclear\"**.\n",
    "\n",
    "- **Formação de túbulos:** será sempre um algarismo 1, 2 ou 3 (apenas três categorias). Para encontrar, basta procurar o primeiro algarismo numérico após o termo **\"formação de túbulos\"**.\n",
    "\n",
    "- **Índice mitótico:** será sempre um algarismo 1, 2 ou 3 (apenas três categorias). Para encontrar, basta procurar o primeiro algarismo numérico após o termo **\"mm2\"**. Nesse caso, é melhor procurar o termo **\"mm2\"** ao invés de **\"índice mitótico\"**.\n",
    "\n",
    "- **Labels de tipos histológicos:**\n",
    "  - Carcinoma de mama ductal invasivo (CDI)/SOE\n",
    "  - Carcinoma de mama ductal in situ\n",
    "  - Carcinoma de mama lobular invasivo\n",
    "  - Carcinoma de mama lobular\n",
    "  - Carcinoma de mama papilífero\n",
    "  - Carcinoma de mama metaplásico\n",
    "  - Carcinoma de mama mucinoso\n",
    "  - Carcinoma de mama tubular\n",
    "  - Carcinoma de mama cístico adenoide\n",
    "  - Carcinoma de mama medular\n",
    "  - Carcinoma de mama micropapilar\n",
    "  - Carcinoma de mama misto (ductal e lobular) invasivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94c1113c-4fae-43a7-8497-a4ec402dfb09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Instalação de pacotes necessários\n",
    "**Objetivo da Célula:** Instalar as bibliotecas necessárias para executar o notebook.\n",
    "\n",
    "**Pacotes Instalados:**\n",
    "- **openai**: Cliente para comunicação com a API OpenAI/Databricks LLM\n",
    "- **databricks-feature-store**: Biblioteca para interagir com o Feature Store do Databricks\n",
    "- **octoops**: Biblioteca para monitoramento e alertas\n",
    "\n",
    "A instalação é feita usando o comando mágico `%pip`, que é específico para ambientes Jupyter/Databricks. O parâmetro `-q` (quiet) é usado em algumas instalações para reduzir a verbosidade da saída."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d53f197a-e7ae-4256-a74d-c8ab9ce42835",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def salvar_excel(df, nome_arquivo):\n",
    "    \"\"\" \n",
    "    Salva um DataFrame em um arquivo Excel.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame a ser salvo.\n",
    "        nome_arquivo (str): Nome do arquivo Excel.\n",
    "    \"\"\"\n",
    "    %pip install openpyxl\n",
    "    import pandas as pd\n",
    "\n",
    "    # After installing, save the DataFrame to Excel again\n",
    "    df.to_excel(nome_arquivo, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "758d550a-6f5b-4b53-ad22-9ba5df156f30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install openai\n",
    "# %pip install tqdm -q\n",
    "# %pip install pandarallel -q\n",
    "%pip install databricks-feature-store -q\n",
    "%pip install octoops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6f1b358-dd48-446d-8c8c-e10622d92269",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Reinicialização do ambiente Python\n",
    "**Objetivo da Célula:** Reiniciar o kernel Python para garantir que as bibliotecas recém-instaladas sejam carregadas corretamente.\n",
    "\n",
    "Esta célula executa o comando `dbutils.library.restartPython()`, que é específico do ambiente Databricks. Este comando reinicia o interpretador Python, garantindo que todas as bibliotecas instaladas na célula anterior sejam devidamente carregadas no ambiente de execução. Isso é necessário porque, em ambientes Jupyter/Databricks, as bibliotecas instaladas durante a execução do notebook só ficam disponíveis após a reinicialização do kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd3f7ce2-7d45-4285-9f9c-65bfa1503408",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "452096a2-3017-464f-93ee-5a512c60f0f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Importação de bibliotecas e configuração do ambiente\n",
    "**Objetivo da Célula:** Importar todas as bibliotecas necessárias para o processamento de dados e desativar exibições automáticas do MLflow.\n",
    "\n",
    "**Dependências:**\n",
    "- Bibliotecas instaladas nas células anteriores\n",
    "\n",
    "**Bibliotecas Importadas:**\n",
    "- **re**: Para manipulação de expressões regulares\n",
    "- **os, sys**: Manipulação do sistema e ambiente\n",
    "- **json, time**: Processamento de JSON e controle de tempo\n",
    "- **warnings**: Controle de mensagens de aviso\n",
    "- **mlflow**: Rastreamento de experimentos e métricas\n",
    "- **tqdm**: Barras de progresso para processos iterativos\n",
    "- **pandas, numpy**: Manipulação e análise de dados\n",
    "- **typing**: Anotações de tipo para melhor documentação do código\n",
    "- **openai**: Cliente para API de LLM\n",
    "- **dateutil.relativedelta**: Cálculos avançados de datas\n",
    "- **pyspark.sql**: Componentes do Spark SQL\n",
    "- **databricks.feature_store**: Cliente para Feature Store do Databricks\n",
    "\n",
    "**Configurações Realizadas:**\n",
    "- Desativa a exibição automática do MLflow no notebook com `mlflow.tracing.disable_notebook_display()`\n",
    "\n",
    "**Variáveis/Objetos Criados:**\n",
    "- Não cria variáveis persistentes além das importações\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- Prepara o ambiente de execução com todas as dependências necessárias\n",
    "- Desativa logs automáticos do MLflow que poderiam sobrecarregar a interface do notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d153a2a-7b35-4e97-8984-702743e44761",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "import mlflow\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Any\n",
    "import openai\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "from databricks.feature_store import FeatureStoreClient\n",
    "\n",
    "mlflow.tracing.disable_notebook_display()\n",
    "\n",
    "# spark = SparkSession.builder.appName(\"LLM_Extractor\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cb47a20-c5bf-4b5f-b3d7-d9f91db72d58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Definição de tabelas e filtros para extração de dados\n",
    "**Objetivo da Célula:** Configurar as variáveis de tabela de destino e definir os filtros SQL para seleção de dados recentes e relevantes.\n",
    "\n",
    "**Variáveis/Objetos Criados:**\n",
    "- `table_anatom`: String com o nome completo da tabela de destino (refined.saude_preventiva.fleury_laudos_mama_anatomia_patologica_v2)\n",
    "- `where_clause`: String contendo cláusula SQL WHERE para selecionar apenas registros novos (com datestamp maior que o último processado)\n",
    "- `filtro_extracao`: String contendo filtros para seleção de registros específicos de mama feminina\n",
    "\n",
    "**Lógica Detalhada:**\n",
    "- Define a tabela de destino para resultados de anatomia patológica\n",
    "- Cria uma cláusula WHERE que seleciona apenas registros mais recentes que o último datestamp na tabela de destino (processamento incremental)\n",
    "- Define filtros para extração que limitam os registros aos laudos:\n",
    "  - Da linha de cuidado \"mama\"\n",
    "  - De pacientes do sexo feminino (UPPER(sexo_cliente) = 'F')\n",
    "  - Com siglas de exames específicas (ANATPATP, CTPUNC, FISHHER)\n",
    "  - Contendo a expressão \"Topografia: mama\" no texto do laudo\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- As variáveis definidas serão utilizadas posteriormente na consulta SQL para extrair dados relevantes de laudos de anatomia patológica mamária\n",
    "- A abordagem de filtro por datestamp garante processamento incremental, evitando reprocessamento de registros já analisados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "282cf43f-caf5-4db4-9e07-c4862f93bf81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# filtros de extração\n",
    "table_anatom = \"refined.saude_preventiva.fleury_laudos_mama_anatomia_patologica_v2\" \n",
    "\n",
    "where_clause = f\"\"\"\n",
    "WHERE\n",
    "    flr.`_datestamp` >= (\n",
    "        SELECT MAX(anatom._datestamp)\n",
    "        FROM {table_anatom} anatom\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    " \n",
    "filtro_extracao = \"\"\"\n",
    "    WHERE\n",
    "        linha_cuidado  = 'mama'\n",
    "        AND UPPER(sexo_cliente) = 'F'\n",
    "        AND sigla_exame IN (\"ANATPATP\", \"CTPUNC\", \"FISHHER\")\n",
    "        AND laudo_tratado RLIKE '(?i)Topografia: mama'\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "497f2353-7da7-49dc-a5f7-6614e6a1ccfa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Construção e execução da consulta SQL\n",
    "**Objetivo da Célula:** Criar uma consulta SQL para extrair laudos relevantes e executá-la para obter os dados a serem processados pelo modelo LLM.\n",
    "\n",
    "**Variáveis/Objetos Criados:**\n",
    "- `query`: String contendo a consulta SQL completa com placeholders para os filtros definidos anteriormente\n",
    "- `df_spk`: DataFrame Spark resultante da execução da consulta\n",
    "\n",
    "**Lógica Detalhada:**\n",
    "1. Define uma consulta SQL com Common Table Expression (CTE) chamada `base`\n",
    "2. Seleciona campos relevantes dos laudos: identificadores, datas, informações do exame e o conteúdo do laudo\n",
    "3. Aplica os filtros definidos anteriormente:\n",
    "   - Processamento incremental via `where_clause` (registros mais recentes que o último processado)\n",
    "   - Filtros específicos de mama via `filtro_extracao` (linha de cuidado, sexo, siglas de exame, conteúdo do laudo)\n",
    "4. Executa a consulta usando `spark.sql()`, formatando a string para incluir os filtros\n",
    "5. Exibe o resultado via `display(df_spk)`\n",
    "\n",
    "**Tabelas/Colunas Utilizadas:**\n",
    "- Tabela: `refined.saude_preventiva.fleury_laudos` (alias `flr`)\n",
    "- Colunas principais:\n",
    "  - Identificadores: `id_marca`, `id_unidade`, `id_cliente`, `id_ficha`, `ficha`, `id_item`, `id_subitem`, `id_exame`\n",
    "  - Datas: `dth_pedido`, `dth_resultado`\n",
    "  - Dados do exame: `sigla_exame`, `laudo_tratado`, `linha_cuidado`, `sexo_cliente`\n",
    "  - Metadata: `_datestamp`\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- Cria o DataFrame `df_spk` contendo os laudos de anatomia patológica mamária que serão processados\n",
    "- Exibe o conteúdo do DataFrame na interface do notebook para visualização prévia dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc7e7385-7c63-4d51-aa27-506703e0fde8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "WITH \n",
    "base AS (\n",
    "    SELECT\n",
    "        flr.id_marca,\n",
    "        flr.id_unidade,\n",
    "        flr.id_cliente, \n",
    "        flr.id_ficha,\n",
    "        flr.ficha,\n",
    "        flr.id_item, \n",
    "        flr.id_subitem, \n",
    "        flr.id_exame, \n",
    "        flr.dth_pedido,\n",
    "        flr.dth_resultado,\n",
    "        flr.sigla_exame,\n",
    "        flr.laudo_tratado,\n",
    "        flr.linha_cuidado,\n",
    "        flr.sexo_cliente,\n",
    "        flr.`_datestamp`\n",
    "    FROM refined.saude_preventiva.fleury_laudos flr \n",
    "    {where_clause} \n",
    "     \n",
    ")\n",
    "SELECT *\n",
    "FROM base\n",
    "{filtro_extracao}\n",
    "\"\"\"\n",
    "df_spk = spark.sql(query)\n",
    "display(df_spk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32b898c1-68d8-4e1a-8b2d-63d911d11b42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Obtenção do token de acesso Databricks\n",
    "**Objetivo da Célula:** Obter o token de autenticação do Databricks para ser utilizado nas chamadas à API do LLM.\n",
    "\n",
    "**Variáveis/Objetos Criados:**\n",
    "- `DATABRICKS_TOKEN`: Token de autenticação para acesso às APIs Databricks\n",
    "\n",
    "**Lógica Detalhada:**\n",
    "- Utiliza a API interna do Databricks para obter o token da sessão atual\n",
    "- A construção condicional verifica se o contexto do notebook está disponível\n",
    "- Se o contexto existir, obtém o token via API\n",
    "- Se não existir, define o token como None\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- O token será utilizado posteriormente para autenticar as chamadas ao serviço de LLM do Databricks\n",
    "- Este método de obtenção de token é mais seguro que armazenar o token diretamente no código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d44a188c-4a7d-4849-874a-939fa7eb40e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DATABRICKS_TOKEN = (\n",
    "    dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "    if dbutils.notebook.entry_point.getDbutils().notebook().getContext() is not None\n",
    "    else None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1a05a40-96c4-4352-af9f-09f8093f6687",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Definição do prompt para extração de informações via LLM\n",
    "**Objetivo da Célula:** Criar uma função que gera o prompt especializado para extração de informações de laudos médicos através de um modelo de linguagem.\n",
    "\n",
    "**Função Definida:**\n",
    "- `prompt_laudo(laudo_texto: str) -> str`: Função que recebe o texto do laudo e retorna o prompt formatado\n",
    "\n",
    "**Lógica Detalhada:**\n",
    "1. A função recebe o texto do laudo como parâmetro\n",
    "2. Constrói um prompt estruturado com instruções específicas para o modelo LLM\n",
    "3. O prompt inclui:\n",
    "   - O texto do laudo entre aspas triplas\n",
    "   - Instruções detalhadas sobre quais informações extrair e como formatá-las\n",
    "   - Especificações sobre os descritores de malignidade, graus histológicos, nucleares, etc.\n",
    "   - Formato esperado da saída (dicionário Python)\n",
    "4. Retorna o prompt formatado como uma string\n",
    "\n",
    "**Critérios de Extração no Prompt:**\n",
    "- **Descritores de malignidade**: Lista de termos específicos (carcinoma, invasivo, etc.)\n",
    "- **Grau histológico**: Valor numérico (1, 2 ou 3)\n",
    "- **Grau nuclear**: Valor numérico (1, 2 ou 3)\n",
    "- **Formação de túbulos**: Valor numérico (1, 2 ou 3)\n",
    "- **Índice mitótico**: Valor numérico após \"mm2\"\n",
    "- **Tipo histológico**: Correspondência com uma lista de tipos específicos de carcinomas\n",
    "\n",
    "**Saída Esperada:**\n",
    "- Um dicionário Python com os campos extraídos ou \"NÃO INFORMADO\" quando a informação não está presente\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- Define a função que será utilizada posteriormente para criar prompts personalizados para cada laudo\n",
    "- A qualidade desta formatação de prompt é crucial para a precisão da extração de informações pelo LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad1766c3-c130-4d44-b48f-21440d11f558",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def prompt_laudo_template() -> str:\n",
    "  prompt = \"\"\"A seguir está um laudo médico de mamografia. Se alguma informação não estiver presente no texto, retorne \"NÃO INFORMADO\". Sempre retorne apenas o dicionário Python.\n",
    "\n",
    "  Laudo clínico:\n",
    "  \\\"\\\"\\\"{laudo_texto}\\\"\\\"\\\"\n",
    "\n",
    "  ### Critérios de extração:\n",
    "\n",
    "  - **Descritores de malignidade**: retorne uma **lista** com os termos de malignidade encontrados no texto (case-insensitive). Se nenhum for encontrado, retorne lista vazia `[]`. Lista de termos: ['carcinoma', \"invasivo\", \"invasor\", \"sarcoma\", \"metástase\", \"metastático\", \"maligno\", \"maligna\", \"cdi\", \"cli\", \"cdis\"]\n",
    "\n",
    "  - **Grau histológico**: retorne o valor numérico do grau histológico.\n",
    "\n",
    "  - **Grau nuclear**: retorne o valor numérico do grau nuclear.\n",
    "\n",
    "  - **Formação de túbulos**: retorne o valor numérico caso exista formação de túbulos.\n",
    "\n",
    "  - **Índice mitótico**: retorne o valor numérico do score do índice mitótico que aparece após o mm2.\n",
    "\n",
    "  - **Tipo histológico**: identifique e retorne a frase correspondente se algum dos seguintes for mencionado (case-insensitive, variações aceitas):\n",
    "    - Carcinoma de mama ductal invasivo\n",
    "    - Carcinoma de mama ductal in situ\n",
    "    - Carcinoma de mama lobular invasivo\n",
    "    - Carcinoma de mama lobular\n",
    "    - Carcinoma de mama papilífero\n",
    "    - Carcinoma de mama metaplásico\n",
    "    - Carcinoma de mama mucinoso\n",
    "    - Carcinoma de mama tubular\n",
    "    - Carcinoma de mama cístico adenoide\n",
    "    - Carcinoma de mama medular\n",
    "    - Carcinoma de mama micropapilar\n",
    "    - Carcinoma de mama misto (ductal e lobular) invasivo\n",
    "\n",
    "  ### Saída esperada (dicionário Python válido):\n",
    "  ```python\n",
    "  {{\n",
    "    \"descritores_malignidade\": [\"termo1\", \"termo2\", ...],\n",
    "    \"grau_histologico\": número | \"NÃO INFORMADO\",\n",
    "    \"grau_nuclear\": número | \"NÃO INFORMADO\",\n",
    "    \"formacao_tubulos\": número | \"NÃO INFORMADO\",\n",
    "    \"indice_mitotico\": número | \"NÃO INFORMADO\",\n",
    "    \"tipo_histologico\": \"texto correspondente ou 'NÃO INFORMADO'\"\n",
    "  }}\n",
    "\n",
    "  \"\"\" \n",
    "  return prompt.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a07113c5-ccb2-4b45-b8c2-636d4f3b4a9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Funções para extração por RegEx e validação das respostas do LLM\n",
    "**Objetivo da Célula:** Implementar um conjunto de funções que extraem informações dos laudos usando expressões regulares e comparam com as respostas do LLM.\n",
    "\n",
    "**Funções Definidas:**\n",
    "1. Funções de extração por RegEx:\n",
    "   - `extrai_descritores`: Encontra descritores de malignidade no texto\n",
    "   - `extrai_grau_histologico`: Extrai o grau histológico (1, 2 ou 3)\n",
    "   - `extrai_grau_nuclear`: Extrai o grau nuclear (1, 2 ou 3)\n",
    "   - `extrai_formacao_tubulos`: Extrai o valor de formação de túbulos (1, 2 ou 3)\n",
    "   - `extrai_indice_mitotico`: Extrai o índice mitótico\n",
    "   - `extrai_tipo_histologico`: Identifica o tipo histológico específico\n",
    "\n",
    "2. Função de avaliação:\n",
    "   - `avalia_extracao_sem_ground_truth`: Compara a extração do LLM com a extração por RegEx\n",
    "\n",
    "**Lógica Detalhada:**\n",
    "- `extrai_descritores`: Procura por cada termo da lista TERMS no texto usando regex case-insensitive\n",
    "- `extrai_grau_histologico`, `extrai_grau_nuclear`, `extrai_formacao_tubulos`: Procuram por padrões específicos seguidos de um dígito\n",
    "- `extrai_indice_mitotico`: Procura por um valor numérico próximo ao termo \"mm2\" ou \"mitoses\"\n",
    "- `extrai_tipo_histologico`: Compara o texto com uma lista predefinida de tipos histológicos\n",
    "- `avalia_extracao_sem_ground_truth`: \n",
    "  1. Gera um pseudo-gold standard usando as funções de extração por RegEx\n",
    "  2. Compara campo a campo com as extrações do LLM\n",
    "  3. Retorna um relatório detalhado de concordância\n",
    "\n",
    "**Constantes Definidas:**\n",
    "- `TERMS`: Lista de termos associados a malignidade\n",
    "- `TIPOS`: Lista de padrões de tipos histológicos a serem buscados\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- As funções serão utilizadas para avaliar a qualidade das extrações do modelo LLM\n",
    "- A avaliação usa as extrações por RegEx como pseudo-gold standard\n",
    "- Os resultados da comparação serão utilizados para métricas e monitoramento do desempenho do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9558e288-0a6e-4891-b378-a8223fe42245",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "TERMS = ['carcinoma', 'invasivo', 'invasor', 'sarcoma', \n",
    "         'metástase', 'metastático', 'maligno', 'maligna', \n",
    "         'cdi', 'cli', 'cdis']\n",
    "\n",
    "def extrai_descritores(txt):\n",
    "    achados = set()\n",
    "    for termo in TERMS:\n",
    "        # insensível a maiúsculas e minúsculas, plenos caracteres\n",
    "        if re.search(rf\"\\b{re.escape(termo)}\\b\", txt, flags=re.IGNORECASE):\n",
    "            achados.add(termo.lower())\n",
    "    return sorted(achados)  # lista em ordem alfabética\n",
    "\n",
    "def extrai_grau_histologico(txt):\n",
    "    # Captura algo como \"Grau histológico: 2\" ou \"grau histológico 2\"\n",
    "    m = re.search(r\"grau\\s+histol[oó]gico\\s*[:\\-]?\\s*(\\d)\", txt, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        return int(m.group(1))\n",
    "    return None\n",
    "\n",
    "def extrai_grau_nuclear(txt):\n",
    "    m = re.search(r\"grau\\s+nuclear\\s*[:\\-]?\\s*(\\d)\", txt, flags=re.IGNORECASE)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def extrai_formacao_tubulos(txt):\n",
    "    m = re.search(r\"forma[cç][aã]o\\s+de\\s+t[uú]bulos\\s*[:\\-]?\\s*(\\d)\", txt, flags=re.IGNORECASE)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "# def extrai_indice_mitotico(txt):\n",
    "#     # Ex.: \"índice mitótico 3/10 mm2\" ou \"mitótico: 2 mm2\"\n",
    "#     m = re.search(r\"mit[oó]tico\\s*[:\\-]?\\s*(\\d+)\\s*/?\\s*\\d*\\s*mm2\", txt, flags=re.IGNORECASE)\n",
    "#     if m:\n",
    "#         return int(m.group(1))\n",
    "#     return None\n",
    "\n",
    "def extrai_indice_mitotico(txt):\n",
    "    # Ex.: \"índice mitótico 3/10 mm2\", \"mitótico: 2 mm2\", \"Índice mitótico: 1 mitose / mm2\", \"Índice mitótico: 11 mitoses / mm2\"\n",
    "    m = re.search(r\"mit[oó]tico\\s*[:\\-]?\\s*(\\d+)(?:\\s*/\\s*\\d+)?\\s*(?:mitoses?|mitose)?\\s*/?\\s*mm2\", txt, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        return int(m.group(1))\n",
    "    return None\n",
    "\n",
    "TIPOS = [\n",
    "  \"carcinoma de mama ductal invasivo\",\n",
    "  \"carcinoma de mama ductal in situ\",\n",
    "  \"carcinoma de mama lobular invasivo\",\n",
    "  \"carcinoma de mama lobular\",\n",
    "  \"carcinoma de mama papilífero\",\n",
    "  \"carcinoma de mama metapl[aá]sico\",\n",
    "  \"carcinoma de mama mucinoso\",\n",
    "  \"carcinoma de mama tubular\",\n",
    "  \"carcinoma de mama c[ií]stico adenoide\",\n",
    "  \"carcinoma de mama medular\",\n",
    "  \"carcinoma de mama micropapilar\",\n",
    "  \"carcinoma de mama misto (ductal e lobular) invasivo\"\n",
    "]\n",
    "\n",
    "def extrai_tipo_histologico(txt):\n",
    "    txt_lower = txt.lower()\n",
    "    for tipo in TIPOS:\n",
    "        # usar comparação simplificada, removendo acentos se quiser\n",
    "        padrao = tipo.lower()\n",
    "        if padrao in txt_lower:\n",
    "            return tipo  # retorna exatamente a frase padronizada\n",
    "    return None\n",
    "\n",
    "def avalia_extracao_sem_ground_truth(laudo_texto, json_modelo):\n",
    "    # 1. Gera pseudo-gold\n",
    "    descrs_hei = extrai_descritores(laudo_texto)\n",
    "    gr_hist_hei = extrai_grau_histologico(laudo_texto)\n",
    "    gr_nuc_hei  = extrai_grau_nuclear(laudo_texto)\n",
    "    form_tub_hei= extrai_formacao_tubulos(laudo_texto)\n",
    "    ind_mit_hei = extrai_indice_mitotico(laudo_texto)\n",
    "    tipo_histo_hei = extrai_tipo_histologico(laudo_texto)\n",
    "\n",
    "    json_heu = {\n",
    "        \"descritores_malignidade\": descrs_hei,\n",
    "        \"grau_histologico\": gr_hist_hei if gr_hist_hei is not None else \"NÃO INFORMADO\",\n",
    "        \"grau_nuclear\": gr_nuc_hei if gr_nuc_hei is not None else \"NÃO INFORMADO\",\n",
    "        \"formacao_tubulos\": form_tub_hei if form_tub_hei is not None else \"NÃO INFORMADO\",\n",
    "        \"indice_mitotico\": ind_mit_hei if ind_mit_hei is not None else \"NÃO INFORMADO\",\n",
    "        \"tipo_histologico\": tipo_histo_hei if tipo_histo_hei is not None else \"NÃO INFORMADO\"\n",
    "    }\n",
    "\n",
    "    # 2. Prepara json_modelo – já é recebido do ChatGPT como dicionário Python\n",
    "\n",
    "    # 3. Comparações campo a campo:\n",
    "    comparacoes = {}\n",
    "\n",
    "    # 3.1. Descritores de malignidade: compara igualdade exata (acertos ou não)\n",
    "    val_heu_desc = set(json_heu[\"descritores_malignidade\"])\n",
    "    val_mod_desc = set(json_modelo.get(\"descritores_malignidade\", []))\n",
    "    acertou_desc = (val_heu_desc == val_mod_desc)\n",
    "    comparacoes[\"descritores_malignidade\"] = {\n",
    "        \"pseudo_gold\": json_heu[\"descritores_malignidade\"],\n",
    "        \"IA\": json_modelo.get(\"descritores_malignidade\", []),\n",
    "        \"acertou\": acertou_desc\n",
    "    }\n",
    "\n",
    "    # 3.2. Para cada campo numérico ou de texto, basta verificar igualdade exata\n",
    "    def compara_campo(nome):\n",
    "        val_heu = json_heu[nome]\n",
    "        val_mod = json_modelo.get(nome, \"NÃO INFORMADO\")\n",
    "        acertou = (val_heu == val_mod)\n",
    "        return {\n",
    "            \"pseudo_gold\": val_heu,\n",
    "            \"IA\": val_mod,\n",
    "            \"acertou\": acertou\n",
    "        }\n",
    "\n",
    "    for campo in [\"grau_histologico\", \"grau_nuclear\", \"formacao_tubulos\", \"indice_mitotico\", \"tipo_histologico\"]:\n",
    "        comparacoes[campo] = compara_campo(campo)\n",
    "\n",
    "    return json_heu, comparacoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6535eb59-e3ef-4f4b-991d-e3c7a00d80fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Função para agregação e análise de resultados\n",
    "**Objetivo da Célula:** Implementar uma função que agrega os resultados das comparações entre LLM e regex para calcular métricas de precisão.\n",
    "\n",
    "**Função Definida:**\n",
    "- `agrega_resultados(lista_comparacoes)`: Calcula estatísticas agregadas sobre a precisão da extração por campo\n",
    "\n",
    "**Lógica Detalhada:**\n",
    "1. Recebe uma lista de resultados de comparações (geradas pela função `avalia_extracao_sem_ground_truth`)\n",
    "2. Calcula para cada campo de interesse:\n",
    "   - Número total de acertos\n",
    "   - Taxa de acerto (acertos ÷ total)\n",
    "3. Estrutura os resultados em um dicionário aninhado por campo\n",
    "4. Usa um `Counter` para facilitar a contagem de acertos por campo\n",
    "\n",
    "**Campos Analisados:**\n",
    "- `descritores_malignidade`: Acurácia na extração da lista de termos de malignidade\n",
    "- `grau_histologico`: Acurácia na extração do grau histológico\n",
    "- `grau_nuclear`: Acurácia na extração do grau nuclear\n",
    "- `formacao_tubulos`: Acurácia na extração dos valores de formação de túbulos\n",
    "- `indice_mitotico`: Acurácia na extração do índice mitótico\n",
    "- `tipo_histologico`: Acurácia na extração do tipo histológico\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- Retorna um dicionário estruturado com estatísticas detalhadas sobre a precisão da extração\n",
    "- Este dicionário será utilizado para registro de métricas no MLflow e para avaliação da qualidade do modelo\n",
    "- As taxas de acerto servirão para determinar se o modelo atende ao threshold de qualidade estabelecido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbc519ce-6e02-4c05-b7ce-06716348b51b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def agrega_resultados(lista_comparacoes):\n",
    "    total_laudos = len(lista_comparacoes)\n",
    "    \n",
    "    # Conta quantos acertos em descritores_malignidade\n",
    "    acertos_descritores = 0\n",
    "    \n",
    "    # Conta acertos por campo numérico/textual\n",
    "    acertos_campos = Counter()\n",
    "    \n",
    "    for comp in lista_comparacoes:\n",
    "        # Para descritores_malignidade, só existe \"acertou\"\n",
    "        if comp[\"descritores_malignidade\"][\"acertou\"]:\n",
    "            acertos_descritores += 1\n",
    "        \n",
    "        # Para cada campo numérico/textual\n",
    "        for campo in [\n",
    "            \"grau_histologico\", \n",
    "            \"grau_nuclear\", \n",
    "            \"formacao_tubulos\", \n",
    "            \"indice_mitotico\", \n",
    "            \"tipo_histologico\"\n",
    "        ]:\n",
    "            if comp[campo][\"acertou\"]:\n",
    "                acertos_campos[campo] += 1\n",
    "\n",
    "    resultado = {\n",
    "        \"descritores_malignidade\": {\n",
    "            \"acertos\": acertos_descritores,\n",
    "            \"total\": total_laudos,\n",
    "            \"taxa_acerto\": acertos_descritores / total_laudos if total_laudos > 0 else 0.0\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for campo in [\n",
    "        \"grau_histologico\", \n",
    "        \"grau_nuclear\", \n",
    "        \"formacao_tubulos\", \n",
    "        \"indice_mitotico\", \n",
    "        \"tipo_histologico\"\n",
    "    ]:\n",
    "        acertou = acertos_campos[campo]\n",
    "        resultado[campo] = {\n",
    "            \"acertos\": acertou,\n",
    "            \"total\": total_laudos,\n",
    "            \"taxa_acerto\": acertou / total_laudos if total_laudos > 0 else 0.0\n",
    "        }\n",
    "\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a79c95f9-474a-49c4-adc1-2465c5936ec5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Processamento e avaliação dos laudos com o modelo LLM\n",
    "**Objetivo da Célula:** Processar os laudos extraídos utilizando o modelo LLM, avaliar a qualidade das extrações e preparar os dados para persistência.\n",
    "\n",
    "**Dependências:**\n",
    "- DataFrames e funções definidas anteriormente\n",
    "- Token de autenticação Databricks\n",
    "- Cliente OpenAI configurado\n",
    "\n",
    "**Lógica Detalhada:**\n",
    "1. Verifica se há dados disponíveis para processamento (`df_spk.count() > 0`)\n",
    "2. Inicializa o cliente OpenAI com o token Databricks e configuração do endpoint\n",
    "3. Define o contexto do agente LLM como \"médico oncologista especialista em laudos de mamografia\"\n",
    "4. Converte o DataFrame Spark para Pandas para processamento local (limitado a 15 registros para teste)\n",
    "5. Processa os laudos em batch utilizando a função `batch_generate`\n",
    "6. Limpa e converte as respostas do LLM para formato estruturado utilizando `limpar_e_converter`\n",
    "7. Avalia a qualidade das extrações comparando com extrações via RegEx\n",
    "8. Calcula métricas agregadas de precisão\n",
    "\n",
    "**Variáveis/Objetos Criados:**\n",
    "- `llm_client`: Cliente para comunicação com a API do LLM\n",
    "- `descricao_agente`: Descrição do papel do LLM na análise\n",
    "- `df_local`: DataFrame Pandas para processamento local\n",
    "- `df_respostas`: DataFrame Spark com as respostas processadas\n",
    "- `resultados`: Lista de comparações entre extrações via LLM e RegEx\n",
    "- `json_metricas`: Estatísticas agregadas sobre a qualidade da extração\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- Cria um DataFrame enriquecido com as informações extraídas dos laudos\n",
    "- Exibe o DataFrame processado via `display(df_respostas)`\n",
    "- Prepara os dados para registro de métricas no MLflow e persistência em tabela Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc36e651-8311-45a8-b7df-08f25a5f4c20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# CORREÇÃO -=========================\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType, IntegerType, BooleanType\n",
    "from pyspark.sql.functions import from_json, col, expr, regexp_replace, lit, regexp_extract, coalesce, udf, when, size, array_sort\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "# Iniciar sessão Spark\n",
    "spark = SparkSession.builder.appName(\"DfPandasparaSpark\").getOrCreate()\n",
    "\n",
    "# Definir modelo Foundation Model\n",
    "model = \"databricks-llama-4-maverick\"  # Ajustar conforme o modelo disponível\n",
    "\n",
    "# Schema para o JSON de saída do LLM\n",
    "llm_output_schema = StructType([\n",
    "StructField(\"descritores_malignidade\", ArrayType(StringType()), True),\n",
    "StructField(\"grau_histologico\", StringType(), True),\n",
    "StructField(\"grau_nuclear\", StringType(), True),\n",
    "StructField(\"formacao_tubulos\", StringType(), True),\n",
    "StructField(\"indice_mitotico\", StringType(), True),\n",
    "StructField(\"tipo_histologico\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Criar UDFs para as funções heurísticas\n",
    "@udf(ArrayType(StringType()))\n",
    "def udf_extrai_descritores(txt):\n",
    "    if txt is None:\n",
    "        return []\n",
    "    return extrai_descritores(txt)\n",
    "\n",
    "@udf(StringType())\n",
    "def udf_extrai_grau_histologico(txt):\n",
    "    if txt is None:\n",
    "        return \"NÃO INFORMADO\"\n",
    "    resultado = extrai_grau_histologico(txt)\n",
    "    return str(resultado) if resultado is not None else \"NÃO INFORMADO\"\n",
    "\n",
    "@udf(StringType())\n",
    "def udf_extrai_grau_nuclear(txt):\n",
    "    if txt is None:\n",
    "        return \"NÃO INFORMADO\"\n",
    "    resultado = extrai_grau_nuclear(txt)\n",
    "    return str(resultado) if resultado is not None else \"NÃO INFORMADO\"\n",
    "\n",
    "@udf(StringType())\n",
    "def udf_extrai_formacao_tubulos(txt):\n",
    "    if txt is None:\n",
    "        return \"NÃO INFORMADO\"\n",
    "    resultado = extrai_formacao_tubulos(txt)\n",
    "    return str(resultado) if resultado is not None else \"NÃO INFORMADO\"\n",
    "\n",
    "@udf(StringType())\n",
    "def udf_extrai_indice_mitotico(txt):\n",
    "    if txt is None:\n",
    "        return \"NÃO INFORMADO\"\n",
    "    resultado = extrai_indice_mitotico(txt)\n",
    "    return str(resultado) if resultado is not None else \"NÃO INFORMADO\"\n",
    "\n",
    "@udf(StringType())\n",
    "def udf_extrai_tipo_histologico(txt):\n",
    "    if txt is None:\n",
    "        return \"NÃO INFORMADO\"\n",
    "    resultado = extrai_tipo_histologico(txt)\n",
    "    return resultado if resultado is not None else \"NÃO INFORMADO\"\n",
    "\n",
    "# Realizar extração\n",
    "if df_spk.count() > 0:\n",
    "\n",
    "    # Obter o template do prompt\n",
    "    prompt_template = prompt_laudo_template()\n",
    "\n",
    "    # 1. Criar prompts dinâmicos injetando cada laudo no template\n",
    "    df_with_prompts = df_spk.withColumn(\n",
    "        \"prompt_formatado\",\n",
    "        regexp_replace(\n",
    "            lit(prompt_template),\n",
    "            r\"\\{laudo_texto\\}\",\n",
    "            col(\"laudo_tratado\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 2. Enviar prompts para o modelo Foundation Model usando ai_query\n",
    "    df_with_llm_response = df_with_prompts.withColumn(\n",
    "        \"resposta_llm_raw\",\n",
    "        expr(f\"ai_query('{model}', prompt_formatado)\")\n",
    "    )\n",
    "\n",
    "    # 3. Limpar e extrair JSON da resposta\n",
    "    df_with_cleaned_response = df_with_llm_response.withColumn(\n",
    "        \"resposta_llm_limpa\",\n",
    "        regexp_replace(\n",
    "            regexp_replace(col(\"resposta_llm_raw\"), \"```python\", \"\"),\n",
    "            \"```\", \"\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 4. Parsear o JSON\n",
    "    df_with_parsed_response = df_with_cleaned_response.withColumn(\n",
    "        \"resposta_llm_json\",\n",
    "        from_json(\n",
    "            regexp_extract(col(\"resposta_llm_limpa\"), r'(\\{[^}]+\\})', 1),\n",
    "            llm_output_schema\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 5. Expandir os campos do JSON (resultados do LLM)\n",
    "    df_with_llm_fields = df_with_parsed_response.withColumn(\n",
    "        \"llm_descritores_malignidade\",\n",
    "        coalesce(col(\"resposta_llm_json.descritores_malignidade\"), expr(\"array()\"))\n",
    "    ).withColumn(\n",
    "        \"llm_grau_histologico\",\n",
    "        coalesce(col(\"resposta_llm_json.grau_histologico\"), lit(\"NÃO INFORMADO\"))\n",
    "    ).withColumn(\n",
    "        \"llm_grau_nuclear\",\n",
    "        coalesce(col(\"resposta_llm_json.grau_nuclear\"), lit(\"NÃO INFORMADO\"))\n",
    "    ).withColumn(\n",
    "        \"llm_formacao_tubulos\",\n",
    "        coalesce(col(\"resposta_llm_json.formacao_tubulos\"), lit(\"NÃO INFORMADO\"))\n",
    "    ).withColumn(\n",
    "        \"llm_indice_mitotico\",\n",
    "        coalesce(col(\"resposta_llm_json.indice_mitotico\"), lit(\"NÃO INFORMADO\"))\n",
    "    ).withColumn(\n",
    "        \"llm_tipo_histologico\",\n",
    "        coalesce(col(\"resposta_llm_json.tipo_histologico\"), lit(\"NÃO INFORMADO\"))\n",
    "    )\n",
    "\n",
    "    # 6. Aplicar funções heurísticas (pseudo-gold)\n",
    "    df_with_heuristics = df_with_llm_fields.withColumn(\n",
    "        \"heu_descritores_malignidade\",\n",
    "        udf_extrai_descritores(col(\"laudo_tratado\"))\n",
    "    ).withColumn(\n",
    "        \"heu_grau_histologico\",\n",
    "        udf_extrai_grau_histologico(col(\"laudo_tratado\"))\n",
    "    ).withColumn(\n",
    "        \"heu_grau_nuclear\",\n",
    "        udf_extrai_grau_nuclear(col(\"laudo_tratado\"))\n",
    "    ).withColumn(\n",
    "        \"heu_formacao_tubulos\",\n",
    "        udf_extrai_formacao_tubulos(col(\"laudo_tratado\"))\n",
    "    ).withColumn(\n",
    "        \"heu_indice_mitotico\",\n",
    "        udf_extrai_indice_mitotico(col(\"laudo_tratado\"))\n",
    "    ).withColumn(\n",
    "        \"heu_tipo_histologico\",\n",
    "        udf_extrai_tipo_histologico(col(\"laudo_tratado\"))\n",
    "    )\n",
    "\n",
    "    # 7. Criar colunas de comparação (acertos)\n",
    "    df_with_comparisons = df_with_heuristics.withColumn(\n",
    "        \"acertou_descritores\",\n",
    "        (array_sort(col(\"heu_descritores_malignidade\")) == array_sort(col(\"llm_descritores_malignidade\")))\n",
    "    ).withColumn(\n",
    "        \"acertou_grau_histologico\",\n",
    "        (col(\"heu_grau_histologico\") == col(\"llm_grau_histologico\"))\n",
    "    ).withColumn(\n",
    "        \"acertou_grau_nuclear\",\n",
    "        (col(\"heu_grau_nuclear\") == col(\"llm_grau_nuclear\"))\n",
    "    ).withColumn(\n",
    "        \"acertou_formacao_tubulos\",\n",
    "        (col(\"heu_formacao_tubulos\") == col(\"llm_formacao_tubulos\"))\n",
    "    ).withColumn(\n",
    "        \"acertou_indice_mitotico\",\n",
    "        (col(\"heu_indice_mitotico\") == col(\"llm_indice_mitotico\"))\n",
    "    ).withColumn(\n",
    "        \"acertou_tipo_histologico\",\n",
    "        (col(\"heu_tipo_histologico\") == col(\"llm_tipo_histologico\"))\n",
    "    )\n",
    "\n",
    "    # 8. Selecionar colunas finais\n",
    "    df_respostas = df_with_comparisons.select(\n",
    "        \"id_marca\", \"id_unidade\", \"id_cliente\", \"id_ficha\", \"ficha\", \n",
    "        \"id_item\", \"id_subitem\", \"id_exame\", \"sigla_exame\", \n",
    "        \"dth_pedido\", \"dth_resultado\", \"_datestamp\", \n",
    "        \"laudo_tratado\", \"linha_cuidado\",\n",
    "        \"resposta_llm_raw\",\n",
    "        # Campos LLM\n",
    "        col(\"llm_descritores_malignidade\").alias(\"descritores_malignidade\"),\n",
    "        col(\"llm_grau_histologico\").alias(\"grau_histologico\"),\n",
    "        col(\"llm_grau_nuclear\").alias(\"grau_nuclear\"),\n",
    "        col(\"llm_formacao_tubulos\").alias(\"formacao_tubulos\"),\n",
    "        col(\"llm_indice_mitotico\").alias(\"indice_mitotico\"),\n",
    "        col(\"llm_tipo_histologico\").alias(\"tipo_histologico\"),\n",
    "        # Campos Heurísticos (pseudo-gold)\n",
    "        \"heu_descritores_malignidade\",\n",
    "        \"heu_grau_histologico\",\n",
    "        \"heu_grau_nuclear\",\n",
    "        \"heu_formacao_tubulos\",\n",
    "        \"heu_indice_mitotico\",\n",
    "        \"heu_tipo_histologico\",\n",
    "        # Campos de Comparação\n",
    "        \"acertou_descritores\",\n",
    "        \"acertou_grau_histologico\",\n",
    "        \"acertou_grau_nuclear\",\n",
    "        \"acertou_formacao_tubulos\",\n",
    "        \"acertou_indice_mitotico\",\n",
    "        \"acertou_tipo_histologico\"\n",
    "    )\n",
    "\n",
    "    display(df_respostas)\n",
    "\n",
    "    # Definição de métricas regex vs llm\n",
    "    lista_laudos = df_respostas.collect()\n",
    "    resultados = []\n",
    "    for row in lista_laudos:\n",
    "        laudo_txt = row[\"laudo_tratado\"]\n",
    "        json_mod = {\n",
    "            \"descritores_malignidade\": row[\"descritores_malignidade\"] if row[\"descritores_malignidade\"] else [],\n",
    "            \"grau_histologico\": row[\"grau_histologico\"],\n",
    "            \"grau_nuclear\": row[\"grau_nuclear\"],\n",
    "            \"formacao_tubulos\": row[\"formacao_tubulos\"],\n",
    "            \"indice_mitotico\": row[\"indice_mitotico\"],\n",
    "            \"tipo_histologico\": row[\"tipo_histologico\"]\n",
    "        }\n",
    "        pseudo_gold, compar = avalia_extracao_sem_ground_truth(laudo_txt, json_mod)\n",
    "        resultados.append(compar)\n",
    "\n",
    "    df_metrics = pd.DataFrame()\n",
    "    df_metrics[\"laudos\"] = df_respostas.select(\"laudo_tratado\").toPandas()[\"laudo_tratado\"]\n",
    "    df_metrics[\"resultados\"] = resultados\n",
    "    resultados_expandidos = pd.json_normalize(df_metrics[\"resultados\"])\n",
    "    df_metrics = pd.concat(\n",
    "        [df_metrics.drop(columns=[\"resultados\"]), resultados_expandidos],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    json_metricas = agrega_resultados(resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8f72376-0f92-4659-80cd-23973f674d5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.types import StructType, StructField, StringType, ArrayType, IntegerType\n",
    "# from pyspark.sql.functions import from_json, col, expr, regexp_replace, lit, regexp_extract, coalesce\n",
    "# from pyspark.sql import SparkSession\n",
    "# import pandas as pd\n",
    "# import mlflow\n",
    "\n",
    "# # Iniciar sessão Spark\n",
    "# spark = SparkSession.builder.appName(\"DfPandasparaSpark\").getOrCreate()\n",
    "\n",
    "# # Definir modelo Foundation Model\n",
    "# model = \"databricks-llama-4-maverick\"  # Ajustar conforme o modelo disponível\n",
    "\n",
    "# # Schema para o JSON de saída do LLM\n",
    "# llm_output_schema = StructType([\n",
    "# StructField(\"descritores_malignidade\", ArrayType(StringType()), True),\n",
    "# StructField(\"grau_histologico\", StringType(), True),\n",
    "# StructField(\"grau_nuclear\", StringType(), True),\n",
    "# StructField(\"formacao_tubulos\", StringType(), True),\n",
    "# StructField(\"indice_mitotico\", StringType(), True),\n",
    "# StructField(\"tipo_histologico\", StringType(), True)\n",
    "# ])\n",
    "\n",
    "# # Realizar extração\n",
    "# if df_spk.count() > 0:\n",
    "\n",
    "#     # Obter o template do prompt\n",
    "#     prompt_template = prompt_laudo_template()\n",
    "\n",
    "#     # 1. Criar prompts dinâmicos injetando cada laudo no template\n",
    "#     df_with_prompts = df_spk.withColumn(\n",
    "#         \"prompt_formatado\",\n",
    "#         regexp_replace(\n",
    "#             lit(prompt_template),\n",
    "#             r\"\\{laudo_texto\\}\",\n",
    "#             col(\"laudo_tratado\")\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "#     # 2. Enviar prompts para o modelo Foundation Model usando ai_query\n",
    "#     df_with_llm_response = df_with_prompts.withColumn(\n",
    "#         \"resposta_llm_raw\",\n",
    "#         expr(f\"ai_query('{model}', prompt_formatado)\")\n",
    "#     )\n",
    "\n",
    "#     # 3. Limpar e extrair JSON da resposta\n",
    "#     df_with_cleaned_response = df_with_llm_response.withColumn(\n",
    "#         \"resposta_llm_limpa\",\n",
    "#         regexp_replace(\n",
    "#             regexp_replace(col(\"resposta_llm_raw\"), \"```python\", \"\"),\n",
    "#             \"```\", \"\"\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "#     # 4. Parsear o JSON\n",
    "#     df_with_parsed_response = df_with_cleaned_response.withColumn(\n",
    "#         \"resposta_llm_json\",\n",
    "#         from_json(\n",
    "#             regexp_extract(col(\"resposta_llm_limpa\"), r'(\\{[^}]+\\})', 1),\n",
    "#             llm_output_schema\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "#     # 5. Expandir os campos do JSON\n",
    "#     df_respostas = df_with_parsed_response.select(\n",
    "#         \"id_marca\", \"id_unidade\", \"id_cliente\", \"id_ficha\", \"ficha\", \n",
    "#         \"id_item\", \"id_subitem\", \"id_exame\", \"sigla_exame\", \n",
    "#         \"dth_pedido\", \"dth_resultado\", \"_datestamp\", \n",
    "#         \"laudo_tratado\", \"linha_cuidado\",\n",
    "#         \"resposta_llm_raw\",\n",
    "#         coalesce(col(\"resposta_llm_json.descritores_malignidade\"), expr(\"array()\")).alias(\"descritores_malignidade\"),\n",
    "#         coalesce(col(\"resposta_llm_json.grau_histologico\"), lit(\"NÃO INFORMADO\")).alias(\"grau_histologico\"),\n",
    "#         coalesce(col(\"resposta_llm_json.grau_nuclear\"), lit(\"NÃO INFORMADO\")).alias(\"grau_nuclear\"),\n",
    "#         coalesce(col(\"resposta_llm_json.formacao_tubulos\"), lit(\"NÃO INFORMADO\")).alias(\"formacao_tubulos\"),\n",
    "#         coalesce(col(\"resposta_llm_json.indice_mitotico\"), lit(\"NÃO INFORMADO\")).alias(\"indice_mitotico\"),\n",
    "#         coalesce(col(\"resposta_llm_json.tipo_histologico\"), lit(\"NÃO INFORMADO\")).alias(\"tipo_histologico\")\n",
    "#     )\n",
    "\n",
    "#     display(df_respostas)\n",
    "\n",
    "#     # Definição de métricas regex vs llm\n",
    "#     lista_laudos = df_respostas.collect()\n",
    "#     resultados = []\n",
    "#     for row in lista_laudos:\n",
    "#         laudo_txt = row[\"laudo_tratado\"]\n",
    "#         json_mod = {\n",
    "#             \"descritores_malignidade\": row[\"descritores_malignidade\"] if row[\"descritores_malignidade\"] else [],\n",
    "#             \"grau_histologico\": row[\"grau_histologico\"],\n",
    "#             \"grau_nuclear\": row[\"grau_nuclear\"],\n",
    "#             \"formacao_tubulos\": row[\"formacao_tubulos\"],\n",
    "#             \"indice_mitotico\": row[\"indice_mitotico\"],\n",
    "#             \"tipo_histologico\": row[\"tipo_histologico\"]\n",
    "#         }\n",
    "#         pseudo_gold, compar = avalia_extracao_sem_ground_truth(laudo_txt, json_mod)\n",
    "#         resultados.append(compar)\n",
    "\n",
    "#     df_metrics = pd.DataFrame()\n",
    "#     df_metrics[\"laudos\"] = df_respostas.select(\"laudo_tratado\").toPandas()[\"laudo_tratado\"]\n",
    "#     df_metrics[\"resultados\"] = resultados\n",
    "#     resultados_expandidos = pd.json_normalize(df_metrics[\"resultados\"])\n",
    "#     df_metrics = pd.concat(\n",
    "#         [df_metrics.drop(columns=[\"resultados\"]), resultados_expandidos],\n",
    "#         axis=1\n",
    "#     )\n",
    "\n",
    "#     json_metricas = agrega_resultados(resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1808d80a-608e-4f8d-8d0c-3e434e872caf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Registro de métricas e experimentos no MLflow\n",
    "**Objetivo da Célula:** Criar ou recuperar um experimento no MLflow e registrar as métricas de qualidade da extração.\n",
    "\n",
    "**Dependências:**\n",
    "- Variável `json_metricas` com resultados agregados da avaliação\n",
    "- Bibliotecas mlflow e json\n",
    "\n",
    "**Funções Definidas:**\n",
    "- `get_or_create_experiment(experiment_name)`: Obtém ID de experimento existente ou cria um novo\n",
    "\n",
    "**Lógica Detalhada:**\n",
    "1. Define a função `get_or_create_experiment` para encontrar ou criar um experimento MLflow\n",
    "2. Obtém o ID do experimento para saúde preventiva mamária\n",
    "3. Configura o MLflow para registro automático de informações adicionais (`mlflow.autolog()`)\n",
    "4. Define um threshold de qualidade (80%) para avaliar se as extrações são aceitáveis\n",
    "5. Inicia uma nova execução (run) do MLflow\n",
    "6. Para cada campo avaliado, registra:\n",
    "   - Taxa de acerto (métrica principal)\n",
    "   - Flag indicando se passou no threshold\n",
    "   - Contagens absolutas de acertos e total\n",
    "7. Registra o ID da execução para referência futura\n",
    "\n",
    "**Parâmetros Registrados:**\n",
    "- `modelo`: Nome do modelo LLM utilizado (\"databricks-llama-4-maverick\")\n",
    "\n",
    "**Métricas Registradas:**\n",
    "- Para cada campo (`descritores_malignidade`, `grau_histologico`, etc.):\n",
    "  - `{campo}_taxa_acerto`: Porcentagem de extrações corretas\n",
    "  - `{campo}_passou_threshold`: Flag binária (1 = passou, 0 = falhou)\n",
    "  - `{campo}_acertos`: Número absoluto de extrações corretas\n",
    "  - `{campo}_total`: Número total de documentos avaliados\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- Cria um registro permanente da qualidade do modelo no sistema MLflow\n",
    "- Permite comparação da performance entre diferentes versões do modelo\n",
    "- Fornece ID de execução para referência e rastreabilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45ce7010-bc06-4059-ac7c-99eac5620b92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# # import requests\n",
    "# import mlflow\n",
    "\n",
    "# def get_or_create_experiment(experiment_name):\n",
    "#     experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "#     if experiment:\n",
    "#         experiment_id = experiment.experiment_id\n",
    "#     else:\n",
    "#         experiment_id = mlflow.create_experiment(experiment_name)\n",
    "#     mlflow.set_experiment(experiment_name)\n",
    "#     return experiment_id\n",
    "\n",
    "\n",
    "# # # criar experimento\n",
    "# experiment_id = get_or_create_experiment(\"/Shared/saude_preventiva_mama/experiments_fleury_anatomopatologico\")\n",
    "# mlflow.autolog()\n",
    "\n",
    "# threshold = 0.8\n",
    "\n",
    "# with mlflow.start_run(experiment_id=experiment_id) as run:\n",
    "#         #mlflow.log_param(\"modelo\", payload[\"model\"])\n",
    "#         mlflow.log_param(\"modelo\", \"databricks-llama-4-maverick\")\n",
    "#         # mlflow.log_param(\"prompt_tokens\", usage.prompt_tokens)\n",
    "#         # mlflow.log_param(\"completion_tokens\", usage.completion_tokens)\n",
    "#         # mlflow.log_param(\"total_tokens\",usage.total_tokens)\n",
    "#         for campo, stats in json_metricas.items():\n",
    "#             taxa = stats[\"taxa_acerto\"]\n",
    "#             mlflow.log_metric(f\"{campo}_taxa_acerto\", taxa)\n",
    "#             passou_flag = 1 if taxa >= threshold else 0\n",
    "#             mlflow.log_metric(f\"{campo}_passou_threshold\", passou_flag)\n",
    "#             mlflow.log_metric(f\"{campo}_acertos\", stats[\"acertos\"])\n",
    "#             mlflow.log_metric(f\"{campo}_total\", stats[\"total\"])\n",
    "            \n",
    "#             run_id = mlflow.active_run().info.run_id\n",
    "#             print(f\"Run registrada: {run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eba9a9e2-7e6a-4f69-8fdf-34ce7220e6b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Visualização das métricas de qualidade da extração\n",
    "**Objetivo da Célula:** Exibir as métricas de qualidade da extração para análise visual.\n",
    "\n",
    "Esta célula usa a função `display()` para mostrar o dicionário de métricas `json_metricas` que foi calculado anteriormente. Estas métricas fornecem uma visão detalhada do desempenho da extração de informações pelo modelo LLM em comparação com a extração por RegEx, incluindo taxas de acerto para cada campo extraído."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ff04d9f-bfd2-43d7-b67d-01cee74e5270",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(json_metricas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d81ed6d8-fea3-40de-80e4-43d9502d3ef2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Persistência dos dados na tabela Delta\n",
    "**Objetivo da Célula:** Salvar os dados processados na tabela Delta de destino usando uma estratégia de merge.\n",
    "\n",
    "**Dependências:**\n",
    "- DataFrame `df_respostas` contendo os dados processados\n",
    "- Biblioteca Delta para operações de merge em tabelas\n",
    "- Octoops (Sentinel) para monitoramento e alertas\n",
    "\n",
    "**Funções Definidas:**\n",
    "- `insert_data(df_spk, output_data_path)`: Realiza o merge dos dados na tabela Delta especificada\n",
    "\n",
    "**Lógica Detalhada:**\n",
    "1. Define a constante `WEBHOOK_DS_AI_BUSINESS_STG` como 'stg' (ambiente de staging)\n",
    "2. Define a constante `OUTPUT_DATA_PATH` com o nome da tabela de destino\n",
    "3. Implementa a função `insert_data`:\n",
    "   - Carrega a tabela Delta existente\n",
    "   - Realiza um merge usando o DataFrame como origem\n",
    "   - Utiliza chaves de junção: ficha, id_item e id_subitem\n",
    "   - Atualiza registros existentes e insere novos registros\n",
    "4. Em um bloco try-except:\n",
    "   - Verifica se o DataFrame tem registros (`df_respostas.count() > 0`)\n",
    "   - Em caso positivo, chama `insert_data` para persistir os dados\n",
    "   - Em caso negativo, envia alerta via Sentinel informando ausência de laudos para extração\n",
    "   - Em caso de exceção, captura o erro, imprime o traceback e relança a exceção\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- Os dados processados são salvos na tabela Delta usando estratégia de merge\n",
    "- O sistema registra a quantidade de registros salvos\n",
    "- Em caso de falha ou ausência de dados, um alerta é enviado via Sentinel para monitoramento\n",
    "- Exceções são devidamente registradas e relançadas para o sistema de monitoramento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ce4b6e3-d896-435b-83ab-de6b65025a41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from delta.tables import DeltaTable\n",
    "# import traceback\n",
    "# from octoops import Sentinel\n",
    "\n",
    "# WEBHOOK_DS_AI_BUSINESS_STG = 'stg'\n",
    "\n",
    "# OUTPUT_DATA_PATH = \"refined.saude_preventiva.fleury_laudos_mama_anatomia_patologica_v2\"\n",
    "\n",
    "# # função para salvar dados na tabela\n",
    "# def insert_data(df_spk, output_data_path):  \n",
    "#     # Carrega a tabela Delta existente\n",
    "#     delta_table = DeltaTable.forName(spark, output_data_path)\n",
    "\n",
    "#     # Faz o merge (upsert)\n",
    "#     (delta_table.alias(\"target\")\n",
    "#         .merge(\n",
    "#             df_spk.alias(\"source\"),\n",
    "#             \"target.ficha = source.ficha AND target.id_item = source.id_item AND target.id_subitem = source.id_subitem\"\n",
    "           \n",
    "#         )\n",
    "#         .whenMatchedUpdateAll() #atualiza todos os campos se o ID já existir\n",
    "#         .whenNotMatchedInsertAll() #insere se o ID não existir\n",
    "#         .execute())\n",
    "\n",
    "# try:\n",
    "#     if df_respostas.count() > 0:        \n",
    "#         # Inserir tabela catalog\n",
    "#     #    fs.write_table(\n",
    "#     #         name=\"refined.saude_preventiva.fleury_laudos_mamo_anatomia_patologica\",\n",
    "#     #         df=df_final,\n",
    "#     #         mode=\"merge\",\n",
    "#     #     )\n",
    "#         insert_data(df_respostas, OUTPUT_DATA_PATH)\n",
    "#         print('Total de registros salvos na tabela:', df_respostas.count())\n",
    "#     else: \n",
    "#         error_message = traceback.format_exc()\n",
    "#         error_message = \"Fleury AnatomoPatologico - Não há laudos para extração.\"\n",
    "#         sentinela_ds_ai_business = Sentinel(\n",
    "#             project_name='Monitor_Linhas_Cuidado_Mama',\n",
    "#             env_type=WEBHOOK_DS_AI_BUSINESS_STG,\n",
    "#             task_title='Fleury AnatomoPatologico'\n",
    "#         )\n",
    "\n",
    "#         sentinela_ds_ai_business.alerta_sentinela(\n",
    "#             categoria='Alerta', \n",
    "#             mensagem=error_message,\n",
    "#             job_id_descritivo='3_fleury_mama_anatomopatologico'\n",
    "#         )\n",
    "# except Exception as e:\n",
    "#     traceback.print_exc()\n",
    "#     raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b033ba23-d289-4193-bbe5-da050ce507e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df2 = df_respostas.toPandas()\n",
    "salvar_excel(df2, \"resultados_anatomo_medicos6.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5986792388758106,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "(refatorado) 3_fleury_mama_anatomopatologico_v2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
