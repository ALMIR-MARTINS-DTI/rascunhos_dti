{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cc9396a-c7bb-4da6-96f0-fbbbdbfb51ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Documentação Técnica: Extração de Dados de Anatomia Patológica - Fleury\n",
    "\n",
    "## Objetivo Principal\n",
    "**Este notebook realiza a extração e classificação automática de informações clínicas relevantes em laudos de anatomia patológica de mama do Fleury.** Utilizando técnicas de processamento de linguagem natural (NLP) com modelos de linguagem avançados (LLMs), o notebook identifica descritores de malignidade, graus histológicos e nucleares, formação de túbulos, índices mitóticos e tipos histológicos em laudos médicos de anatomia patológica mamária.\n",
    "\n",
    "## Tecnologias Utilizadas\n",
    "- **OpenAI/Databricks LLM API**: Para processamento e extração de informações dos textos dos laudos\n",
    "- **PySpark**: Framework principal para processamento distribuído de dados\n",
    "- **MLflow**: Para registro de métricas, experimentos e monitoramento dos resultados de extração\n",
    "- **Delta Lake**: Sistema de armazenamento para tabelas de destino\n",
    "- **Pandas**: Manipulação de dataframes para processamento local\n",
    "- **Expressões Regulares (re)**: Validação e extração de padrões específicos nos textos dos laudos\n",
    "- **Octoops**: Monitoramento e alertas de falhas\n",
    "\n",
    "## Fluxo de Trabalho/Etapas Principais\n",
    "1. **Definição dos Parâmetros**: Configuração de tabelas, filtros e critérios de extração\n",
    "2. **Consulta de Dados**: Extração de laudos recentes da base de dados do Fleury\n",
    "3. **Processamento via LLM**:\n",
    "   - Definição do prompt especializado para extração de informações\n",
    "   - Processamento batch dos laudos via API de LLM\n",
    "   - Extração estruturada das informações relevantes\n",
    "4. **Validação dos Resultados**:\n",
    "   - Comparação entre extração via regex e via LLM\n",
    "   - Cálculo de métricas de precisão\n",
    "   - Registro de métricas no MLflow\n",
    "5. **Persistência dos Dados**: Salvamento dos dados processados em tabela Delta\n",
    "\n",
    "## Dados Envolvidos\n",
    "- **Fonte**: Tabela `refined.saude_preventiva.fleury_laudos`\n",
    "- **Filtros**:\n",
    "  - Linha de cuidado: \"mama\"\n",
    "  - Sexo: \"F\" (feminino)\n",
    "  - Siglas de exame: \"ANATPATP\", \"CTPUNC\", \"FISHHER\"\n",
    "  - Laudos contendo \"Topografia: mama\"\n",
    "- **Tabela de Destino**: `refined.saude_preventiva.fleury_laudos_mama_anatomia_patologica_v2`\n",
    "- **Informações Extraídas**:\n",
    "  - **Descritores de Malignidade**: carcinoma, invasivo, invasor, sarcoma, metástase, metastático, maligno, maligna, cdi, cli, cdis\n",
    "  - **Grau Histológico**: 1, 2 ou 3\n",
    "  - **Grau Nuclear**: 1, 2 ou 3\n",
    "  - **Formação de Túbulos**: 1, 2 ou 3\n",
    "  - **Índice Mitótico**: valor numérico\n",
    "  - **Tipo Histológico**: classificação específica do tipo de carcinoma\n",
    "\n",
    "## Resultados/Saídas Esperadas\n",
    "- DataFrame enriquecido com os campos extraídos dos laudos\n",
    "- Registro de métricas de qualidade da extração via MLflow\n",
    "- Dados persistidos na tabela Delta `refined.saude_preventiva.fleury_laudos_mama_anatomia_patologica_v2`\n",
    "- Alertas via Sentinel (Octoops) em caso de falhas ou ausência de dados\n",
    "\n",
    "## Pré-requisitos\n",
    "- Ambiente Databricks configurado\n",
    "- Acesso ao endpoint LLM Databricks (`databricks-llama-4-maverick` ou `teste-maverick`)\n",
    "- Permissões de acesso às tabelas de origem e destino\n",
    "- Bibliotecas instaladas: openai, mlflow, pandas, tqdm, databricks-feature-store, octoops\n",
    "\n",
    "## Considerações Importantes/Observações\n",
    "- A extração via LLM é comparada com uma extração via regex (considerada pseudo-gold) para validação\n",
    "- O threshold definido para aceitação da qualidade da extração é de 80%\n",
    "- O modelo está otimizado para identificar termos específicos de malignidade e classificações dentro do contexto oncológico mamário\n",
    "- Os resultados são registrados no experimento MLflow `/Shared/saude_preventiva_mama/experiments_fleury_anatomopatologico`\n",
    "- A persistência utiliza estratégia de merge (upsert) para garantir a atualização de registros já existentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25bb71fd-3c2c-477b-a48e-9237f36e3d6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Extração de dados - Anatomo Patologico\n",
    "Serão analisados os descritores de malignidade.\n",
    "**Descritores de MALIGNIDADE:**\n",
    "- carcinoma\n",
    "- invasivo\n",
    "- invasor\n",
    "- sarcoma\n",
    "- metástase\n",
    "- metastático\n",
    "- maligno\n",
    "- maligna\n",
    "- cdi, cli, cdis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1916e94c-8e81-4c27-9c53-f5538a157781",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Outros labels a serem extraídos:\n",
    "\n",
    "- **Grau histológico:** será sempre um algarismo 1, 2 ou 3 (apenas três categorias). Para encontrar, basta procurar o primeiro algarismo numérico após o termo **\"grau histológico\"**.\n",
    "\n",
    "- **Grau nuclear:** será sempre um algarismo 1, 2 ou 3 (apenas três categorias). Para encontrar, basta procurar o primeiro algarismo numérico após o termo **\"grau nuclear\"**.\n",
    "\n",
    "- **Formação de túbulos:** será sempre um algarismo 1, 2 ou 3 (apenas três categorias). Para encontrar, basta procurar o primeiro algarismo numérico após o termo **\"formação de túbulos\"**.\n",
    "\n",
    "- **Índice mitótico:** será sempre um algarismo 1, 2 ou 3 (apenas três categorias). Para encontrar, basta procurar o primeiro algarismo numérico após o termo **\"mm2\"**. Nesse caso, é melhor procurar o termo **\"mm2\"** ao invés de **\"índice mitótico\"**.\n",
    "\n",
    "- **Labels de tipos histológicos:**\n",
    "  - Carcinoma de mama ductal invasivo (CDI)/SOE\n",
    "  - Carcinoma de mama ductal in situ\n",
    "  - Carcinoma de mama lobular invasivo\n",
    "  - Carcinoma de mama lobular\n",
    "  - Carcinoma de mama papilífero\n",
    "  - Carcinoma de mama metaplásico\n",
    "  - Carcinoma de mama mucinoso\n",
    "  - Carcinoma de mama tubular\n",
    "  - Carcinoma de mama cístico adenoide\n",
    "  - Carcinoma de mama medular\n",
    "  - Carcinoma de mama micropapilar\n",
    "  - Carcinoma de mama misto (ductal e lobular) invasivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94c1113c-4fae-43a7-8497-a4ec402dfb09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Instalação de pacotes necessários\n",
    "**Objetivo da Célula:** Instalar as bibliotecas necessárias para executar o notebook.\n",
    "\n",
    "**Pacotes Instalados:**\n",
    "- **openai**: Cliente para comunicação com a API OpenAI/Databricks LLM\n",
    "- **databricks-feature-store**: Biblioteca para interagir com o Feature Store do Databricks\n",
    "- **octoops**: Biblioteca para monitoramento e alertas\n",
    "\n",
    "A instalação é feita usando o comando mágico `%pip`, que é específico para ambientes Jupyter/Databricks. O parâmetro `-q` (quiet) é usado em algumas instalações para reduzir a verbosidade da saída."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d53f197a-e7ae-4256-a74d-c8ab9ce42835",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def salvar_excel(df, nome_arquivo):\n",
    "    \"\"\" \n",
    "    Salva um DataFrame em um arquivo Excel.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame a ser salvo.\n",
    "        nome_arquivo (str): Nome do arquivo Excel.\n",
    "    \"\"\"\n",
    "    %pip install openpyxl\n",
    "    import pandas as pd\n",
    "\n",
    "    # After installing, save the DataFrame to Excel again\n",
    "    df.to_excel(nome_arquivo, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "758d550a-6f5b-4b53-ad22-9ba5df156f30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install openai\n",
    "# %pip install tqdm -q\n",
    "# %pip install pandarallel -q\n",
    "%pip install databricks-feature-store -q\n",
    "%pip install octoops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6f1b358-dd48-446d-8c8c-e10622d92269",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Reinicialização do ambiente Python\n",
    "**Objetivo da Célula:** Reiniciar o kernel Python para garantir que as bibliotecas recém-instaladas sejam carregadas corretamente.\n",
    "\n",
    "Esta célula executa o comando `dbutils.library.restartPython()`, que é específico do ambiente Databricks. Este comando reinicia o interpretador Python, garantindo que todas as bibliotecas instaladas na célula anterior sejam devidamente carregadas no ambiente de execução. Isso é necessário porque, em ambientes Jupyter/Databricks, as bibliotecas instaladas durante a execução do notebook só ficam disponíveis após a reinicialização do kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd3f7ce2-7d45-4285-9f9c-65bfa1503408",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "452096a2-3017-464f-93ee-5a512c60f0f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Importação de bibliotecas e configuração do ambiente\n",
    "**Objetivo da Célula:** Importar todas as bibliotecas necessárias para o processamento de dados e desativar exibições automáticas do MLflow.\n",
    "\n",
    "**Dependências:**\n",
    "- Bibliotecas instaladas nas células anteriores\n",
    "\n",
    "**Bibliotecas Importadas:**\n",
    "- **re**: Para manipulação de expressões regulares\n",
    "- **os, sys**: Manipulação do sistema e ambiente\n",
    "- **json, time**: Processamento de JSON e controle de tempo\n",
    "- **warnings**: Controle de mensagens de aviso\n",
    "- **mlflow**: Rastreamento de experimentos e métricas\n",
    "- **tqdm**: Barras de progresso para processos iterativos\n",
    "- **pandas, numpy**: Manipulação e análise de dados\n",
    "- **typing**: Anotações de tipo para melhor documentação do código\n",
    "- **openai**: Cliente para API de LLM\n",
    "- **dateutil.relativedelta**: Cálculos avançados de datas\n",
    "- **pyspark.sql**: Componentes do Spark SQL\n",
    "- **databricks.feature_store**: Cliente para Feature Store do Databricks\n",
    "\n",
    "**Configurações Realizadas:**\n",
    "- Desativa a exibição automática do MLflow no notebook com `mlflow.tracing.disable_notebook_display()`\n",
    "\n",
    "**Variáveis/Objetos Criados:**\n",
    "- Não cria variáveis persistentes além das importações\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- Prepara o ambiente de execução com todas as dependências necessárias\n",
    "- Desativa logs automáticos do MLflow que poderiam sobrecarregar a interface do notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d153a2a-7b35-4e97-8984-702743e44761",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Any\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number, udf\n",
    "from databricks.feature_store import FeatureStoreClient\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "mlflow.tracing.disable_notebook_display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cb47a20-c5bf-4b5f-b3d7-d9f91db72d58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Definição de tabelas e filtros para extração de dados\n",
    "**Objetivo da Célula:** Configurar as variáveis de tabela de destino e definir os filtros SQL para seleção de dados recentes e relevantes.\n",
    "\n",
    "**Variáveis/Objetos Criados:**\n",
    "- `table_anatom`: String com o nome completo da tabela de destino (refined.saude_preventiva.fleury_laudos_mama_anatomia_patologica_v2)\n",
    "- `where_clause`: String contendo cláusula SQL WHERE para selecionar apenas registros novos (com datestamp maior que o último processado)\n",
    "- `filtro_extracao`: String contendo filtros para seleção de registros específicos de mama feminina\n",
    "\n",
    "**Lógica Detalhada:**\n",
    "- Define a tabela de destino para resultados de anatomia patológica\n",
    "- Cria uma cláusula WHERE que seleciona apenas registros mais recentes que o último datestamp na tabela de destino (processamento incremental)\n",
    "- Define filtros para extração que limitam os registros aos laudos:\n",
    "  - Da linha de cuidado \"mama\"\n",
    "  - De pacientes do sexo feminino (UPPER(sexo_cliente) = 'F')\n",
    "  - Com siglas de exames específicas (ANATPATP, CTPUNC, FISHHER)\n",
    "  - Contendo a expressão \"Topografia: mama\" no texto do laudo\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- As variáveis definidas serão utilizadas posteriormente na consulta SQL para extrair dados relevantes de laudos de anatomia patológica mamária\n",
    "- A abordagem de filtro por datestamp garante processamento incremental, evitando reprocessamento de registros já analisados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "282cf43f-caf5-4db4-9e07-c4862f93bf81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# filtros de extração\n",
    "table_anatom = \"refined.saude_preventiva.fleury_laudos_mama_anatomia_patologica_v2\" \n",
    "\n",
    "where_clause = f\"\"\"\n",
    "WHERE\n",
    "    flr.`_datestamp` >= (\n",
    "        SELECT MAX(anatom._datestamp)\n",
    "        FROM {table_anatom} anatom\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    " \n",
    "filtro_extracao = \"\"\"\n",
    "    WHERE\n",
    "        linha_cuidado  = 'mama'\n",
    "        AND UPPER(sexo_cliente) = 'F'\n",
    "        AND sigla_exame IN (\"ANATPATP\", \"CTPUNC\", \"FISHHER\")\n",
    "        AND laudo_tratado RLIKE '(?i)Topografia: mama'\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "497f2353-7da7-49dc-a5f7-6614e6a1ccfa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Construção e execução da consulta SQL\n",
    "**Objetivo da Célula:** Criar uma consulta SQL para extrair laudos relevantes e executá-la para obter os dados a serem processados pelo modelo LLM.\n",
    "\n",
    "**Variáveis/Objetos Criados:**\n",
    "- `query`: String contendo a consulta SQL completa com placeholders para os filtros definidos anteriormente\n",
    "- `df_spk`: DataFrame Spark resultante da execução da consulta\n",
    "\n",
    "**Lógica Detalhada:**\n",
    "1. Define uma consulta SQL com Common Table Expression (CTE) chamada `base`\n",
    "2. Seleciona campos relevantes dos laudos: identificadores, datas, informações do exame e o conteúdo do laudo\n",
    "3. Aplica os filtros definidos anteriormente:\n",
    "   - Processamento incremental via `where_clause` (registros mais recentes que o último processado)\n",
    "   - Filtros específicos de mama via `filtro_extracao` (linha de cuidado, sexo, siglas de exame, conteúdo do laudo)\n",
    "4. Executa a consulta usando `spark.sql()`, formatando a string para incluir os filtros\n",
    "5. Exibe o resultado via `display(df_spk)`\n",
    "\n",
    "**Tabelas/Colunas Utilizadas:**\n",
    "- Tabela: `refined.saude_preventiva.fleury_laudos` (alias `flr`)\n",
    "- Colunas principais:\n",
    "  - Identificadores: `id_marca`, `id_unidade`, `id_cliente`, `id_ficha`, `ficha`, `id_item`, `id_subitem`, `id_exame`\n",
    "  - Datas: `dth_pedido`, `dth_resultado`\n",
    "  - Dados do exame: `sigla_exame`, `laudo_tratado`, `linha_cuidado`, `sexo_cliente`\n",
    "  - Metadata: `_datestamp`\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- Cria o DataFrame `df_spk` contendo os laudos de anatomia patológica mamária que serão processados\n",
    "- Exibe o conteúdo do DataFrame na interface do notebook para visualização prévia dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc7e7385-7c63-4d51-aa27-506703e0fde8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "WITH \n",
    "base AS (\n",
    "    SELECT\n",
    "        flr.id_marca,\n",
    "        flr.id_unidade,\n",
    "        flr.id_cliente, \n",
    "        flr.id_ficha,\n",
    "        flr.ficha,\n",
    "        flr.id_item, \n",
    "        flr.id_subitem, \n",
    "        flr.id_exame, \n",
    "        flr.dth_pedido,\n",
    "        flr.dth_resultado,\n",
    "        flr.sigla_exame,\n",
    "        flr.laudo_tratado,\n",
    "        flr.linha_cuidado,\n",
    "        flr.sexo_cliente,\n",
    "        flr.`_datestamp`\n",
    "    FROM refined.saude_preventiva.fleury_laudos flr \n",
    "    {where_clause} \n",
    "     \n",
    ")\n",
    "SELECT *\n",
    "FROM base\n",
    "{filtro_extracao}\n",
    "\"\"\"\n",
    "df_spk = spark.sql(query)\n",
    "display(df_spk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad1766c3-c130-4d44-b48f-21440d11f558",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Template do prompt para uso com F.format_string\n",
    "# Use %s como placeholder e escape %% literal\n",
    "prompt_laudo_template = \"\"\"A seguir está um laudo médico de mamografia. Se alguma informação não estiver presente no texto, retorne \"NÃO INFORMADO\". Retorne APENAS um JSON válido, sem blocos de código e sem comentários.\n",
    "\n",
    "Laudo clínico:\n",
    "\\\"\\\"\\\"%s\\\"\\\"\\\"\n",
    "\n",
    "### Critérios de extração:\n",
    "\n",
    "- **Descritores de malignidade**: retorne uma **lista** com os termos de malignidade encontrados no texto (case-insensitive). Se nenhum for encontrado, retorne lista vazia []. Lista de termos: [\"carcinoma\", \"invasivo\", \"invasor\", \"sarcoma\", \"metástase\", \"metastático\", \"maligno\", \"maligna\", \"cdi\", \"cli\", \"cdis\"]\n",
    "\n",
    "- **Grau histológico**: retorne o valor numérico do grau histológico ou \"NÃO INFORMADO\".\n",
    "\n",
    "- **Grau nuclear**: retorne o valor numérico do grau nuclear ou \"NÃO INFORMADO\".\n",
    "\n",
    "- **Formação de túbulos**: retorne o valor numérico caso exista formação de túbulos ou \"NÃO INFORMADO\".\n",
    "\n",
    "- **Índice mitótico**: retorne o valor numérico do score do índice mitótico que aparece após o mm2 ou \"NÃO INFORMADO\".\n",
    "\n",
    "- **Tipo histológico**: identifique e retorne a frase correspondente se algum dos seguintes for mencionado (case-insensitive, variações aceitas):\n",
    "- Carcinoma de mama ductal invasivo\n",
    "- Carcinoma de mama ductal in situ\n",
    "- Carcinoma de mama lobular invasivo\n",
    "- Carcinoma de mama lobular\n",
    "- Carcinoma de mama papilífero\n",
    "- Carcinoma de mama metaplásico\n",
    "- Carcinoma de mama mucinoso\n",
    "- Carcinoma de mama tubular\n",
    "- Carcinoma de mama cístico adenoide\n",
    "- Carcinoma de mama medular\n",
    "- Carcinoma de mama micropapilar\n",
    "- Carcinoma de mama misto (ductal e lobular) invasivo\n",
    "\n",
    "\n",
    "### Exemplo de saída (JSON válido):\n",
    "{\n",
    "  \"descritores_malignidade\": [\"carcinoma\", \"invasivo\"], \n",
    "  \"grau_histologico\": \"1\", \n",
    "  \"grau_nuclear\": \"2\", \n",
    "  \"formacao_tubulos\": \"2\", \n",
    "  \"indice_mitotico\": \"1\", \n",
    "  \"tipo_histologico\": \"Carcinoma de mama ductal invasivo\"\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Schema para parsear a resposta JSON do LLM\n",
    "llm_output_schema = StructType(\n",
    "  [\n",
    "    StructField(\"descritores_malignidade\", ArrayType(StringType()), True),\n",
    "    StructField(\"grau_histologico\", StringType(), True),\n",
    "    StructField(\"grau_nuclear\", StringType(), True),\n",
    "    StructField(\"formacao_tubulos\", StringType(), True),\n",
    "    StructField(\"indice_mitotico\", StringType(), True),\n",
    "    StructField(\"tipo_histologico\", StringType(), True),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33d10d4f-ff9d-462f-a7b4-3519477701b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Funções para geração de respostas usando o LLM\n",
    "**Objetivo da Célula:** Definir funções que gerenciam as chamadas à API do LLM e processam respostas para análise de laudos médicos.\n",
    "\n",
    "**Funções Definidas:**\n",
    "1. `generate(descricao_agente:str, laudo:str, llm_client) -> str`: Função principal para enviar um laudo ao modelo e obter resposta\n",
    "2. `batch_generate(descricao_agente, laudos, llm_client, batch_size=25)`: Função para processar múltiplos laudos em lotes\n",
    "\n",
    "**Lógica Detalhada da Função `generate`:**\n",
    "1. Recebe os parâmetros: descrição do papel do LLM, texto do laudo, e o cliente da API\n",
    "2. Cria o prompt específico para o laudo usando a função `prompt_laudo()`\n",
    "3. Monta a estrutura de mensagens para a API:\n",
    "   - Mensagem de sistema definindo o papel do LLM\n",
    "   - Mensagem do usuário contendo o prompt com o laudo\n",
    "4. Define parâmetros para a chamada ao modelo:\n",
    "   - Modelo: \"teste-maverick\" (endpoint do Databricks)\n",
    "   - Temperatura: 0 (determinístico)\n",
    "   - Tokens máximos: 4000\n",
    "   - Outros parâmetros de controle da geração de texto\n",
    "5. Implementa mecanismo de retry (3 tentativas) em caso de falha de conexão\n",
    "6. Retorna o texto da resposta do modelo\n",
    "\n",
    "**Lógica Detalhada da Função `batch_generate`:**\n",
    "1. Recebe listas de laudos, descrição do agente, cliente da API e tamanho do lote\n",
    "2. Inicializa o cliente OpenAI com o token do Databricks\n",
    "3. Divide os laudos em lotes menores (padrão: 25 laudos por lote)\n",
    "4. Para cada lote, processa cada laudo individualmente usando a função `generate()`\n",
    "5. Exibe barra de progresso usando tqdm\n",
    "6. Retorna lista com todas as respostas do modelo\n",
    "\n",
    "**Dependências:**\n",
    "- Função `prompt_laudo()` definida anteriormente\n",
    "- Variável `DATABRICKS_TOKEN` para autenticação\n",
    "- Biblioteca tqdm para exibição de progresso\n",
    "- Cliente OpenAI para comunicação com a API\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- As funções definidas serão utilizadas posteriormente para processamento dos laudos extraídos\n",
    "- O mecanismo de retry aumenta a robustez do sistema a falhas temporárias de rede/API\n",
    "- O processamento em batch otimiza o uso da API e permite monitoramento de progresso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee1c6dc4-e5df-436e-8963-d3c9206892ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Funções generate e batch_generate removidas\n",
    "# A extração será feita diretamente no Spark DataFrame usando ai_query + F.expr\n",
    "# Não é mais necessário coletar os dados para pandas nem usar cliente OpenAI\n",
    "\n",
    "# Nome do endpoint do Foundation Model\n",
    "ENDPOINT_NAME = \"databricks-llama-4-maverick\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a07113c5-ccb2-4b45-b8c2-636d4f3b4a9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Funções para extração por RegEx e validação das respostas do LLM\n",
    "**Objetivo da Célula:** Implementar um conjunto de funções que extraem informações dos laudos usando expressões regulares e comparam com as respostas do LLM.\n",
    "\n",
    "**Funções Definidas:**\n",
    "1. Funções de extração por RegEx:\n",
    "   - `extrai_descritores`: Encontra descritores de malignidade no texto\n",
    "   - `extrai_grau_histologico`: Extrai o grau histológico (1, 2 ou 3)\n",
    "   - `extrai_grau_nuclear`: Extrai o grau nuclear (1, 2 ou 3)\n",
    "   - `extrai_formacao_tubulos`: Extrai o valor de formação de túbulos (1, 2 ou 3)\n",
    "   - `extrai_indice_mitotico`: Extrai o índice mitótico\n",
    "   - `extrai_tipo_histologico`: Identifica o tipo histológico específico\n",
    "\n",
    "2. Função de avaliação:\n",
    "   - `avalia_extracao_sem_ground_truth`: Compara a extração do LLM com a extração por RegEx\n",
    "\n",
    "**Lógica Detalhada:**\n",
    "- `extrai_descritores`: Procura por cada termo da lista TERMS no texto usando regex case-insensitive\n",
    "- `extrai_grau_histologico`, `extrai_grau_nuclear`, `extrai_formacao_tubulos`: Procuram por padrões específicos seguidos de um dígito\n",
    "- `extrai_indice_mitotico`: Procura por um valor numérico próximo ao termo \"mm2\" ou \"mitoses\"\n",
    "- `extrai_tipo_histologico`: Compara o texto com uma lista predefinida de tipos histológicos\n",
    "- `avalia_extracao_sem_ground_truth`: \n",
    "  1. Gera um pseudo-gold standard usando as funções de extração por RegEx\n",
    "  2. Compara campo a campo com as extrações do LLM\n",
    "  3. Retorna um relatório detalhado de concordância\n",
    "\n",
    "**Constantes Definidas:**\n",
    "- `TERMS`: Lista de termos associados a malignidade\n",
    "- `TIPOS`: Lista de padrões de tipos histológicos a serem buscados\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- As funções serão utilizadas para avaliar a qualidade das extrações do modelo LLM\n",
    "- A avaliação usa as extrações por RegEx como pseudo-gold standard\n",
    "- Os resultados da comparação serão utilizados para métricas e monitoramento do desempenho do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9558e288-0a6e-4891-b378-a8223fe42245",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "TERMS = ['carcinoma', 'invasivo', 'invasor', 'sarcoma', \n",
    "       'metástase', 'metastático', 'maligno', 'maligna', \n",
    "       'cdi', 'cli', 'cdis']\n",
    "\n",
    "def extrai_descritores(txt):\n",
    "  if txt is None:\n",
    "      return []\n",
    "  achados = set()\n",
    "  for termo in TERMS:\n",
    "      if re.search(rf\"\\b{re.escape(termo)}\\b\", txt, flags=re.IGNORECASE):\n",
    "          achados.add(termo.lower())\n",
    "  return sorted(achados)\n",
    "\n",
    "def extrai_grau_histologico(txt):\n",
    "  if txt is None:\n",
    "      return None\n",
    "  m = re.search(r\"grau\\s+histol[oó]gico\\s*[:\\-]?\\s*(\\d)\", txt, flags=re.IGNORECASE)\n",
    "  if m:\n",
    "      return int(m.group(1))\n",
    "  return None\n",
    "\n",
    "def extrai_grau_nuclear(txt):\n",
    "  if txt is None:\n",
    "      return None\n",
    "  m = re.search(r\"grau\\s+nuclear\\s*[:\\-]?\\s*(\\d)\", txt, flags=re.IGNORECASE)\n",
    "  return int(m.group(1)) if m else None\n",
    "\n",
    "def extrai_formacao_tubulos(txt):\n",
    "  if txt is None:\n",
    "      return None\n",
    "  m = re.search(r\"forma[cç][aã]o\\s+de\\s+t[uú]bulos\\s*[:\\-]?\\s*(\\d)\", txt, flags=re.IGNORECASE)\n",
    "  return int(m.group(1)) if m else None\n",
    "\n",
    "def extrai_indice_mitotico(txt):\n",
    "  if txt is None:\n",
    "      return None\n",
    "  m = re.search(r\"mit[oó]tico\\s*[:\\-]?\\s*(\\d+)(?:\\s*/\\s*\\d+)?\\s*(?:mitoses?|mitose)?\\s*/?\\s*mm2\", txt, flags=re.IGNORECASE)\n",
    "  if m:\n",
    "      return int(m.group(1))\n",
    "  return None\n",
    "\n",
    "TIPOS = [\n",
    "  \"carcinoma de mama ductal invasivo\",\n",
    "  \"carcinoma de mama ductal in situ\",\n",
    "  \"carcinoma de mama lobular invasivo\",\n",
    "  \"carcinoma de mama lobular\",\n",
    "  \"carcinoma de mama papilífero\",\n",
    "  \"carcinoma de mama metapl[aá]sico\",\n",
    "  \"carcinoma de mama mucinoso\",\n",
    "  \"carcinoma de mama tubular\",\n",
    "  \"carcinoma de mama c[ií]stico adenoide\",\n",
    "  \"carcinoma de mama medular\",\n",
    "  \"carcinoma de mama micropapilar\",\n",
    "  \"carcinoma de mama misto (ductal e lobular) invasivo\"\n",
    "]\n",
    "\n",
    "def extrai_tipo_histologico(txt):\n",
    "  if txt is None:\n",
    "      return None\n",
    "  txt_lower = txt.lower()\n",
    "  for tipo in TIPOS:\n",
    "      padrao = tipo.lower()\n",
    "      if padrao in txt_lower:\n",
    "          return tipo\n",
    "  return None\n",
    "\n",
    "# Registrar as funções como UDFs para uso no Spark\n",
    "extrai_descritores_udf = udf(extrai_descritores, ArrayType(StringType()))\n",
    "extrai_grau_histologico_udf = udf(extrai_grau_histologico, IntegerType())\n",
    "extrai_grau_nuclear_udf = udf(extrai_grau_nuclear, IntegerType())\n",
    "extrai_formacao_tubulos_udf = udf(extrai_formacao_tubulos, IntegerType())\n",
    "extrai_indice_mitotico_udf = udf(extrai_indice_mitotico, IntegerType())\n",
    "extrai_tipo_histologico_udf = udf(extrai_tipo_histologico, StringType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a79c95f9-474a-49c4-adc1-2465c5936ec5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Processamento e avaliação dos laudos com o modelo LLM\n",
    "**Objetivo da Célula:** Processar os laudos extraídos utilizando o modelo LLM, avaliar a qualidade das extrações e preparar os dados para persistência.\n",
    "\n",
    "**Dependências:**\n",
    "- DataFrames e funções definidas anteriormente\n",
    "- Token de autenticação Databricks\n",
    "- Cliente OpenAI configurado\n",
    "\n",
    "**Lógica Detalhada:**\n",
    "1. Verifica se há dados disponíveis para processamento (`df_spk.count() > 0`)\n",
    "2. Inicializa o cliente OpenAI com o token Databricks e configuração do endpoint\n",
    "3. Define o contexto do agente LLM como \"médico oncologista especialista em laudos de mamografia\"\n",
    "4. Converte o DataFrame Spark para Pandas para processamento local (limitado a 15 registros para teste)\n",
    "5. Processa os laudos em batch utilizando a função `batch_generate`\n",
    "6. Limpa e converte as respostas do LLM para formato estruturado utilizando `limpar_e_converter`\n",
    "7. Avalia a qualidade das extrações comparando com extrações via RegEx\n",
    "8. Calcula métricas agregadas de precisão\n",
    "\n",
    "**Variáveis/Objetos Criados:**\n",
    "- `llm_client`: Cliente para comunicação com a API do LLM\n",
    "- `descricao_agente`: Descrição do papel do LLM na análise\n",
    "- `df_local`: DataFrame Pandas para processamento local\n",
    "- `df_respostas`: DataFrame Spark com as respostas processadas\n",
    "- `resultados`: Lista de comparações entre extrações via LLM e RegEx\n",
    "- `json_metricas`: Estatísticas agregadas sobre a qualidade da extração\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- Cria um DataFrame enriquecido com as informações extraídas dos laudos\n",
    "- Exibe o DataFrame processado via `display(df_respostas)`\n",
    "- Prepara os dados para registro de métricas no MLflow e persistência em tabela Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94360d4e-0d98-4b4d-8b7e-0f1e650f86f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Verificar e corrigir o filtro should_call_llm\n",
    "if df_spk.count() > 0:\n",
    "    # Versão corrigida: usar pattern mais simples sem word boundaries complexos\n",
    "    termos_escaped = [re.escape(t) for t in TERMS]\n",
    "    termos_pattern = \"(?i)(\" + \"|\".join(termos_escaped) + \")\"\n",
    "\n",
    "    df_test = df_spk.withColumn(\"should_call_llm\", F.expr(f\"laudo_tratado RLIKE '{termos_pattern}'\"))\n",
    "\n",
    "    print(\"Verificando filtro should_call_llm CORRIGIDO:\")\n",
    "    df_test.select(\"should_call_llm\").groupBy(\"should_call_llm\").count().show()\n",
    "\n",
    "    # Mostrar exemplo de laudo que deveria dar match\n",
    "    print(\"\\nPrimeiros 100 caracteres de um laudo:\")\n",
    "    df_test.select(F.substring(\"laudo_tratado\", 1, 100).alias(\"inicio_laudo\"), \"should_call_llm\").show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "728d3c7e-638e-4ed7-b4e7-8537baddb73b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Extração usando ai_query diretamente no Spark DataFrame\n",
    "\n",
    "if df_spk.count() > 0:\n",
    "    # 1. Opcional: Filtro para reduzir custo (apenas laudos com termos relevantes)\n",
    "    # Como ai_query funciona bem, você pode usar ou não este filtro\n",
    "    termos_escaped = [re.escape(t) for t in TERMS]\n",
    "    termos_pattern = \"(?i)(\" + \"|\".join(termos_escaped) + \")\"\n",
    "\n",
    "    df_filtered = df_spk.withColumn(\"should_call_llm\", F.expr(f\"laudo_tratado RLIKE '{termos_pattern}'\"))\n",
    "\n",
    "    print(f\"Total de laudos: {df_filtered.count()}\")\n",
    "    print(\"Distribuição do filtro:\")\n",
    "    df_filtered.groupBy(\"should_call_llm\").count().show()\n",
    "\n",
    "    # 2. Gerar prompt para cada laudo\n",
    "    df_with_prompt = df_filtered.withColumn(\n",
    "        \"prompt_llm\",\n",
    "        F.format_string(prompt_laudo_template, F.col(\"laudo_tratado\"))\n",
    "    )\n",
    "\n",
    "    # 3. Chamar o LLM via ai_query\n",
    "    # OPÇÃO A: Chamar para todos (sem filtro)\n",
    "    df_llm_raw = df_with_prompt.withColumn(\n",
    "        \"resp_raw\",\n",
    "        F.expr(f\"ai_query('{ENDPOINT_NAME}', prompt_llm)\")\n",
    "    )\n",
    "\n",
    "    # OPÇÃO B: Chamar apenas para laudos relevantes (com filtro - descomente se preferir)\n",
    "    # df_llm_raw = df_with_prompt.withColumn(\n",
    "    #     \"resp_raw\",\n",
    "    #     F.when(\n",
    "    #         F.col(\"should_call_llm\"),\n",
    "    #         F.expr(f\"ai_query('{ENDPOINT_NAME}', prompt_llm)\")\n",
    "    #     ).otherwise(F.lit('{\"descritores_malignidade\":[], \"grau_histologico\":\"NÃO INFORMADO\",\"grau_nuclear\":\"NÃO INFORMADO\",\"formacao_tubulos\":\"NÃO INFORMADO\",\"indice_mitotico\":\"NÃO INFORMADO\",\"tipo_histologico\":\"NÃO INFORMADO\"}'))\n",
    "    # )\n",
    "\n",
    "    # 4. Limpar blocos de código caso o modelo retorne com ```json ou ```python\n",
    "    df_llm_clean = df_llm_raw.withColumn(\n",
    "        \"resp_clean\",\n",
    "        F.regexp_replace(\n",
    "            F.regexp_replace(F.col(\"resp_raw\"), \"```(?:json|python)?\", \"\"),\n",
    "            \"```\", \"\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 5. Parsear JSON com from_json\n",
    "    df_llm_parsed = df_llm_clean.withColumn(\n",
    "        \"resp\",\n",
    "        F.from_json(F.trim(F.col(\"resp_clean\")), llm_output_schema)\n",
    "    )\n",
    "\n",
    "    # 6. Extrair campos da estrutura JSON parseada e converter numéricos de forma segura\n",
    "    def cast_int_safe(colname):\n",
    "        return F.when(\n",
    "            F.lower(F.col(f\"resp.{colname}\")).isin(\"não informado\", \"nao informado\"), \n",
    "            F.lit(None)\n",
    "        ).when(\n",
    "            F.col(f\"resp.{colname}\").isNull(),\n",
    "            F.lit(None)\n",
    "        ).otherwise(\n",
    "            F.col(f\"resp.{colname}\").cast(IntegerType())\n",
    "        )\n",
    "\n",
    "    df_llm_final = (\n",
    "        df_llm_parsed\n",
    "        .withColumn(\"descritores_malignidade\", F.col(\"resp.descritores_malignidade\"))\n",
    "        .withColumn(\"grau_histologico\", cast_int_safe(\"grau_histologico\"))\n",
    "        .withColumn(\"grau_nuclear\", cast_int_safe(\"grau_nuclear\"))\n",
    "        .withColumn(\"formacao_tubulos\", cast_int_safe(\"formacao_tubulos\"))\n",
    "        .withColumn(\"indice_mitotico\", cast_int_safe(\"indice_mitotico\"))\n",
    "        .withColumn(\"tipo_histologico\", F.col(\"resp.tipo_histologico\"))\n",
    "    )\n",
    "\n",
    "    # 7. Aplicar heurísticas (pseudo-gold) usando UDFs\n",
    "    df_with_heuristics = (\n",
    "        df_llm_final\n",
    "        .withColumn(\"heu_descritores\", extrai_descritores_udf(F.col(\"laudo_tratado\")))\n",
    "        .withColumn(\"heu_grau_histologico\", extrai_grau_histologico_udf(F.col(\"laudo_tratado\")))\n",
    "        .withColumn(\"heu_grau_nuclear\", extrai_grau_nuclear_udf(F.col(\"laudo_tratado\")))\n",
    "        .withColumn(\"heu_formacao_tubulos\", extrai_formacao_tubulos_udf(F.col(\"laudo_tratado\")))\n",
    "        .withColumn(\"heu_indice_mitotico\", extrai_indice_mitotico_udf(F.col(\"laudo_tratado\")))\n",
    "        .withColumn(\"heu_tipo_histologico\", extrai_tipo_histologico_udf(F.col(\"laudo_tratado\")))\n",
    "    )\n",
    "\n",
    "    # 8. Comparar LLM vs Heurística campo a campo\n",
    "    df_comparisons = (\n",
    "        df_with_heuristics\n",
    "        .withColumn(\"acertou_descritores\", \n",
    "                    F.sort_array(F.coalesce(F.col(\"descritores_malignidade\"), F.array())) == \n",
    "                    F.sort_array(F.coalesce(F.col(\"heu_descritores\"), F.array())))\n",
    "        .withColumn(\"acertou_grau_histologico\", \n",
    "                    (F.col(\"grau_histologico\") == F.col(\"heu_grau_histologico\")) | \n",
    "                    (F.col(\"grau_histologico\").isNull() & F.col(\"heu_grau_histologico\").isNull()))\n",
    "        .withColumn(\"acertou_grau_nuclear\", \n",
    "                    (F.col(\"grau_nuclear\") == F.col(\"heu_grau_nuclear\")) | \n",
    "                    (F.col(\"grau_nuclear\").isNull() & F.col(\"heu_grau_nuclear\").isNull()))\n",
    "        .withColumn(\"acertou_formacao_tubulos\", \n",
    "                    (F.col(\"formacao_tubulos\") == F.col(\"heu_formacao_tubulos\")) | \n",
    "                    (F.col(\"formacao_tubulos\").isNull() & F.col(\"heu_formacao_tubulos\").isNull()))\n",
    "        .withColumn(\"acertou_indice_mitotico\", \n",
    "                    (F.col(\"indice_mitotico\") == F.col(\"heu_indice_mitotico\")) | \n",
    "                    (F.col(\"indice_mitotico\").isNull() & F.col(\"heu_indice_mitotico\").isNull()))\n",
    "        .withColumn(\"acertou_tipo_histologico\", \n",
    "                    F.col(\"tipo_histologico\") == F.col(\"heu_tipo_histologico\"))\n",
    "    )\n",
    "\n",
    "    # DataFrame final com todas as extrações e comparações\n",
    "    df_respostas = df_comparisons\n",
    "\n",
    "    # 9. Calcular métricas agregadas\n",
    "    total_laudos = df_respostas.count()\n",
    "\n",
    "    def calcular_taxa_acerto(col_name):\n",
    "        if total_laudos == 0:\n",
    "            return {\"acertos\": 0, \"total\": 0, \"taxa_acerto\": 0.0}\n",
    "        taxa = df_respostas.select(F.avg(F.col(col_name).cast(\"double\")).alias(\"taxa\")).collect()[0][\"taxa\"]\n",
    "        if taxa is None:\n",
    "            taxa = 0.0\n",
    "        acertos = int(taxa * total_laudos)\n",
    "        return {\n",
    "            \"acertos\": acertos,\n",
    "            \"total\": total_laudos,\n",
    "            \"taxa_acerto\": taxa\n",
    "        }\n",
    "\n",
    "    json_metricas = {\n",
    "        \"descritores_malignidade\": calcular_taxa_acerto(\"acertou_descritores\"),\n",
    "        \"grau_histologico\": calcular_taxa_acerto(\"acertou_grau_histologico\"),\n",
    "        \"grau_nuclear\": calcular_taxa_acerto(\"acertou_grau_nuclear\"),\n",
    "        \"formacao_tubulos\": calcular_taxa_acerto(\"acertou_formacao_tubulos\"),\n",
    "        \"indice_mitotico\": calcular_taxa_acerto(\"acertou_indice_mitotico\"),\n",
    "        \"tipo_histologico\": calcular_taxa_acerto(\"acertou_tipo_histologico\"),\n",
    "    }\n",
    "\n",
    "    print(f\"\\n✓ Processamento concluído: {total_laudos} laudos\")\n",
    "    display(df_respostas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4032207-24f7-4d1f-a195-985019ba9733",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# correção ======================\n",
    "# Extração usando ai_query via SQL puro (mais confiável no contexto distribuído)\n",
    "\n",
    "if df_spk.count() > 0:\n",
    "    # 1. Opcional: Filtro para reduzir custo\n",
    "    termos_escaped = [re.escape(t) for t in TERMS]\n",
    "    termos_pattern = \"(?i)(\" + \"|\".join(termos_escaped) + \")\"\n",
    "\n",
    "    df_filtered = df_spk.withColumn(\"should_call_llm\", F.expr(f\"laudo_tratado RLIKE '{termos_pattern}'\"))\n",
    "\n",
    "    print(f\"Total de laudos: {df_filtered.count()}\")\n",
    "    print(\"Distribuição do filtro:\")\n",
    "    df_filtered.groupBy(\"should_call_llm\").count().show()\n",
    "\n",
    "    # 2. Gerar prompt usando CONCAT\n",
    "    prompt_prefix = \"\"\"A seguir está um laudo médico de mamografia. Se alguma informação não estiver presente no texto, retorne \"NÃO INFORMADO\". Retorne APENAS um JSON válido, sem blocos de código e sem comentários.\n",
    "\n",
    "    Laudo clínico:\n",
    "    \\\"\\\"\\\"\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_suffix = \"\"\"\n",
    "    \\\"\\\"\\\"\n",
    "\n",
    "    ### Critérios de extração:\n",
    "\n",
    "    - **Descritores de malignidade**: retorne uma **lista** com os termos de malignidade encontrados no texto (case-insensitive). Se nenhum for encontrado, retorne lista vazia []. Lista de termos: [\"carcinoma\", \"invasivo\", \"invasor\", \"sarcoma\", \"metástase\", \"metastático\", \"maligno\", \"maligna\", \"cdi\", \"cli\", \"cdis\"]\n",
    "\n",
    "    - **Grau histológico**: retorne o valor numérico do grau histológico ou \"NÃO INFORMADO\".\n",
    "\n",
    "    - **Grau nuclear**: retorne o valor numérico do grau nuclear ou \"NÃO INFORMADO\".\n",
    "\n",
    "    - **Formação de túbulos**: retorne o valor numérico do escore caso exista formação de túbulos ou \"NÃO INFORMADO\".\n",
    "\n",
    "    - **Índice mitótico**: retorne o valor numérico do escore do índice mitótico que aparece entre parênteses ou \"NÃO INFORMADO\".\n",
    "\n",
    "    - **Tipo histológico**: identifique e retorne a frase correspondente se algum dos seguintes for mencionado (case-insensitive): Carcinoma de mama ductal invasivo, Carcinoma de mama ductal in situ, Carcinoma de mama lobular invasivo, Carcinoma de mama lobular, Carcinoma de mama papilífero, Carcinoma de mama metaplásico, Carcinoma de mama mucinoso, Carcinoma de mama tubular, Carcinoma de mama cístico adenoide, Carcinoma de mama medular, Carcinoma de mama micropapilar, Carcinoma de mama misto (ductal e lobular) invasivo, ou \"NÃO INFORMADO\".\n",
    "\n",
    "    ### Exemplo de saída (JSON válido):\n",
    "    {\"descritores_malignidade\": [\"carcinoma\", \"invasivo\"], \"grau_histologico\": \"1\", \"grau_nuclear\": \"2\", \"formacao_tubulos\": \"2\", \"indice_mitotico\": \"1\", \"tipo_histologico\": \"Carcinoma de mama ductal invasivo\"}\n",
    "    \"\"\"\n",
    "\n",
    "    df_with_prompt = df_filtered.withColumn(\n",
    "        \"prompt_llm\",\n",
    "        F.concat(\n",
    "            F.lit(prompt_prefix),\n",
    "            F.col(\"laudo_tratado\"),\n",
    "            F.lit(prompt_suffix)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 3. Registrar como tabela temporária e usar SQL PURO\n",
    "    df_with_prompt.createOrReplaceTempView(\"laudos_para_processar\")\n",
    "\n",
    "    # 4. Chamar ai_query via SQL (método mais confiável)\n",
    "    df_llm_raw = spark.sql(f\"\"\"\n",
    "        SELECT \n",
    "            *,\n",
    "            ai_query('{ENDPOINT_NAME}', prompt_llm) as resp_raw\n",
    "        FROM laudos_para_processar\n",
    "    \"\"\")\n",
    "\n",
    "    print(\"Primeiras 2 respostas do modelo:\")\n",
    "    df_llm_raw.select(F.substring(\"resp_raw\", 1, 200).alias(\"resposta_inicio\")).show(2, truncate=False)\n",
    "\n",
    "    # 5. Limpar blocos de código\n",
    "    df_llm_clean = df_llm_raw.withColumn(\n",
    "        \"resp_clean\",\n",
    "        F.regexp_replace(\n",
    "            F.regexp_replace(F.col(\"resp_raw\"), \"```(?:json|python)?\", \"\"),\n",
    "            \"```\", \"\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 6. Parsear JSON\n",
    "    df_llm_parsed = df_llm_clean.withColumn(\n",
    "        \"resp\",\n",
    "        F.from_json(F.trim(F.col(\"resp_clean\")), llm_output_schema)\n",
    "    )\n",
    "\n",
    "    # 7. Extrair campos e converter numéricos\n",
    "    def cast_int_safe(colname):\n",
    "        return F.when(\n",
    "            F.lower(F.col(f\"resp.{colname}\")).isin(\"não informado\", \"nao informado\"), \n",
    "            F.lit(None)\n",
    "        ).when(\n",
    "            F.col(f\"resp.{colname}\").isNull(),\n",
    "            F.lit(None)\n",
    "        ).otherwise(\n",
    "            F.col(f\"resp.{colname}\").cast(IntegerType())\n",
    "        )\n",
    "\n",
    "    df_llm_final = (\n",
    "        df_llm_parsed\n",
    "        .withColumn(\"descritores_malignidade\", F.coalesce(F.col(\"resp.descritores_malignidade\"), F.array()))\n",
    "        .withColumn(\"grau_histologico\", cast_int_safe(\"grau_histologico\"))\n",
    "        .withColumn(\"grau_nuclear\", cast_int_safe(\"grau_nuclear\"))\n",
    "        .withColumn(\"formacao_tubulos\", cast_int_safe(\"formacao_tubulos\"))\n",
    "        .withColumn(\"indice_mitotico\", cast_int_safe(\"indice_mitotico\"))\n",
    "        .withColumn(\"tipo_histologico\", F.coalesce(F.col(\"resp.tipo_histologico\"), F.lit(\"NÃO INFORMADO\")))\n",
    "    )\n",
    "\n",
    "    # 8. Aplicar heurísticas\n",
    "    df_with_heuristics = (\n",
    "        df_llm_final\n",
    "        .withColumn(\"heu_descritores\", extrai_descritores_udf(F.col(\"laudo_tratado\")))\n",
    "        .withColumn(\"heu_grau_histologico\", extrai_grau_histologico_udf(F.col(\"laudo_tratado\")))\n",
    "        .withColumn(\"heu_grau_nuclear\", extrai_grau_nuclear_udf(F.col(\"laudo_tratado\")))\n",
    "        .withColumn(\"heu_formacao_tubulos\", extrai_formacao_tubulos_udf(F.col(\"laudo_tratado\")))\n",
    "        .withColumn(\"heu_indice_mitotico\", extrai_indice_mitotico_udf(F.col(\"laudo_tratado\")))\n",
    "        .withColumn(\"heu_tipo_histologico\", extrai_tipo_histologico_udf(F.col(\"laudo_tratado\")))\n",
    "    )\n",
    "\n",
    "    # 9. Comparar - NÃO contar NULL==NULL como acerto\n",
    "    df_comparisons = (\n",
    "        df_with_heuristics\n",
    "        .withColumn(\"acertou_descritores\", \n",
    "                    F.sort_array(F.col(\"descritores_malignidade\")) == F.sort_array(F.col(\"heu_descritores\")))\n",
    "        .withColumn(\"acertou_grau_histologico\", \n",
    "                    F.when(F.col(\"grau_histologico\").isNull() | F.col(\"heu_grau_histologico\").isNull(), F.lit(False))\n",
    "                    .otherwise(F.col(\"grau_histologico\") == F.col(\"heu_grau_histologico\")))\n",
    "        .withColumn(\"acertou_grau_nuclear\", \n",
    "                    F.when(F.col(\"grau_nuclear\").isNull() | F.col(\"heu_grau_nuclear\").isNull(), F.lit(False))\n",
    "                    .otherwise(F.col(\"grau_nuclear\") == F.col(\"heu_grau_nuclear\")))\n",
    "        .withColumn(\"acertou_formacao_tubulos\", \n",
    "                    F.when(F.col(\"formacao_tubulos\").isNull() | F.col(\"heu_formacao_tubulos\").isNull(), F.lit(False))\n",
    "                    .otherwise(F.col(\"formacao_tubulos\") == F.col(\"heu_formacao_tubulos\")))\n",
    "        .withColumn(\"acertou_indice_mitotico\", \n",
    "                    F.when(F.col(\"indice_mitotico\").isNull() | F.col(\"heu_indice_mitotico\").isNull(), F.lit(False))\n",
    "                    .otherwise(F.col(\"indice_mitotico\") == F.col(\"heu_indice_mitotico\")))\n",
    "        .withColumn(\"acertou_tipo_histologico\",\n",
    "                    F.when((F.col(\"tipo_histologico\") == \"NÃO INFORMADO\") | F.col(\"heu_tipo_histologico\").isNull(), F.lit(False))\n",
    "                    .otherwise(F.col(\"tipo_histologico\") == F.col(\"heu_tipo_histologico\")))\n",
    "    )\n",
    "\n",
    "    df_respostas = df_comparisons\n",
    "\n",
    "    # 10. Calcular métricas\n",
    "    total_laudos = df_respostas.count()\n",
    "\n",
    "    def calcular_taxa_acerto(col_name):\n",
    "        if total_laudos == 0:\n",
    "            return {\"acertos\": 0, \"total\": 0, \"taxa_acerto\": 0.0}\n",
    "        taxa = df_respostas.select(F.avg(F.col(col_name).cast(\"double\")).alias(\"taxa\")).collect()[0][\"taxa\"]\n",
    "        if taxa is None:\n",
    "            taxa = 0.0\n",
    "        acertos = int(taxa * total_laudos)\n",
    "        return {\n",
    "            \"acertos\": acertos,\n",
    "            \"total\": total_laudos,\n",
    "            \"taxa_acerto\": taxa\n",
    "        }\n",
    "\n",
    "    json_metricas = {\n",
    "        \"descritores_malignidade\": calcular_taxa_acerto(\"acertou_descritores\"),\n",
    "        \"grau_histologico\": calcular_taxa_acerto(\"acertou_grau_histologico\"),\n",
    "        \"grau_nuclear\": calcular_taxa_acerto(\"acertou_grau_nuclear\"),\n",
    "        \"formacao_tubulos\": calcular_taxa_acerto(\"acertou_formacao_tubulos\"),\n",
    "        \"indice_mitotico\": calcular_taxa_acerto(\"acertou_indice_mitotico\"),\n",
    "        \"tipo_histologico\": calcular_taxa_acerto(\"acertou_tipo_histologico\"),\n",
    "    }\n",
    "\n",
    "    print(f\"\\n✓ Processamento concluído: {total_laudos} laudos\")\n",
    "    display(df_respostas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1808d80a-608e-4f8d-8d0c-3e434e872caf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Registro de métricas e experimentos no MLflow\n",
    "**Objetivo da Célula:** Criar ou recuperar um experimento no MLflow e registrar as métricas de qualidade da extração.\n",
    "\n",
    "**Dependências:**\n",
    "- Variável `json_metricas` com resultados agregados da avaliação\n",
    "- Bibliotecas mlflow e json\n",
    "\n",
    "**Funções Definidas:**\n",
    "- `get_or_create_experiment(experiment_name)`: Obtém ID de experimento existente ou cria um novo\n",
    "\n",
    "**Lógica Detalhada:**\n",
    "1. Define a função `get_or_create_experiment` para encontrar ou criar um experimento MLflow\n",
    "2. Obtém o ID do experimento para saúde preventiva mamária\n",
    "3. Configura o MLflow para registro automático de informações adicionais (`mlflow.autolog()`)\n",
    "4. Define um threshold de qualidade (80%) para avaliar se as extrações são aceitáveis\n",
    "5. Inicia uma nova execução (run) do MLflow\n",
    "6. Para cada campo avaliado, registra:\n",
    "   - Taxa de acerto (métrica principal)\n",
    "   - Flag indicando se passou no threshold\n",
    "   - Contagens absolutas de acertos e total\n",
    "7. Registra o ID da execução para referência futura\n",
    "\n",
    "**Parâmetros Registrados:**\n",
    "- `modelo`: Nome do modelo LLM utilizado (\"databricks-llama-4-maverick\")\n",
    "\n",
    "**Métricas Registradas:**\n",
    "- Para cada campo (`descritores_malignidade`, `grau_histologico`, etc.):\n",
    "  - `{campo}_taxa_acerto`: Porcentagem de extrações corretas\n",
    "  - `{campo}_passou_threshold`: Flag binária (1 = passou, 0 = falhou)\n",
    "  - `{campo}_acertos`: Número absoluto de extrações corretas\n",
    "  - `{campo}_total`: Número total de documentos avaliados\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- Cria um registro permanente da qualidade do modelo no sistema MLflow\n",
    "- Permite comparação da performance entre diferentes versões do modelo\n",
    "- Fornece ID de execução para referência e rastreabilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45ce7010-bc06-4059-ac7c-99eac5620b92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# import mlflow\n",
    "\n",
    "# def get_or_create_experiment(experiment_name):\n",
    "#     experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "#     if experiment:\n",
    "#         experiment_id = experiment.experiment_id\n",
    "#     else:\n",
    "#         experiment_id = mlflow.create_experiment(experiment_name)\n",
    "#     mlflow.set_experiment(experiment_name)\n",
    "#     return experiment_id\n",
    "\n",
    "# # Registrar métricas no MLflow apenas se houver dados processados\n",
    "# if df_spk.count() > 0:\n",
    "#     experiment_id = get_or_create_experiment(\"/Shared/saude_preventiva_mama/experiments_fleury_anatomopatologico\")\n",
    "#     mlflow.autolog()\n",
    "\n",
    "# threshold = 0.8\n",
    "\n",
    "# with mlflow.start_run(experiment_id=experiment_id) as run:\n",
    "#     mlflow.log_param(\"modelo\", ENDPOINT_NAME)\n",
    "#     mlflow.log_param(\"total_laudos\", total_laudos)\n",
    "    \n",
    "#     for campo, stats in json_metricas.items():\n",
    "#         taxa = stats[\"taxa_acerto\"]\n",
    "#         mlflow.log_metric(f\"{campo}_taxa_acerto\", taxa)\n",
    "#         passou_flag = 1 if taxa >= threshold else 0\n",
    "#         mlflow.log_metric(f\"{campo}_passou_threshold\", passou_flag)\n",
    "#         mlflow.log_metric(f\"{campo}_acertos\", stats[\"acertos\"])\n",
    "#         mlflow.log_metric(f\"{campo}_total\", stats[\"total\"])\n",
    "    \n",
    "#     run_id = mlflow.active_run().info.run_id\n",
    "#     print(f\"Run registrada: {run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eba9a9e2-7e6a-4f69-8fdf-34ce7220e6b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Visualização das métricas de qualidade da extração\n",
    "**Objetivo da Célula:** Exibir as métricas de qualidade da extração para análise visual.\n",
    "\n",
    "Esta célula usa a função `display()` para mostrar o dicionário de métricas `json_metricas` que foi calculado anteriormente. Estas métricas fornecem uma visão detalhada do desempenho da extração de informações pelo modelo LLM em comparação com a extração por RegEx, incluindo taxas de acerto para cada campo extraído."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ff04d9f-bfd2-43d7-b67d-01cee74e5270",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(json_metricas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d81ed6d8-fea3-40de-80e4-43d9502d3ef2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Persistência dos dados na tabela Delta\n",
    "**Objetivo da Célula:** Salvar os dados processados na tabela Delta de destino usando uma estratégia de merge.\n",
    "\n",
    "**Dependências:**\n",
    "- DataFrame `df_respostas` contendo os dados processados\n",
    "- Biblioteca Delta para operações de merge em tabelas\n",
    "- Octoops (Sentinel) para monitoramento e alertas\n",
    "\n",
    "**Funções Definidas:**\n",
    "- `insert_data(df_spk, output_data_path)`: Realiza o merge dos dados na tabela Delta especificada\n",
    "\n",
    "**Lógica Detalhada:**\n",
    "1. Define a constante `WEBHOOK_DS_AI_BUSINESS_STG` como 'stg' (ambiente de staging)\n",
    "2. Define a constante `OUTPUT_DATA_PATH` com o nome da tabela de destino\n",
    "3. Implementa a função `insert_data`:\n",
    "   - Carrega a tabela Delta existente\n",
    "   - Realiza um merge usando o DataFrame como origem\n",
    "   - Utiliza chaves de junção: ficha, id_item e id_subitem\n",
    "   - Atualiza registros existentes e insere novos registros\n",
    "4. Em um bloco try-except:\n",
    "   - Verifica se o DataFrame tem registros (`df_respostas.count() > 0`)\n",
    "   - Em caso positivo, chama `insert_data` para persistir os dados\n",
    "   - Em caso negativo, envia alerta via Sentinel informando ausência de laudos para extração\n",
    "   - Em caso de exceção, captura o erro, imprime o traceback e relança a exceção\n",
    "\n",
    "**Saída/Impacto:**\n",
    "- Os dados processados são salvos na tabela Delta usando estratégia de merge\n",
    "- O sistema registra a quantidade de registros salvos\n",
    "- Em caso de falha ou ausência de dados, um alerta é enviado via Sentinel para monitoramento\n",
    "- Exceções são devidamente registradas e relançadas para o sistema de monitoramento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ce4b6e3-d896-435b-83ab-de6b65025a41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from octoops import Sentinel\n",
    "# import traceback\n",
    "\n",
    "# WEBHOOK_DS_AI_BUSINESS_STG = 'stg'\n",
    "# OUTPUT_DATA_PATH = \"refined.saude_preventiva.fleury_laudos_mama_anatomia_patologica_v2\"\n",
    "\n",
    "# # Função para salvar dados na tabela Delta\n",
    "# def insert_data(df_spk, output_data_path):  \n",
    "#     # Carrega a tabela Delta existente\n",
    "#     delta_table = DeltaTable.forName(spark, output_data_path)\n",
    "\n",
    "#     # Faz o merge (upsert)\n",
    "#     (delta_table.alias(\"target\")\n",
    "#         .merge(\n",
    "#             df_spk.alias(\"source\"),\n",
    "#             \"target.ficha = source.ficha AND target.id_item = source.id_item AND target.id_subitem = source.id_subitem\"\n",
    "#         )\n",
    "#         .whenMatchedUpdateAll()  # atualiza todos os campos se o ID já existir\n",
    "#         .whenNotMatchedInsertAll()  # insere se o ID não existir\n",
    "#         .execute())\n",
    "\n",
    "# try:\n",
    "#     if df_spk.count() > 0:        \n",
    "#         insert_data(df_respostas, OUTPUT_DATA_PATH)\n",
    "#         print('Total de registros salvos na tabela:', df_respostas.count())\n",
    "#     else: \n",
    "#         error_message = \"Fleury AnatomoPatologico - Não há laudos para extração.\"\n",
    "#         sentinela_ds_ai_business = Sentinel(\n",
    "#             project_name='Monitor_Linhas_Cuidado_Mama',\n",
    "#             env_type=WEBHOOK_DS_AI_BUSINESS_STG,\n",
    "#             task_title='Fleury AnatomoPatologico'\n",
    "#         )\n",
    "\n",
    "#         sentinela_ds_ai_business.alerta_sentinela(\n",
    "#             categoria='Alerta', \n",
    "#             mensagem=error_message,\n",
    "#             job_id_descritivo='3_fleury_mama_anatomopatologico'\n",
    "#         )\n",
    "# except Exception as e:\n",
    "#     traceback.print_exc()\n",
    "#     raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b033ba23-d289-4193-bbe5-da050ce507e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df2 = df_respostas.toPandas()\n",
    "salvar_excel(df2, \"resultados_anatomo_medicos_5.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5986792388758106,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "(refatorado) 3_fleury_mama_anatomopatologico",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
